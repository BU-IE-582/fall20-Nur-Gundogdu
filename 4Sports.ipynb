{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sports News Objectivity Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate, integer attributes, classification problem. 1000 instances, 59 attributes, no missing data. We are trying to label the text objective or subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1000 sports articles were labeled using Amazon Mechanical Turk as objective or subjective. The raw texts, extracted features, and the URLs from which the articles were retrieved are provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(glmnet)\n",
    "library(tidyverse)\n",
    "library(caret)\n",
    "library(pROC)\n",
    "library(randomForest)\n",
    "library(gbm)\n",
    "library(rpart)\n",
    "require(rpart.plot)\n",
    "library(e1071)\n",
    "library(ranger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>61</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 61\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 61\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t1000 obs. of  61 variables:\n",
      " $ TextID           : Factor w/ 1000 levels \"Text0001\",\"Text0002\",..: 1 2 3 4 5 6 7 8 9 11 ...\n",
      " $ totalWordsCount  : int  109 309 149 305 491 314 314 462 808 860 ...\n",
      " $ semanticobjscore : int  0 21 6 18 23 14 10 19 40 44 ...\n",
      " $ semanticsubjscore: int  1 4 1 5 8 1 6 6 11 22 ...\n",
      " $ CC               : int  7 1 8 7 33 17 1 5 49 13 ...\n",
      " $ CD               : int  9 19 14 26 47 17 37 47 71 111 ...\n",
      " $ DT               : int  0 1 0 0 0 0 1 0 1 0 ...\n",
      " $ EX               : int  5 4 5 10 12 0 10 0 6 4 ...\n",
      " $ FW               : int  8 35 15 37 61 36 33 40 94 101 ...\n",
      " $ INs              : int  6 23 11 21 36 15 20 39 44 56 ...\n",
      " $ JJ               : int  0 0 0 1 0 2 0 0 2 3 ...\n",
      " $ JJR              : int  0 0 0 1 1 1 0 1 1 2 ...\n",
      " $ JJS              : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ LS               : int  0 2 0 0 2 0 0 9 0 2 ...\n",
      " $ MD               : int  29 93 47 83 142 88 112 101 162 196 ...\n",
      " $ NN               : int  0 1 1 2 1 1 3 1 7 2 ...\n",
      " $ NNP              : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ NNPS             : int  12 17 4 18 15 20 19 31 56 58 ...\n",
      " $ NNS              : int  0 0 0 0 0 1 0 0 0 0 ...\n",
      " $ PDT              : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ POS              : int  1 7 4 6 7 10 4 20 23 15 ...\n",
      " $ PRP              : int  2 5 0 2 9 6 2 7 10 15 ...\n",
      " $ PRP.             : int  2 16 7 9 10 8 3 16 34 35 ...\n",
      " $ RB               : int  0 0 0 1 1 0 0 0 0 4 ...\n",
      " $ RBR              : int  0 0 0 0 0 0 0 0 0 1 ...\n",
      " $ RBS              : int  2 0 1 1 1 1 0 1 10 11 ...\n",
      " $ RP               : int  0 1 0 2 0 0 0 3 8 0 ...\n",
      " $ SYM              : int  3 3 4 9 13 4 3 11 20 28 ...\n",
      " $ TOs              : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ UH               : int  0 0 0 1 1 0 0 3 3 3 ...\n",
      " $ VB               : int  11 13 8 13 34 24 13 21 59 73 ...\n",
      " $ VBD              : int  0 7 2 12 5 13 5 16 23 17 ...\n",
      " $ VBG              : int  2 13 2 6 6 2 7 8 7 9 ...\n",
      " $ VBN              : int  0 9 2 1 6 1 3 10 4 6 ...\n",
      " $ VBP              : int  0 14 3 7 5 5 1 16 12 8 ...\n",
      " $ VBZ              : int  0 0 0 1 0 3 2 1 2 1 ...\n",
      " $ WDT              : int  1 0 0 1 3 3 2 2 6 5 ...\n",
      " $ WP               : int  0 0 0 0 0 0 0 0 0 2 ...\n",
      " $ WP.              : int  1 3 2 1 1 0 0 3 7 1 ...\n",
      " $ WRB              : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ baseform         : int  2 8 4 5 7 11 4 16 23 30 ...\n",
      " $ Quotes           : int  0 7 0 3 4 6 2 9 10 0 ...\n",
      " $ questionmarks    : int  0 0 0 0 0 1 0 0 0 0 ...\n",
      " $ exclamationmarks : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ fullstops        : int  4 19 6 13 18 14 8 24 45 33 ...\n",
      " $ commas           : int  2 3 3 17 17 16 8 17 43 28 ...\n",
      " $ semicolon        : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ colon            : int  0 5 0 0 0 0 8 0 0 0 ...\n",
      " $ ellipsis         : int  0 0 0 0 0 0 0 0 0 0 ...\n",
      " $ pronouns1st      : int  0 1 0 0 0 0 3 2 1 0 ...\n",
      " $ pronouns2nd      : int  0 0 0 0 0 0 0 2 2 0 ...\n",
      " $ pronouns3rd      : int  3 10 2 8 16 16 3 13 18 25 ...\n",
      " $ compsupadjadv    : int  0 0 0 3 2 3 0 1 3 10 ...\n",
      " $ past             : int  11 13 8 13 34 24 13 21 59 73 ...\n",
      " $ imperative       : int  0 0 0 1 1 0 0 3 3 3 ...\n",
      " $ present3rd       : int  0 14 3 7 5 5 1 16 12 8 ...\n",
      " $ present1st2nd    : int  0 9 2 1 6 1 3 10 4 6 ...\n",
      " $ sentence1st      : int  0 1 1 1 1 1 1 1 1 1 ...\n",
      " $ sentencelast     : int  1 1 1 1 1 1 1 1 1 1 ...\n",
      " $ txtcomplexity    : int  18 14 18 20 24 18 31 17 17 24 ...\n",
      " $ Label            : Factor w/ 2 levels \"objective\",\"subjective\": 1 1 1 1 1 1 1 1 1 1 ...\n"
     ]
    }
   ],
   "source": [
    "sports <- read.table(\"C:/Users/n__gu/Desktop/sports.txt\", header=TRUE)\n",
    "dim(sports)\n",
    "str(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sports <- subset(sports, select=-c(TextID))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1000</li>\n",
       "\t<li>60</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1000\n",
       "\\item 60\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1000\n",
       "2. 60\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 1000   60"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim(sports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(101) # Set Seed so that same sample can be reproduced in future also\n",
    "# Now Selecting 75% of data as sample from total 'n' rows of the data  \n",
    "sample <- sample.int(n = nrow(sports), size = floor(.75*nrow(sports)), replace = F)\n",
    "train <- sports[sample, ]\n",
    "test  <- sports[-sample, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LASSO regression, find best lambda parameter with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train <- as.data.frame(train)\n",
    "x <- as.matrix(train[,1:59])\n",
    "y <- as.matrix(as.factor(train[,60]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.00977843169602353"
      ],
      "text/latex": [
       "0.00977843169602353"
      ],
      "text/markdown": [
       "0.00977843169602353"
      ],
      "text/plain": [
       "[1] 0.009778432"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "60 x 1 sparse Matrix of class \"dgCMatrix\"\n",
       "                             s0\n",
       "(Intercept)       -1.3509583314\n",
       "totalWordsCount    .           \n",
       "semanticobjscore   .           \n",
       "semanticsubjscore  0.0029512177\n",
       "CC                -0.0163373261\n",
       "CD                 0.0022222168\n",
       "DT                 0.0727121152\n",
       "EX                 .           \n",
       "FW                 .           \n",
       "INs                .           \n",
       "JJ                 .           \n",
       "JJR                .           \n",
       "JJS                0.4243318899\n",
       "LS                 0.0059703453\n",
       "MD                 .           \n",
       "NN                -0.0105248178\n",
       "NNP                .           \n",
       "NNPS               .           \n",
       "NNS                .           \n",
       "PDT               -0.0481510974\n",
       "POS                .           \n",
       "PRP                .           \n",
       "PRP.               0.0199072021\n",
       "RB                 0.1440880966\n",
       "RBR                .           \n",
       "RBS                .           \n",
       "RP                 .           \n",
       "SYM                .           \n",
       "TOs                0.2183095590\n",
       "UH                 0.0107192707\n",
       "VB                -0.0004981359\n",
       "VBD                .           \n",
       "VBG                .           \n",
       "VBN                .           \n",
       "VBP                0.0195594871\n",
       "VBZ                .           \n",
       "WDT                0.0244799625\n",
       "WP                 0.4096400787\n",
       "WP.                0.0586020723\n",
       "WRB                .           \n",
       "baseform           0.0134592212\n",
       "Quotes            -0.0606672764\n",
       "questionmarks      0.2352631092\n",
       "exclamationmarks   0.1059294467\n",
       "fullstops          .           \n",
       "commas             .           \n",
       "semicolon          .           \n",
       "colon             -0.0149763600\n",
       "ellipsis           .           \n",
       "pronouns1st       -0.0095103174\n",
       "pronouns2nd        .           \n",
       "pronouns3rd        0.0029371571\n",
       "compsupadjadv      0.0333791482\n",
       "past              -0.0177400421\n",
       "imperative         .           \n",
       "present3rd         .           \n",
       "present1st2nd      .           \n",
       "sentence1st       -0.2134503175\n",
       "sentencelast       .           \n",
       "txtcomplexity     -0.0135645832"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set.seed(123) \n",
    "cv <- cv.glmnet(x, y, alpha = 1,family=\"binomial\")\n",
    "\n",
    "# Display the best lambda value\n",
    "cv$lambda.min\n",
    "model <- glmnet(x, y , alpha = 1, lambda = cv$lambda.min,family=\"binomial\")\n",
    "# Display regression coefficients\n",
    "coef(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " objective subjective \n",
       "       476        274 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = objective, case = subjective\n",
      "Setting direction: controls < cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.897242838741336"
      ],
      "text/latex": [
       "0.897242838741336"
      ],
      "text/markdown": [
       "0.897242838741336"
      ],
      "text/plain": [
       "Area under the curve: 0.8972"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.train <- as.matrix(train[,1:59])\n",
    "predictions <- model %>% predict(x.train) %>% as.vector()\n",
    "\n",
    "table(train[,60])\n",
    "auc(roc(response = train$Label, predictor = predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " objective subjective \n",
       "       159         91 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting levels: control = objective, case = subjective\n",
      "Setting direction: controls < cases\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.90096067454558"
      ],
      "text/latex": [
       "0.90096067454558"
      ],
      "text/markdown": [
       "0.90096067454558"
      ],
      "text/plain": [
       "Area under the curve: 0.901"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x.test <- as.matrix(test[,1:59])\n",
    "predictions <- model %>% predict(x.test) %>% as.vector()\n",
    "\n",
    "table(test[,60])\n",
    "auc(roc(response = test$Label, predictor = predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Worked well, AUC=0.9 for test and 0.89 for train data shows good performance. No issue of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters of the minimal number of observations per tree leaf and complexity parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "caret.control <- trainControl(method = \"repeatedcv\",\n",
    "                              number = 10,\n",
    "                              repeats = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpGrid = expand.grid( .cp = seq(0.01,0.5) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rpart.cv <- train(Label ~ ., \n",
    "                  data = train,\n",
    "                  method = \"rpart\",\n",
    "                  trControl = caret.control,\n",
    "                  tuneGrid = cpGrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CART \n",
       "\n",
       "750 samples\n",
       " 59 predictor\n",
       "  2 classes: 'objective', 'subjective' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold, repeated 3 times) \n",
       "Summary of sample sizes: 675, 675, 674, 675, 675, 674, ... \n",
       "Resampling results:\n",
       "\n",
       "  Accuracy   Kappa    \n",
       "  0.7866758  0.5321262\n",
       "\n",
       "Tuning parameter 'cp' was held constant at a value of 0.01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rpart.cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        133         26\n",
       "  subjective        19         72\n",
       "                                          \n",
       "               Accuracy : 0.82            \n",
       "                 95% CI : (0.7667, 0.8656)\n",
       "    No Information Rate : 0.608           \n",
       "    P-Value [Acc > NIR] : 3.735e-13       \n",
       "                                          \n",
       "                  Kappa : 0.6175          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.3711          \n",
       "                                          \n",
       "            Sensitivity : 0.8750          \n",
       "            Specificity : 0.7347          \n",
       "         Pos Pred Value : 0.8365          \n",
       "         Neg Pred Value : 0.7912          \n",
       "             Prevalence : 0.6080          \n",
       "         Detection Rate : 0.5320          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8048          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree2 <- rpart(Label~., data=train,control = rpart.control(minbucket =2, cp= 0.02) , method = 'class')\n",
    "predict2 <-predict(tree2, newdata=test, type = 'class')\n",
    "confusionMatrix(test$Label,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        133         26\n",
       "  subjective        19         72\n",
       "                                          \n",
       "               Accuracy : 0.82            \n",
       "                 95% CI : (0.7667, 0.8656)\n",
       "    No Information Rate : 0.608           \n",
       "    P-Value [Acc > NIR] : 3.735e-13       \n",
       "                                          \n",
       "                  Kappa : 0.6175          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.3711          \n",
       "                                          \n",
       "            Sensitivity : 0.8750          \n",
       "            Specificity : 0.7347          \n",
       "         Pos Pred Value : 0.8365          \n",
       "         Neg Pred Value : 0.7912          \n",
       "             Prevalence : 0.6080          \n",
       "         Detection Rate : 0.5320          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8048          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree2 <- rpart(Label~., data=train,control = rpart.control(minbucket =5, cp= 0.02) , method = 'class')\n",
    "predict2 <-predict(tree2, newdata=test, type = 'class')\n",
    "confusionMatrix(test$Label,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        133         26\n",
       "  subjective        19         72\n",
       "                                          \n",
       "               Accuracy : 0.82            \n",
       "                 95% CI : (0.7667, 0.8656)\n",
       "    No Information Rate : 0.608           \n",
       "    P-Value [Acc > NIR] : 3.735e-13       \n",
       "                                          \n",
       "                  Kappa : 0.6175          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.3711          \n",
       "                                          \n",
       "            Sensitivity : 0.8750          \n",
       "            Specificity : 0.7347          \n",
       "         Pos Pred Value : 0.8365          \n",
       "         Neg Pred Value : 0.7912          \n",
       "             Prevalence : 0.6080          \n",
       "         Detection Rate : 0.5320          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8048          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree2 <- rpart(Label~., data=train,control = rpart.control(minbucket =3, cp= 0.015) , method = 'class')\n",
    "predict2 <-predict(tree2, newdata=test, type = 'class')\n",
    "confusionMatrix(test$Label,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        133         26\n",
       "  subjective        19         72\n",
       "                                          \n",
       "               Accuracy : 0.82            \n",
       "                 95% CI : (0.7667, 0.8656)\n",
       "    No Information Rate : 0.608           \n",
       "    P-Value [Acc > NIR] : 3.735e-13       \n",
       "                                          \n",
       "                  Kappa : 0.6175          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.3711          \n",
       "                                          \n",
       "            Sensitivity : 0.8750          \n",
       "            Specificity : 0.7347          \n",
       "         Pos Pred Value : 0.8365          \n",
       "         Neg Pred Value : 0.7912          \n",
       "             Prevalence : 0.6080          \n",
       "         Detection Rate : 0.5320          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8048          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree2 <- rpart(Label~., data=train,control = rpart.control(minbucket =3, cp= 0.02) , method = 'class')\n",
    "predict2 <-predict(tree2, newdata=test, type = 'class')\n",
    "confusionMatrix(test$Label,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        416         60\n",
       "  subjective        64        210\n",
       "                                          \n",
       "               Accuracy : 0.8347          \n",
       "                 95% CI : (0.8061, 0.8606)\n",
       "    No Information Rate : 0.64            \n",
       "    P-Value [Acc > NIR] : <2e-16          \n",
       "                                          \n",
       "                  Kappa : 0.6424          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.7876          \n",
       "                                          \n",
       "            Sensitivity : 0.8667          \n",
       "            Specificity : 0.7778          \n",
       "         Pos Pred Value : 0.8739          \n",
       "         Neg Pred Value : 0.7664          \n",
       "             Prevalence : 0.6400          \n",
       "         Detection Rate : 0.5547          \n",
       "   Detection Prevalence : 0.6347          \n",
       "      Balanced Accuracy : 0.8222          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predict2 <-predict(tree2, newdata=train, type = 'class')\n",
    "confusionMatrix(train$Label,predict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"average error using k-fold cross-validation: 18.000 percent\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "\n",
    "errs <- rep(NA, length(folds))\n",
    "\n",
    "for (i in 1:10) {\n",
    " tmp.model <- rpart(Label~. , train,control = rpart.control(minbucket =3, cp= 0.02), method = \"class\")\n",
    " tmp.predict <- predict(tmp.model, newdata = test, type = \"class\")\n",
    " conf.mat <- table(test$Label, tmp.predict)\n",
    " errs[i] <- 1-sum(diag(conf.mat))/sum(conf.mat)\n",
    "}\n",
    "print(sprintf(\"average error using k-fold cross-validation: %.3f percent\", 100*mean(errs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"average error using k-fold cross-validation: 16.533 percent\"\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "\n",
    "errs <- rep(NA, length(folds))\n",
    "\n",
    "for (i in 1:10) {\n",
    " tmp.model <- rpart(Label~. , train,control = rpart.control(minbucket =3, cp= 0.02), method = \"class\")\n",
    " tmp.predict <- predict(tmp.model, newdata = train, type = \"class\")\n",
    " conf.mat <- table(train$Label, tmp.predict)\n",
    " errs[i] <- 1-sum(diag(conf.mat))/sum(conf.mat)\n",
    "}\n",
    "print(sprintf(\"average error using k-fold cross-validation: %.3f percent\", 100*mean(errs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying diffferent set of parameters, the best parameters are found to be minbucket = 3, cp = 0.02. Accuracy is 0.82, somewhat good result.\n",
    "\n",
    "Average error of k-fold cross valiation is 18% for test data, and 16.5% for train data. Accuracy for train data is 0.83. We do not observe under or overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameter for the minimal number of observations per tree leaf with cross validation. Min node size is set to 5 and ntree to 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold01.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep1: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep1: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep1: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep1: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep2: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep2: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep2: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep2: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold01.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold01.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold02.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold02.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold03.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold03.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold04.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold04.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold05.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold05.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold06.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold06.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold07.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold07.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold08.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold08.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold09.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold09.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep3: mtry= 2, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep3: mtry= 5, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep3: mtry= 7, splitrule=gini, min.node.size=5 \n",
      "+ Fold10.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "- Fold10.Rep3: mtry=10, splitrule=gini, min.node.size=5 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting mtry = 2, splitrule = gini, min.node.size = 5 on full training set\n"
     ]
    }
   ],
   "source": [
    "folds <- createMultiFolds(train$Label, k = 10, times = 3)\n",
    "control <- trainControl(method = \"cv\", number = 10, verboseIter = TRUE,\n",
    "                        classProbs = TRUE, savePredictions = TRUE, index = folds, allowParallel = TRUE)\n",
    "tune_grid <- expand.grid(mtry = c(2,5,7,10), splitrule = \"gini\", min.node.size = 5)\n",
    "rf <- train(Label~., train, method = \"ranger\", tuneGrid = tune_grid, trControl = control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictrf <-predict(rf, newdata=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        140         19\n",
       "  subjective        23         68\n",
       "                                          \n",
       "               Accuracy : 0.832           \n",
       "                 95% CI : (0.7798, 0.8762)\n",
       "    No Information Rate : 0.652           \n",
       "    P-Value [Acc > NIR] : 1.952e-10       \n",
       "                                          \n",
       "                  Kappa : 0.6337          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.6434          \n",
       "                                          \n",
       "            Sensitivity : 0.8589          \n",
       "            Specificity : 0.7816          \n",
       "         Pos Pred Value : 0.8805          \n",
       "         Neg Pred Value : 0.7473          \n",
       "             Prevalence : 0.6520          \n",
       "         Detection Rate : 0.5600          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8203          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "confusionMatrix(test$Label,predictrf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        476          0\n",
       "  subjective        12        262\n",
       "                                          \n",
       "               Accuracy : 0.984           \n",
       "                 95% CI : (0.9722, 0.9917)\n",
       "    No Information Rate : 0.6507          \n",
       "    P-Value [Acc > NIR] : < 2.2e-16       \n",
       "                                          \n",
       "                  Kappa : 0.9652          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.001496        \n",
       "                                          \n",
       "            Sensitivity : 0.9754          \n",
       "            Specificity : 1.0000          \n",
       "         Pos Pred Value : 1.0000          \n",
       "         Neg Pred Value : 0.9562          \n",
       "             Prevalence : 0.6507          \n",
       "         Detection Rate : 0.6347          \n",
       "   Detection Prevalence : 0.6347          \n",
       "      Balanced Accuracy : 0.9877          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictrf <-predict(rf, newdata=train)\n",
    "confusionMatrix(train$Label,predictrf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is 0.83 for test data, and 0.98 for train data. We observe overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best parameters for depth, learning rate, and number of trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in train.default(x, y, weights = w, ...):\n",
      "\"The metric \"Accuracy\" was not in the result set. ROC will be used instead.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ Fold01.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3123             nan     0.0010    0.0003\n",
      "     2        1.3117             nan     0.0010    0.0003\n",
      "     3        1.3110             nan     0.0010    0.0003\n",
      "     4        1.3104             nan     0.0010    0.0003\n",
      "     5        1.3098             nan     0.0010    0.0003\n",
      "     6        1.3092             nan     0.0010    0.0003\n",
      "     7        1.3086             nan     0.0010    0.0003\n",
      "     8        1.3080             nan     0.0010    0.0003\n",
      "     9        1.3075             nan     0.0010    0.0003\n",
      "    10        1.3069             nan     0.0010    0.0003\n",
      "    20        1.3008             nan     0.0010    0.0003\n",
      "    40        1.2890             nan     0.0010    0.0003\n",
      "    60        1.2779             nan     0.0010    0.0002\n",
      "    80        1.2672             nan     0.0010    0.0003\n",
      "   100        1.2567             nan     0.0010    0.0002\n",
      "   120        1.2465             nan     0.0010    0.0002\n",
      "   140        1.2368             nan     0.0010    0.0002\n",
      "   160        1.2272             nan     0.0010    0.0002\n",
      "   180        1.2180             nan     0.0010    0.0002\n",
      "   200        1.2088             nan     0.0010    0.0002\n",
      "   220        1.2003             nan     0.0010    0.0002\n",
      "   240        1.1917             nan     0.0010    0.0002\n",
      "   260        1.1834             nan     0.0010    0.0002\n",
      "   280        1.1756             nan     0.0010    0.0001\n",
      "   300        1.1680             nan     0.0010    0.0002\n",
      "   320        1.1604             nan     0.0010    0.0002\n",
      "   340        1.1530             nan     0.0010    0.0002\n",
      "   360        1.1457             nan     0.0010    0.0002\n",
      "   380        1.1391             nan     0.0010    0.0001\n",
      "   400        1.1323             nan     0.0010    0.0002\n",
      "   420        1.1259             nan     0.0010    0.0001\n",
      "   440        1.1195             nan     0.0010    0.0001\n",
      "   460        1.1134             nan     0.0010    0.0001\n",
      "   480        1.1072             nan     0.0010    0.0001\n",
      "   500        1.1014             nan     0.0010    0.0001\n",
      "   520        1.0958             nan     0.0010    0.0001\n",
      "   540        1.0901             nan     0.0010    0.0001\n",
      "   560        1.0845             nan     0.0010    0.0001\n",
      "   580        1.0791             nan     0.0010    0.0001\n",
      "   600        1.0739             nan     0.0010    0.0001\n",
      "   620        1.0688             nan     0.0010    0.0001\n",
      "   640        1.0637             nan     0.0010    0.0001\n",
      "   660        1.0589             nan     0.0010    0.0001\n",
      "   680        1.0542             nan     0.0010    0.0001\n",
      "   700        1.0496             nan     0.0010    0.0001\n",
      "   720        1.0451             nan     0.0010    0.0001\n",
      "   740        1.0407             nan     0.0010    0.0001\n",
      "   760        1.0363             nan     0.0010    0.0001\n",
      "   780        1.0322             nan     0.0010    0.0001\n",
      "   800        1.0280             nan     0.0010    0.0001\n",
      "   820        1.0241             nan     0.0010    0.0001\n",
      "   840        1.0202             nan     0.0010    0.0001\n",
      "   860        1.0164             nan     0.0010    0.0001\n",
      "   880        1.0128             nan     0.0010    0.0001\n",
      "   900        1.0091             nan     0.0010    0.0001\n",
      "   920        1.0056             nan     0.0010    0.0001\n",
      "   940        1.0022             nan     0.0010    0.0001\n",
      "   960        0.9989             nan     0.0010    0.0001\n",
      "   980        0.9957             nan     0.0010    0.0001\n",
      "  1000        0.9922             nan     0.0010    0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold01.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3122             nan     0.0010    0.0003\n",
      "     2        1.3114             nan     0.0010    0.0004\n",
      "     3        1.3106             nan     0.0010    0.0004\n",
      "     4        1.3098             nan     0.0010    0.0003\n",
      "     5        1.3089             nan     0.0010    0.0004\n",
      "     6        1.3082             nan     0.0010    0.0004\n",
      "     7        1.3074             nan     0.0010    0.0004\n",
      "     8        1.3066             nan     0.0010    0.0003\n",
      "     9        1.3058             nan     0.0010    0.0003\n",
      "    10        1.3049             nan     0.0010    0.0004\n",
      "    20        1.2973             nan     0.0010    0.0003\n",
      "    40        1.2825             nan     0.0010    0.0003\n",
      "    60        1.2676             nan     0.0010    0.0003\n",
      "    80        1.2541             nan     0.0010    0.0003\n",
      "   100        1.2409             nan     0.0010    0.0003\n",
      "   120        1.2280             nan     0.0010    0.0003\n",
      "   140        1.2155             nan     0.0010    0.0003\n",
      "   160        1.2037             nan     0.0010    0.0003\n",
      "   180        1.1918             nan     0.0010    0.0003\n",
      "   200        1.1806             nan     0.0010    0.0002\n",
      "   220        1.1694             nan     0.0010    0.0002\n",
      "   240        1.1587             nan     0.0010    0.0002\n",
      "   260        1.1484             nan     0.0010    0.0002\n",
      "   280        1.1384             nan     0.0010    0.0002\n",
      "   300        1.1287             nan     0.0010    0.0002\n",
      "   320        1.1194             nan     0.0010    0.0002\n",
      "   340        1.1103             nan     0.0010    0.0002\n",
      "   360        1.1014             nan     0.0010    0.0002\n",
      "   380        1.0928             nan     0.0010    0.0002\n",
      "   400        1.0842             nan     0.0010    0.0002\n",
      "   420        1.0760             nan     0.0010    0.0001\n",
      "   440        1.0682             nan     0.0010    0.0002\n",
      "   460        1.0604             nan     0.0010    0.0001\n",
      "   480        1.0531             nan     0.0010    0.0002\n",
      "   500        1.0460             nan     0.0010    0.0001\n",
      "   520        1.0387             nan     0.0010    0.0001\n",
      "   540        1.0319             nan     0.0010    0.0002\n",
      "   560        1.0252             nan     0.0010    0.0001\n",
      "   580        1.0186             nan     0.0010    0.0001\n",
      "   600        1.0123             nan     0.0010    0.0001\n",
      "   620        1.0060             nan     0.0010    0.0001\n",
      "   640        1.0000             nan     0.0010    0.0001\n",
      "   660        0.9938             nan     0.0010    0.0001\n",
      "   680        0.9878             nan     0.0010    0.0001\n",
      "   700        0.9821             nan     0.0010    0.0001\n",
      "   720        0.9768             nan     0.0010    0.0001\n",
      "   740        0.9713             nan     0.0010    0.0001\n",
      "   760        0.9662             nan     0.0010    0.0001\n",
      "   780        0.9610             nan     0.0010    0.0001\n",
      "   800        0.9562             nan     0.0010    0.0001\n",
      "   820        0.9511             nan     0.0010    0.0001\n",
      "   840        0.9465             nan     0.0010    0.0001\n",
      "   860        0.9417             nan     0.0010    0.0001\n",
      "   880        0.9370             nan     0.0010    0.0001\n",
      "   900        0.9324             nan     0.0010    0.0001\n",
      "   920        0.9279             nan     0.0010    0.0001\n",
      "   940        0.9236             nan     0.0010    0.0001\n",
      "   960        0.9192             nan     0.0010    0.0001\n",
      "   980        0.9149             nan     0.0010    0.0001\n",
      "  1000        0.9106             nan     0.0010    0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold01.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3121             nan     0.0010    0.0003\n",
      "     2        1.3112             nan     0.0010    0.0004\n",
      "     3        1.3103             nan     0.0010    0.0004\n",
      "     4        1.3093             nan     0.0010    0.0004\n",
      "     5        1.3084             nan     0.0010    0.0003\n",
      "     6        1.3075             nan     0.0010    0.0004\n",
      "     7        1.3066             nan     0.0010    0.0004\n",
      "     8        1.3057             nan     0.0010    0.0003\n",
      "     9        1.3049             nan     0.0010    0.0004\n",
      "    10        1.3040             nan     0.0010    0.0004\n",
      "    20        1.2956             nan     0.0010    0.0003\n",
      "    40        1.2790             nan     0.0010    0.0004\n",
      "    60        1.2630             nan     0.0010    0.0004\n",
      "    80        1.2478             nan     0.0010    0.0003\n",
      "   100        1.2329             nan     0.0010    0.0004\n",
      "   120        1.2189             nan     0.0010    0.0003\n",
      "   140        1.2050             nan     0.0010    0.0003\n",
      "   160        1.1915             nan     0.0010    0.0003\n",
      "   180        1.1785             nan     0.0010    0.0003\n",
      "   200        1.1659             nan     0.0010    0.0003\n",
      "   220        1.1540             nan     0.0010    0.0003\n",
      "   240        1.1421             nan     0.0010    0.0003\n",
      "   260        1.1305             nan     0.0010    0.0002\n",
      "   280        1.1197             nan     0.0010    0.0002\n",
      "   300        1.1090             nan     0.0010    0.0002\n",
      "   320        1.0984             nan     0.0010    0.0002\n",
      "   340        1.0881             nan     0.0010    0.0002\n",
      "   360        1.0780             nan     0.0010    0.0002\n",
      "   380        1.0685             nan     0.0010    0.0002\n",
      "   400        1.0591             nan     0.0010    0.0002\n",
      "   420        1.0499             nan     0.0010    0.0002\n",
      "   440        1.0411             nan     0.0010    0.0002\n",
      "   460        1.0325             nan     0.0010    0.0002\n",
      "   480        1.0241             nan     0.0010    0.0001\n",
      "   500        1.0157             nan     0.0010    0.0001\n",
      "   520        1.0076             nan     0.0010    0.0002\n",
      "   540        0.9998             nan     0.0010    0.0001\n",
      "   560        0.9921             nan     0.0010    0.0001\n",
      "   580        0.9847             nan     0.0010    0.0001\n",
      "   600        0.9774             nan     0.0010    0.0001\n",
      "   620        0.9703             nan     0.0010    0.0001\n",
      "   640        0.9635             nan     0.0010    0.0001\n",
      "   660        0.9569             nan     0.0010    0.0001\n",
      "   680        0.9501             nan     0.0010    0.0001\n",
      "   700        0.9437             nan     0.0010    0.0001\n",
      "   720        0.9374             nan     0.0010    0.0001\n",
      "   740        0.9314             nan     0.0010    0.0001\n",
      "   760        0.9253             nan     0.0010    0.0001\n",
      "   780        0.9194             nan     0.0010    0.0001\n",
      "   800        0.9136             nan     0.0010    0.0001\n",
      "   820        0.9079             nan     0.0010    0.0001\n",
      "   840        0.9025             nan     0.0010    0.0001\n",
      "   860        0.8970             nan     0.0010    0.0001\n",
      "   880        0.8917             nan     0.0010    0.0001\n",
      "   900        0.8868             nan     0.0010    0.0001\n",
      "   920        0.8817             nan     0.0010    0.0001\n",
      "   940        0.8768             nan     0.0010    0.0001\n",
      "   960        0.8720             nan     0.0010    0.0001\n",
      "   980        0.8671             nan     0.0010    0.0001\n",
      "  1000        0.8625             nan     0.0010    0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold01.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3066             nan     0.0100    0.0028\n",
      "     2        1.3004             nan     0.0100    0.0027\n",
      "     3        1.2946             nan     0.0100    0.0027\n",
      "     4        1.2888             nan     0.0100    0.0025\n",
      "     5        1.2827             nan     0.0100    0.0027\n",
      "     6        1.2778             nan     0.0100    0.0027\n",
      "     7        1.2730             nan     0.0100    0.0021\n",
      "     8        1.2680             nan     0.0100    0.0025\n",
      "     9        1.2625             nan     0.0100    0.0026\n",
      "    10        1.2568             nan     0.0100    0.0025\n",
      "    20        1.2084             nan     0.0100    0.0021\n",
      "    40        1.1305             nan     0.0100    0.0015\n",
      "    60        1.0721             nan     0.0100    0.0012\n",
      "    80        1.0279             nan     0.0100    0.0008\n",
      "   100        0.9906             nan     0.0100    0.0005\n",
      "   120        0.9634             nan     0.0100    0.0005\n",
      "   140        0.9406             nan     0.0100    0.0004\n",
      "   160        0.9217             nan     0.0100    0.0002\n",
      "   180        0.9062             nan     0.0100   -0.0000\n",
      "   200        0.8930             nan     0.0100    0.0003\n",
      "   220        0.8828             nan     0.0100    0.0001\n",
      "   240        0.8731             nan     0.0100    0.0000\n",
      "   260        0.8646             nan     0.0100    0.0001\n",
      "   280        0.8566             nan     0.0100    0.0002\n",
      "   300        0.8485             nan     0.0100   -0.0000\n",
      "   320        0.8416             nan     0.0100   -0.0000\n",
      "   340        0.8353             nan     0.0100    0.0001\n",
      "   360        0.8290             nan     0.0100    0.0000\n",
      "   380        0.8233             nan     0.0100   -0.0000\n",
      "   400        0.8173             nan     0.0100    0.0000\n",
      "   420        0.8117             nan     0.0100    0.0000\n",
      "   440        0.8066             nan     0.0100   -0.0001\n",
      "   460        0.8016             nan     0.0100   -0.0001\n",
      "   480        0.7969             nan     0.0100   -0.0000\n",
      "   500        0.7921             nan     0.0100   -0.0000\n",
      "   520        0.7878             nan     0.0100    0.0000\n",
      "   540        0.7832             nan     0.0100   -0.0001\n",
      "   560        0.7792             nan     0.0100   -0.0001\n",
      "   580        0.7747             nan     0.0100   -0.0000\n",
      "   600        0.7704             nan     0.0100   -0.0000\n",
      "   620        0.7664             nan     0.0100    0.0000\n",
      "   640        0.7626             nan     0.0100   -0.0001\n",
      "   660        0.7589             nan     0.0100   -0.0001\n",
      "   680        0.7552             nan     0.0100   -0.0000\n",
      "   700        0.7515             nan     0.0100    0.0000\n",
      "   720        0.7479             nan     0.0100    0.0000\n",
      "   740        0.7445             nan     0.0100   -0.0001\n",
      "   760        0.7415             nan     0.0100    0.0000\n",
      "   780        0.7385             nan     0.0100   -0.0001\n",
      "   800        0.7356             nan     0.0100   -0.0000\n",
      "   820        0.7329             nan     0.0100   -0.0002\n",
      "   840        0.7300             nan     0.0100    0.0000\n",
      "   860        0.7267             nan     0.0100   -0.0000\n",
      "   880        0.7235             nan     0.0100   -0.0000\n",
      "   900        0.7208             nan     0.0100   -0.0000\n",
      "   920        0.7177             nan     0.0100   -0.0000\n",
      "   940        0.7147             nan     0.0100   -0.0001\n",
      "   960        0.7117             nan     0.0100   -0.0001\n",
      "   980        0.7088             nan     0.0100   -0.0001\n",
      "  1000        0.7066             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold01.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3054             nan     0.0100    0.0032\n",
      "     2        1.2977             nan     0.0100    0.0033\n",
      "     3        1.2896             nan     0.0100    0.0036\n",
      "     4        1.2825             nan     0.0100    0.0034\n",
      "     5        1.2749             nan     0.0100    0.0030\n",
      "     6        1.2675             nan     0.0100    0.0036\n",
      "     7        1.2608             nan     0.0100    0.0030\n",
      "     8        1.2536             nan     0.0100    0.0031\n",
      "     9        1.2475             nan     0.0100    0.0029\n",
      "    10        1.2413             nan     0.0100    0.0027\n",
      "    20        1.1791             nan     0.0100    0.0026\n",
      "    40        1.0851             nan     0.0100    0.0017\n",
      "    60        1.0124             nan     0.0100    0.0011\n",
      "    80        0.9554             nan     0.0100    0.0009\n",
      "   100        0.9112             nan     0.0100    0.0008\n",
      "   120        0.8749             nan     0.0100    0.0005\n",
      "   140        0.8439             nan     0.0100    0.0004\n",
      "   160        0.8171             nan     0.0100    0.0003\n",
      "   180        0.7946             nan     0.0100    0.0003\n",
      "   200        0.7749             nan     0.0100    0.0002\n",
      "   220        0.7573             nan     0.0100    0.0001\n",
      "   240        0.7420             nan     0.0100    0.0000\n",
      "   260        0.7283             nan     0.0100   -0.0000\n",
      "   280        0.7151             nan     0.0100    0.0000\n",
      "   300        0.7029             nan     0.0100   -0.0002\n",
      "   320        0.6920             nan     0.0100   -0.0001\n",
      "   340        0.6809             nan     0.0100    0.0000\n",
      "   360        0.6717             nan     0.0100   -0.0000\n",
      "   380        0.6620             nan     0.0100   -0.0001\n",
      "   400        0.6525             nan     0.0100   -0.0000\n",
      "   420        0.6439             nan     0.0100   -0.0001\n",
      "   440        0.6356             nan     0.0100    0.0000\n",
      "   460        0.6273             nan     0.0100   -0.0001\n",
      "   480        0.6185             nan     0.0100    0.0000\n",
      "   500        0.6103             nan     0.0100   -0.0002\n",
      "   520        0.6026             nan     0.0100    0.0000\n",
      "   540        0.5956             nan     0.0100   -0.0000\n",
      "   560        0.5884             nan     0.0100   -0.0001\n",
      "   580        0.5813             nan     0.0100   -0.0002\n",
      "   600        0.5743             nan     0.0100   -0.0002\n",
      "   620        0.5678             nan     0.0100   -0.0002\n",
      "   640        0.5607             nan     0.0100   -0.0000\n",
      "   660        0.5549             nan     0.0100   -0.0001\n",
      "   680        0.5486             nan     0.0100   -0.0000\n",
      "   700        0.5430             nan     0.0100   -0.0001\n",
      "   720        0.5362             nan     0.0100   -0.0001\n",
      "   740        0.5299             nan     0.0100   -0.0001\n",
      "   760        0.5247             nan     0.0100   -0.0001\n",
      "   780        0.5182             nan     0.0100   -0.0001\n",
      "   800        0.5123             nan     0.0100   -0.0001\n",
      "   820        0.5061             nan     0.0100   -0.0001\n",
      "   840        0.5008             nan     0.0100   -0.0001\n",
      "   860        0.4956             nan     0.0100   -0.0001\n",
      "   880        0.4903             nan     0.0100   -0.0000\n",
      "   900        0.4848             nan     0.0100   -0.0000\n",
      "   920        0.4799             nan     0.0100   -0.0001\n",
      "   940        0.4741             nan     0.0100   -0.0002\n",
      "   960        0.4692             nan     0.0100   -0.0001\n",
      "   980        0.4640             nan     0.0100   -0.0001\n",
      "  1000        0.4585             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold01.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3048             nan     0.0100    0.0035\n",
      "     2        1.2967             nan     0.0100    0.0037\n",
      "     3        1.2883             nan     0.0100    0.0035\n",
      "     4        1.2805             nan     0.0100    0.0029\n",
      "     5        1.2726             nan     0.0100    0.0033\n",
      "     6        1.2642             nan     0.0100    0.0036\n",
      "     7        1.2569             nan     0.0100    0.0032\n",
      "     8        1.2497             nan     0.0100    0.0028\n",
      "     9        1.2420             nan     0.0100    0.0033\n",
      "    10        1.2352             nan     0.0100    0.0031\n",
      "    20        1.1680             nan     0.0100    0.0025\n",
      "    40        1.0586             nan     0.0100    0.0020\n",
      "    60        0.9763             nan     0.0100    0.0016\n",
      "    80        0.9128             nan     0.0100    0.0008\n",
      "   100        0.8616             nan     0.0100    0.0007\n",
      "   120        0.8189             nan     0.0100    0.0005\n",
      "   140        0.7826             nan     0.0100    0.0004\n",
      "   160        0.7522             nan     0.0100    0.0004\n",
      "   180        0.7269             nan     0.0100    0.0004\n",
      "   200        0.7047             nan     0.0100    0.0003\n",
      "   220        0.6828             nan     0.0100    0.0002\n",
      "   240        0.6632             nan     0.0100   -0.0001\n",
      "   260        0.6448             nan     0.0100    0.0000\n",
      "   280        0.6275             nan     0.0100   -0.0001\n",
      "   300        0.6123             nan     0.0100   -0.0001\n",
      "   320        0.5981             nan     0.0100   -0.0000\n",
      "   340        0.5839             nan     0.0100   -0.0002\n",
      "   360        0.5713             nan     0.0100   -0.0000\n",
      "   380        0.5597             nan     0.0100   -0.0001\n",
      "   400        0.5478             nan     0.0100    0.0000\n",
      "   420        0.5362             nan     0.0100    0.0000\n",
      "   440        0.5246             nan     0.0100   -0.0002\n",
      "   460        0.5136             nan     0.0100   -0.0002\n",
      "   480        0.5034             nan     0.0100    0.0000\n",
      "   500        0.4935             nan     0.0100   -0.0001\n",
      "   520        0.4837             nan     0.0100   -0.0001\n",
      "   540        0.4745             nan     0.0100   -0.0002\n",
      "   560        0.4661             nan     0.0100   -0.0002\n",
      "   580        0.4573             nan     0.0100   -0.0000\n",
      "   600        0.4482             nan     0.0100   -0.0001\n",
      "   620        0.4406             nan     0.0100   -0.0001\n",
      "   640        0.4323             nan     0.0100   -0.0000\n",
      "   660        0.4247             nan     0.0100   -0.0001\n",
      "   680        0.4167             nan     0.0100   -0.0002\n",
      "   700        0.4095             nan     0.0100   -0.0001\n",
      "   720        0.4029             nan     0.0100   -0.0002\n",
      "   740        0.3955             nan     0.0100   -0.0001\n",
      "   760        0.3882             nan     0.0100   -0.0002\n",
      "   780        0.3808             nan     0.0100   -0.0002\n",
      "   800        0.3737             nan     0.0100   -0.0001\n",
      "   820        0.3670             nan     0.0100   -0.0000\n",
      "   840        0.3610             nan     0.0100   -0.0002\n",
      "   860        0.3548             nan     0.0100   -0.0001\n",
      "   880        0.3482             nan     0.0100   -0.0001\n",
      "   900        0.3420             nan     0.0100   -0.0001\n",
      "   920        0.3361             nan     0.0100   -0.0000\n",
      "   940        0.3306             nan     0.0100   -0.0001\n",
      "   960        0.3255             nan     0.0100   -0.0002\n",
      "   980        0.3203             nan     0.0100    0.0000\n",
      "  1000        0.3150             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold01.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3112             nan     0.0010    0.0003\n",
      "     2        1.3106             nan     0.0010    0.0003\n",
      "     3        1.3099             nan     0.0010    0.0003\n",
      "     4        1.3093             nan     0.0010    0.0003\n",
      "     5        1.3087             nan     0.0010    0.0003\n",
      "     6        1.3080             nan     0.0010    0.0003\n",
      "     7        1.3075             nan     0.0010    0.0003\n",
      "     8        1.3069             nan     0.0010    0.0003\n",
      "     9        1.3063             nan     0.0010    0.0003\n",
      "    10        1.3057             nan     0.0010    0.0003\n",
      "    20        1.2995             nan     0.0010    0.0003\n",
      "    40        1.2873             nan     0.0010    0.0003\n",
      "    60        1.2755             nan     0.0010    0.0003\n",
      "    80        1.2643             nan     0.0010    0.0003\n",
      "   100        1.2534             nan     0.0010    0.0002\n",
      "   120        1.2428             nan     0.0010    0.0002\n",
      "   140        1.2329             nan     0.0010    0.0002\n",
      "   160        1.2230             nan     0.0010    0.0002\n",
      "   180        1.2133             nan     0.0010    0.0002\n",
      "   200        1.2040             nan     0.0010    0.0002\n",
      "   220        1.1948             nan     0.0010    0.0002\n",
      "   240        1.1860             nan     0.0010    0.0002\n",
      "   260        1.1773             nan     0.0010    0.0002\n",
      "   280        1.1688             nan     0.0010    0.0002\n",
      "   300        1.1610             nan     0.0010    0.0002\n",
      "   320        1.1531             nan     0.0010    0.0002\n",
      "   340        1.1457             nan     0.0010    0.0002\n",
      "   360        1.1385             nan     0.0010    0.0002\n",
      "   380        1.1314             nan     0.0010    0.0002\n",
      "   400        1.1246             nan     0.0010    0.0002\n",
      "   420        1.1180             nan     0.0010    0.0002\n",
      "   440        1.1116             nan     0.0010    0.0001\n",
      "   460        1.1052             nan     0.0010    0.0001\n",
      "   480        1.0991             nan     0.0010    0.0001\n",
      "   500        1.0933             nan     0.0010    0.0001\n",
      "   520        1.0876             nan     0.0010    0.0001\n",
      "   540        1.0819             nan     0.0010    0.0001\n",
      "   560        1.0764             nan     0.0010    0.0001\n",
      "   580        1.0709             nan     0.0010    0.0001\n",
      "   600        1.0656             nan     0.0010    0.0001\n",
      "   620        1.0606             nan     0.0010    0.0001\n",
      "   640        1.0556             nan     0.0010    0.0001\n",
      "   660        1.0507             nan     0.0010    0.0001\n",
      "   680        1.0461             nan     0.0010    0.0001\n",
      "   700        1.0414             nan     0.0010    0.0001\n",
      "   720        1.0369             nan     0.0010    0.0001\n",
      "   740        1.0324             nan     0.0010    0.0001\n",
      "   760        1.0282             nan     0.0010    0.0001\n",
      "   780        1.0241             nan     0.0010    0.0001\n",
      "   800        1.0199             nan     0.0010    0.0001\n",
      "   820        1.0161             nan     0.0010    0.0000\n",
      "   840        1.0122             nan     0.0010    0.0001\n",
      "   860        1.0084             nan     0.0010    0.0001\n",
      "   880        1.0049             nan     0.0010    0.0001\n",
      "   900        1.0014             nan     0.0010    0.0001\n",
      "   920        0.9979             nan     0.0010    0.0001\n",
      "   940        0.9945             nan     0.0010    0.0001\n",
      "   960        0.9912             nan     0.0010    0.0001\n",
      "   980        0.9878             nan     0.0010    0.0001\n",
      "  1000        0.9846             nan     0.0010    0.0001\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3111             nan     0.0010    0.0003\n",
      "     2        1.3103             nan     0.0010    0.0004\n",
      "     3        1.3095             nan     0.0010    0.0004\n",
      "     4        1.3087             nan     0.0010    0.0003\n",
      "     5        1.3080             nan     0.0010    0.0003\n",
      "     6        1.3072             nan     0.0010    0.0003\n",
      "     7        1.3064             nan     0.0010    0.0004\n",
      "     8        1.3056             nan     0.0010    0.0004\n",
      "     9        1.3048             nan     0.0010    0.0004\n",
      "    10        1.3040             nan     0.0010    0.0003\n",
      "    20        1.2963             nan     0.0010    0.0003\n",
      "    40        1.2810             nan     0.0010    0.0004\n",
      "    60        1.2664             nan     0.0010    0.0003\n",
      "    80        1.2523             nan     0.0010    0.0003\n",
      "   100        1.2388             nan     0.0010    0.0003\n",
      "   120        1.2255             nan     0.0010    0.0003\n",
      "   140        1.2128             nan     0.0010    0.0003\n",
      "   160        1.2007             nan     0.0010    0.0003\n",
      "   180        1.1887             nan     0.0010    0.0003\n",
      "   200        1.1775             nan     0.0010    0.0002\n",
      "   220        1.1664             nan     0.0010    0.0002\n",
      "   240        1.1558             nan     0.0010    0.0002\n",
      "   260        1.1454             nan     0.0010    0.0002\n",
      "   280        1.1352             nan     0.0010    0.0002\n",
      "   300        1.1253             nan     0.0010    0.0002\n",
      "   320        1.1158             nan     0.0010    0.0002\n",
      "   340        1.1066             nan     0.0010    0.0002\n",
      "   360        1.0976             nan     0.0010    0.0002\n",
      "   380        1.0890             nan     0.0010    0.0002\n",
      "   400        1.0806             nan     0.0010    0.0002\n",
      "   420        1.0722             nan     0.0010    0.0002\n",
      "   440        1.0642             nan     0.0010    0.0002\n",
      "   460        1.0563             nan     0.0010    0.0002\n",
      "   480        1.0485             nan     0.0010    0.0002\n",
      "   500        1.0409             nan     0.0010    0.0002\n",
      "   520        1.0337             nan     0.0010    0.0001\n",
      "   540        1.0267             nan     0.0010    0.0002\n",
      "   560        1.0201             nan     0.0010    0.0001\n",
      "   580        1.0136             nan     0.0010    0.0001\n",
      "   600        1.0072             nan     0.0010    0.0002\n",
      "   620        1.0009             nan     0.0010    0.0001\n",
      "   640        0.9944             nan     0.0010    0.0001\n",
      "   660        0.9884             nan     0.0010    0.0001\n",
      "   680        0.9825             nan     0.0010    0.0001\n",
      "   700        0.9766             nan     0.0010    0.0001\n",
      "   720        0.9712             nan     0.0010    0.0001\n",
      "   740        0.9659             nan     0.0010    0.0001\n",
      "   760        0.9605             nan     0.0010    0.0001\n",
      "   780        0.9554             nan     0.0010    0.0001\n",
      "   800        0.9505             nan     0.0010    0.0001\n",
      "   820        0.9456             nan     0.0010    0.0001\n",
      "   840        0.9408             nan     0.0010    0.0001\n",
      "   860        0.9358             nan     0.0010    0.0001\n",
      "   880        0.9311             nan     0.0010    0.0001\n",
      "   900        0.9267             nan     0.0010    0.0001\n",
      "   920        0.9224             nan     0.0010    0.0001\n",
      "   940        0.9180             nan     0.0010    0.0000\n",
      "   960        0.9137             nan     0.0010    0.0000\n",
      "   980        0.9096             nan     0.0010    0.0001\n",
      "  1000        0.9055             nan     0.0010    0.0001\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3110             nan     0.0010    0.0004\n",
      "     2        1.3102             nan     0.0010    0.0003\n",
      "     3        1.3093             nan     0.0010    0.0004\n",
      "     4        1.3085             nan     0.0010    0.0004\n",
      "     5        1.3076             nan     0.0010    0.0004\n",
      "     6        1.3068             nan     0.0010    0.0004\n",
      "     7        1.3060             nan     0.0010    0.0004\n",
      "     8        1.3051             nan     0.0010    0.0004\n",
      "     9        1.3042             nan     0.0010    0.0004\n",
      "    10        1.3034             nan     0.0010    0.0004\n",
      "    20        1.2952             nan     0.0010    0.0004\n",
      "    40        1.2787             nan     0.0010    0.0003\n",
      "    60        1.2628             nan     0.0010    0.0003\n",
      "    80        1.2474             nan     0.0010    0.0003\n",
      "   100        1.2325             nan     0.0010    0.0003\n",
      "   120        1.2182             nan     0.0010    0.0003\n",
      "   140        1.2045             nan     0.0010    0.0003\n",
      "   160        1.1909             nan     0.0010    0.0003\n",
      "   180        1.1775             nan     0.0010    0.0003\n",
      "   200        1.1649             nan     0.0010    0.0003\n",
      "   220        1.1524             nan     0.0010    0.0002\n",
      "   240        1.1402             nan     0.0010    0.0002\n",
      "   260        1.1288             nan     0.0010    0.0002\n",
      "   280        1.1174             nan     0.0010    0.0002\n",
      "   300        1.1064             nan     0.0010    0.0002\n",
      "   320        1.0955             nan     0.0010    0.0002\n",
      "   340        1.0852             nan     0.0010    0.0002\n",
      "   360        1.0751             nan     0.0010    0.0002\n",
      "   380        1.0654             nan     0.0010    0.0002\n",
      "   400        1.0561             nan     0.0010    0.0002\n",
      "   420        1.0469             nan     0.0010    0.0002\n",
      "   440        1.0378             nan     0.0010    0.0002\n",
      "   460        1.0292             nan     0.0010    0.0001\n",
      "   480        1.0209             nan     0.0010    0.0002\n",
      "   500        1.0126             nan     0.0010    0.0001\n",
      "   520        1.0048             nan     0.0010    0.0001\n",
      "   540        0.9968             nan     0.0010    0.0001\n",
      "   560        0.9893             nan     0.0010    0.0001\n",
      "   580        0.9818             nan     0.0010    0.0001\n",
      "   600        0.9746             nan     0.0010    0.0001\n",
      "   620        0.9678             nan     0.0010    0.0001\n",
      "   640        0.9609             nan     0.0010    0.0001\n",
      "   660        0.9541             nan     0.0010    0.0001\n",
      "   680        0.9477             nan     0.0010    0.0001\n",
      "   700        0.9413             nan     0.0010    0.0001\n",
      "   720        0.9352             nan     0.0010    0.0001\n",
      "   740        0.9291             nan     0.0010    0.0001\n",
      "   760        0.9232             nan     0.0010    0.0001\n",
      "   780        0.9175             nan     0.0010    0.0001\n",
      "   800        0.9118             nan     0.0010    0.0001\n",
      "   820        0.9062             nan     0.0010    0.0001\n",
      "   840        0.9009             nan     0.0010    0.0001\n",
      "   860        0.8958             nan     0.0010    0.0001\n",
      "   880        0.8905             nan     0.0010    0.0001\n",
      "   900        0.8855             nan     0.0010    0.0001\n",
      "   920        0.8806             nan     0.0010    0.0001\n",
      "   940        0.8758             nan     0.0010    0.0001\n",
      "   960        0.8712             nan     0.0010    0.0001\n",
      "   980        0.8663             nan     0.0010    0.0001\n",
      "  1000        0.8616             nan     0.0010    0.0001\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3063             nan     0.0100    0.0029\n",
      "     2        1.2998             nan     0.0100    0.0029\n",
      "     3        1.2943             nan     0.0100    0.0027\n",
      "     4        1.2887             nan     0.0100    0.0028\n",
      "     5        1.2822             nan     0.0100    0.0027\n",
      "     6        1.2762             nan     0.0100    0.0029\n",
      "     7        1.2704             nan     0.0100    0.0027\n",
      "     8        1.2649             nan     0.0100    0.0025\n",
      "     9        1.2587             nan     0.0100    0.0024\n",
      "    10        1.2534             nan     0.0100    0.0026\n",
      "    20        1.2033             nan     0.0100    0.0022\n",
      "    40        1.1252             nan     0.0100    0.0015\n",
      "    60        1.0654             nan     0.0100    0.0008\n",
      "    80        1.0199             nan     0.0100    0.0008\n",
      "   100        0.9849             nan     0.0100    0.0005\n",
      "   120        0.9566             nan     0.0100    0.0005\n",
      "   140        0.9332             nan     0.0100    0.0004\n",
      "   160        0.9148             nan     0.0100    0.0002\n",
      "   180        0.9003             nan     0.0100    0.0003\n",
      "   200        0.8878             nan     0.0100    0.0001\n",
      "   220        0.8770             nan     0.0100    0.0002\n",
      "   240        0.8680             nan     0.0100   -0.0000\n",
      "   260        0.8595             nan     0.0100    0.0001\n",
      "   280        0.8517             nan     0.0100    0.0001\n",
      "   300        0.8441             nan     0.0100    0.0001\n",
      "   320        0.8377             nan     0.0100    0.0000\n",
      "   340        0.8311             nan     0.0100    0.0000\n",
      "   360        0.8247             nan     0.0100   -0.0000\n",
      "   380        0.8183             nan     0.0100   -0.0001\n",
      "   400        0.8131             nan     0.0100    0.0000\n",
      "   420        0.8078             nan     0.0100    0.0001\n",
      "   440        0.8028             nan     0.0100   -0.0001\n",
      "   460        0.7980             nan     0.0100   -0.0000\n",
      "   480        0.7930             nan     0.0100   -0.0000\n",
      "   500        0.7881             nan     0.0100   -0.0001\n",
      "   520        0.7840             nan     0.0100    0.0000\n",
      "   540        0.7797             nan     0.0100   -0.0000\n",
      "   560        0.7758             nan     0.0100    0.0001\n",
      "   580        0.7719             nan     0.0100   -0.0000\n",
      "   600        0.7680             nan     0.0100    0.0000\n",
      "   620        0.7644             nan     0.0100   -0.0000\n",
      "   640        0.7609             nan     0.0100   -0.0000\n",
      "   660        0.7575             nan     0.0100   -0.0000\n",
      "   680        0.7539             nan     0.0100    0.0000\n",
      "   700        0.7502             nan     0.0100   -0.0000\n",
      "   720        0.7468             nan     0.0100   -0.0000\n",
      "   740        0.7432             nan     0.0100   -0.0000\n",
      "   760        0.7403             nan     0.0100   -0.0001\n",
      "   780        0.7373             nan     0.0100   -0.0001\n",
      "   800        0.7340             nan     0.0100   -0.0000\n",
      "   820        0.7315             nan     0.0100   -0.0000\n",
      "   840        0.7286             nan     0.0100   -0.0001\n",
      "   860        0.7256             nan     0.0100    0.0000\n",
      "   880        0.7231             nan     0.0100   -0.0000\n",
      "   900        0.7205             nan     0.0100   -0.0000\n",
      "   920        0.7177             nan     0.0100   -0.0000\n",
      "   940        0.7149             nan     0.0100   -0.0001\n",
      "   960        0.7125             nan     0.0100   -0.0001\n",
      "   980        0.7101             nan     0.0100   -0.0000\n",
      "  1000        0.7076             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3040             nan     0.0100    0.0035\n",
      "     2        1.2962             nan     0.0100    0.0038\n",
      "     3        1.2892             nan     0.0100    0.0034\n",
      "     4        1.2822             nan     0.0100    0.0036\n",
      "     5        1.2745             nan     0.0100    0.0032\n",
      "     6        1.2675             nan     0.0100    0.0033\n",
      "     7        1.2600             nan     0.0100    0.0034\n",
      "     8        1.2527             nan     0.0100    0.0032\n",
      "     9        1.2458             nan     0.0100    0.0030\n",
      "    10        1.2389             nan     0.0100    0.0031\n",
      "    20        1.1766             nan     0.0100    0.0026\n",
      "    40        1.0809             nan     0.0100    0.0018\n",
      "    60        1.0087             nan     0.0100    0.0012\n",
      "    80        0.9516             nan     0.0100    0.0009\n",
      "   100        0.9061             nan     0.0100    0.0006\n",
      "   120        0.8695             nan     0.0100    0.0005\n",
      "   140        0.8378             nan     0.0100    0.0006\n",
      "   160        0.8132             nan     0.0100    0.0002\n",
      "   180        0.7913             nan     0.0100    0.0004\n",
      "   200        0.7723             nan     0.0100    0.0001\n",
      "   220        0.7566             nan     0.0100    0.0001\n",
      "   240        0.7419             nan     0.0100   -0.0001\n",
      "   260        0.7289             nan     0.0100    0.0001\n",
      "   280        0.7164             nan     0.0100    0.0000\n",
      "   300        0.7051             nan     0.0100   -0.0000\n",
      "   320        0.6940             nan     0.0100   -0.0001\n",
      "   340        0.6837             nan     0.0100   -0.0002\n",
      "   360        0.6738             nan     0.0100    0.0001\n",
      "   380        0.6643             nan     0.0100   -0.0001\n",
      "   400        0.6546             nan     0.0100   -0.0001\n",
      "   420        0.6455             nan     0.0100   -0.0001\n",
      "   440        0.6376             nan     0.0100   -0.0001\n",
      "   460        0.6285             nan     0.0100   -0.0000\n",
      "   480        0.6207             nan     0.0100   -0.0001\n",
      "   500        0.6129             nan     0.0100   -0.0002\n",
      "   520        0.6054             nan     0.0100   -0.0000\n",
      "   540        0.5988             nan     0.0100   -0.0002\n",
      "   560        0.5914             nan     0.0100   -0.0001\n",
      "   580        0.5844             nan     0.0100   -0.0001\n",
      "   600        0.5767             nan     0.0100   -0.0001\n",
      "   620        0.5702             nan     0.0100   -0.0000\n",
      "   640        0.5633             nan     0.0100   -0.0002\n",
      "   660        0.5566             nan     0.0100   -0.0001\n",
      "   680        0.5509             nan     0.0100   -0.0000\n",
      "   700        0.5449             nan     0.0100    0.0000\n",
      "   720        0.5389             nan     0.0100   -0.0001\n",
      "   740        0.5335             nan     0.0100   -0.0001\n",
      "   760        0.5282             nan     0.0100   -0.0000\n",
      "   780        0.5224             nan     0.0100   -0.0002\n",
      "   800        0.5170             nan     0.0100   -0.0000\n",
      "   820        0.5121             nan     0.0100   -0.0002\n",
      "   840        0.5062             nan     0.0100   -0.0001\n",
      "   860        0.5002             nan     0.0100   -0.0000\n",
      "   880        0.4948             nan     0.0100   -0.0000\n",
      "   900        0.4901             nan     0.0100   -0.0001\n",
      "   920        0.4849             nan     0.0100   -0.0000\n",
      "   940        0.4792             nan     0.0100   -0.0001\n",
      "   960        0.4748             nan     0.0100   -0.0001\n",
      "   980        0.4700             nan     0.0100   -0.0003\n",
      "  1000        0.4656             nan     0.0100    0.0000\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold02.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3034             nan     0.0100    0.0034\n",
      "     2        1.2958             nan     0.0100    0.0032\n",
      "     3        1.2871             nan     0.0100    0.0036\n",
      "     4        1.2791             nan     0.0100    0.0036\n",
      "     5        1.2714             nan     0.0100    0.0035\n",
      "     6        1.2636             nan     0.0100    0.0033\n",
      "     7        1.2551             nan     0.0100    0.0037\n",
      "     8        1.2471             nan     0.0100    0.0034\n",
      "     9        1.2395             nan     0.0100    0.0034\n",
      "    10        1.2313             nan     0.0100    0.0033\n",
      "    20        1.1658             nan     0.0100    0.0021\n",
      "    40        1.0574             nan     0.0100    0.0021\n",
      "    60        0.9773             nan     0.0100    0.0014\n",
      "    80        0.9148             nan     0.0100    0.0012\n",
      "   100        0.8641             nan     0.0100    0.0008\n",
      "   120        0.8223             nan     0.0100    0.0005\n",
      "   140        0.7881             nan     0.0100    0.0003\n",
      "   160        0.7596             nan     0.0100    0.0003\n",
      "   180        0.7335             nan     0.0100    0.0001\n",
      "   200        0.7096             nan     0.0100    0.0001\n",
      "   220        0.6896             nan     0.0100   -0.0001\n",
      "   240        0.6709             nan     0.0100   -0.0001\n",
      "   260        0.6538             nan     0.0100   -0.0000\n",
      "   280        0.6388             nan     0.0100   -0.0001\n",
      "   300        0.6229             nan     0.0100    0.0001\n",
      "   320        0.6072             nan     0.0100   -0.0001\n",
      "   340        0.5931             nan     0.0100   -0.0001\n",
      "   360        0.5807             nan     0.0100    0.0001\n",
      "   380        0.5680             nan     0.0100   -0.0002\n",
      "   400        0.5565             nan     0.0100   -0.0001\n",
      "   420        0.5460             nan     0.0100    0.0001\n",
      "   440        0.5357             nan     0.0100   -0.0001\n",
      "   460        0.5255             nan     0.0100   -0.0000\n",
      "   480        0.5152             nan     0.0100   -0.0003\n",
      "   500        0.5047             nan     0.0100    0.0001\n",
      "   520        0.4951             nan     0.0100   -0.0002\n",
      "   540        0.4854             nan     0.0100   -0.0001\n",
      "   560        0.4759             nan     0.0100   -0.0001\n",
      "   580        0.4673             nan     0.0100   -0.0001\n",
      "   600        0.4593             nan     0.0100   -0.0002\n",
      "   620        0.4518             nan     0.0100   -0.0003\n",
      "   640        0.4433             nan     0.0100   -0.0001\n",
      "   660        0.4355             nan     0.0100   -0.0001\n",
      "   680        0.4273             nan     0.0100   -0.0001\n",
      "   700        0.4194             nan     0.0100   -0.0002\n",
      "   720        0.4117             nan     0.0100   -0.0001\n",
      "   740        0.4042             nan     0.0100   -0.0001\n",
      "   760        0.3976             nan     0.0100   -0.0002\n",
      "   780        0.3908             nan     0.0100   -0.0001\n",
      "   800        0.3844             nan     0.0100   -0.0002\n",
      "   820        0.3769             nan     0.0100   -0.0000\n",
      "   840        0.3705             nan     0.0100   -0.0001\n",
      "   860        0.3639             nan     0.0100   -0.0002\n",
      "   880        0.3574             nan     0.0100   -0.0001\n",
      "   900        0.3514             nan     0.0100   -0.0001\n",
      "   920        0.3456             nan     0.0100   -0.0001\n",
      "   940        0.3403             nan     0.0100   -0.0002\n",
      "   960        0.3348             nan     0.0100   -0.0001\n",
      "   980        0.3292             nan     0.0100   -0.0001\n",
      "  1000        0.3241             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold02.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3129             nan     0.0010    0.0003\n",
      "     2        1.3123             nan     0.0010    0.0003\n",
      "     3        1.3117             nan     0.0010    0.0003\n",
      "     4        1.3111             nan     0.0010    0.0003\n",
      "     5        1.3106             nan     0.0010    0.0003\n",
      "     6        1.3099             nan     0.0010    0.0003\n",
      "     7        1.3093             nan     0.0010    0.0003\n",
      "     8        1.3087             nan     0.0010    0.0003\n",
      "     9        1.3081             nan     0.0010    0.0003\n",
      "    10        1.3075             nan     0.0010    0.0003\n",
      "    20        1.3016             nan     0.0010    0.0003\n",
      "    40        1.2900             nan     0.0010    0.0003\n",
      "    60        1.2787             nan     0.0010    0.0003\n",
      "    80        1.2676             nan     0.0010    0.0002\n",
      "   100        1.2571             nan     0.0010    0.0002\n",
      "   120        1.2469             nan     0.0010    0.0002\n",
      "   140        1.2368             nan     0.0010    0.0002\n",
      "   160        1.2273             nan     0.0010    0.0002\n",
      "   180        1.2181             nan     0.0010    0.0002\n",
      "   200        1.2091             nan     0.0010    0.0002\n",
      "   220        1.2002             nan     0.0010    0.0002\n",
      "   240        1.1918             nan     0.0010    0.0002\n",
      "   260        1.1833             nan     0.0010    0.0002\n",
      "   280        1.1754             nan     0.0010    0.0002\n",
      "   300        1.1675             nan     0.0010    0.0002\n",
      "   320        1.1600             nan     0.0010    0.0002\n",
      "   340        1.1527             nan     0.0010    0.0002\n",
      "   360        1.1456             nan     0.0010    0.0002\n",
      "   380        1.1386             nan     0.0010    0.0002\n",
      "   400        1.1317             nan     0.0010    0.0001\n",
      "   420        1.1252             nan     0.0010    0.0002\n",
      "   440        1.1190             nan     0.0010    0.0002\n",
      "   460        1.1128             nan     0.0010    0.0001\n",
      "   480        1.1068             nan     0.0010    0.0001\n",
      "   500        1.1009             nan     0.0010    0.0001\n",
      "   520        1.0951             nan     0.0010    0.0001\n",
      "   540        1.0898             nan     0.0010    0.0001\n",
      "   560        1.0843             nan     0.0010    0.0001\n",
      "   580        1.0791             nan     0.0010    0.0001\n",
      "   600        1.0741             nan     0.0010    0.0001\n",
      "   620        1.0690             nan     0.0010    0.0001\n",
      "   640        1.0641             nan     0.0010    0.0001\n",
      "   660        1.0593             nan     0.0010    0.0001\n",
      "   680        1.0546             nan     0.0010    0.0001\n",
      "   700        1.0500             nan     0.0010    0.0001\n",
      "   720        1.0455             nan     0.0010    0.0001\n",
      "   740        1.0411             nan     0.0010    0.0001\n",
      "   760        1.0371             nan     0.0010    0.0001\n",
      "   780        1.0331             nan     0.0010    0.0001\n",
      "   800        1.0290             nan     0.0010    0.0001\n",
      "   820        1.0252             nan     0.0010    0.0001\n",
      "   840        1.0215             nan     0.0010    0.0001\n",
      "   860        1.0178             nan     0.0010    0.0001\n",
      "   880        1.0142             nan     0.0010    0.0001\n",
      "   900        1.0105             nan     0.0010    0.0001\n",
      "   920        1.0070             nan     0.0010    0.0001\n",
      "   940        1.0036             nan     0.0010    0.0001\n",
      "   960        1.0002             nan     0.0010    0.0001\n",
      "   980        0.9970             nan     0.0010    0.0001\n",
      "  1000        0.9937             nan     0.0010    0.0001\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3128             nan     0.0010    0.0003\n",
      "     2        1.3121             nan     0.0010    0.0003\n",
      "     3        1.3113             nan     0.0010    0.0003\n",
      "     4        1.3105             nan     0.0010    0.0004\n",
      "     5        1.3097             nan     0.0010    0.0004\n",
      "     6        1.3090             nan     0.0010    0.0003\n",
      "     7        1.3082             nan     0.0010    0.0003\n",
      "     8        1.3075             nan     0.0010    0.0003\n",
      "     9        1.3067             nan     0.0010    0.0004\n",
      "    10        1.3059             nan     0.0010    0.0003\n",
      "    20        1.2985             nan     0.0010    0.0003\n",
      "    40        1.2836             nan     0.0010    0.0003\n",
      "    60        1.2693             nan     0.0010    0.0003\n",
      "    80        1.2555             nan     0.0010    0.0003\n",
      "   100        1.2427             nan     0.0010    0.0003\n",
      "   120        1.2298             nan     0.0010    0.0003\n",
      "   140        1.2170             nan     0.0010    0.0003\n",
      "   160        1.2052             nan     0.0010    0.0003\n",
      "   180        1.1936             nan     0.0010    0.0002\n",
      "   200        1.1825             nan     0.0010    0.0003\n",
      "   220        1.1716             nan     0.0010    0.0003\n",
      "   240        1.1612             nan     0.0010    0.0003\n",
      "   260        1.1510             nan     0.0010    0.0002\n",
      "   280        1.1413             nan     0.0010    0.0002\n",
      "   300        1.1316             nan     0.0010    0.0002\n",
      "   320        1.1221             nan     0.0010    0.0002\n",
      "   340        1.1131             nan     0.0010    0.0002\n",
      "   360        1.1044             nan     0.0010    0.0002\n",
      "   380        1.0957             nan     0.0010    0.0002\n",
      "   400        1.0871             nan     0.0010    0.0002\n",
      "   420        1.0789             nan     0.0010    0.0002\n",
      "   440        1.0710             nan     0.0010    0.0001\n",
      "   460        1.0634             nan     0.0010    0.0002\n",
      "   480        1.0561             nan     0.0010    0.0002\n",
      "   500        1.0490             nan     0.0010    0.0002\n",
      "   520        1.0421             nan     0.0010    0.0002\n",
      "   540        1.0352             nan     0.0010    0.0002\n",
      "   560        1.0285             nan     0.0010    0.0002\n",
      "   580        1.0222             nan     0.0010    0.0001\n",
      "   600        1.0156             nan     0.0010    0.0001\n",
      "   620        1.0095             nan     0.0010    0.0001\n",
      "   640        1.0037             nan     0.0010    0.0001\n",
      "   660        0.9979             nan     0.0010    0.0001\n",
      "   680        0.9923             nan     0.0010    0.0001\n",
      "   700        0.9868             nan     0.0010    0.0001\n",
      "   720        0.9810             nan     0.0010    0.0001\n",
      "   740        0.9757             nan     0.0010    0.0001\n",
      "   760        0.9704             nan     0.0010    0.0001\n",
      "   780        0.9654             nan     0.0010    0.0001\n",
      "   800        0.9604             nan     0.0010    0.0001\n",
      "   820        0.9555             nan     0.0010    0.0001\n",
      "   840        0.9508             nan     0.0010    0.0001\n",
      "   860        0.9461             nan     0.0010    0.0001\n",
      "   880        0.9417             nan     0.0010    0.0001\n",
      "   900        0.9372             nan     0.0010    0.0001\n",
      "   920        0.9329             nan     0.0010    0.0000\n",
      "   940        0.9287             nan     0.0010    0.0001\n",
      "   960        0.9245             nan     0.0010    0.0001\n",
      "   980        0.9203             nan     0.0010    0.0001\n",
      "  1000        0.9164             nan     0.0010    0.0001\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3127             nan     0.0010    0.0003\n",
      "     2        1.3118             nan     0.0010    0.0004\n",
      "     3        1.3109             nan     0.0010    0.0004\n",
      "     4        1.3101             nan     0.0010    0.0004\n",
      "     5        1.3091             nan     0.0010    0.0004\n",
      "     6        1.3082             nan     0.0010    0.0004\n",
      "     7        1.3075             nan     0.0010    0.0004\n",
      "     8        1.3066             nan     0.0010    0.0004\n",
      "     9        1.3058             nan     0.0010    0.0004\n",
      "    10        1.3049             nan     0.0010    0.0003\n",
      "    20        1.2965             nan     0.0010    0.0004\n",
      "    40        1.2801             nan     0.0010    0.0004\n",
      "    60        1.2640             nan     0.0010    0.0003\n",
      "    80        1.2490             nan     0.0010    0.0003\n",
      "   100        1.2343             nan     0.0010    0.0003\n",
      "   120        1.2205             nan     0.0010    0.0002\n",
      "   140        1.2067             nan     0.0010    0.0003\n",
      "   160        1.1933             nan     0.0010    0.0003\n",
      "   180        1.1804             nan     0.0010    0.0003\n",
      "   200        1.1680             nan     0.0010    0.0002\n",
      "   220        1.1559             nan     0.0010    0.0003\n",
      "   240        1.1443             nan     0.0010    0.0002\n",
      "   260        1.1327             nan     0.0010    0.0003\n",
      "   280        1.1216             nan     0.0010    0.0002\n",
      "   300        1.1110             nan     0.0010    0.0002\n",
      "   320        1.1004             nan     0.0010    0.0002\n",
      "   340        1.0904             nan     0.0010    0.0002\n",
      "   360        1.0809             nan     0.0010    0.0002\n",
      "   380        1.0715             nan     0.0010    0.0002\n",
      "   400        1.0626             nan     0.0010    0.0002\n",
      "   420        1.0536             nan     0.0010    0.0002\n",
      "   440        1.0450             nan     0.0010    0.0002\n",
      "   460        1.0364             nan     0.0010    0.0002\n",
      "   480        1.0284             nan     0.0010    0.0001\n",
      "   500        1.0202             nan     0.0010    0.0001\n",
      "   520        1.0124             nan     0.0010    0.0002\n",
      "   540        1.0048             nan     0.0010    0.0002\n",
      "   560        0.9973             nan     0.0010    0.0001\n",
      "   580        0.9902             nan     0.0010    0.0001\n",
      "   600        0.9831             nan     0.0010    0.0001\n",
      "   620        0.9762             nan     0.0010    0.0001\n",
      "   640        0.9695             nan     0.0010    0.0001\n",
      "   660        0.9626             nan     0.0010    0.0001\n",
      "   680        0.9562             nan     0.0010    0.0001\n",
      "   700        0.9499             nan     0.0010    0.0001\n",
      "   720        0.9439             nan     0.0010    0.0001\n",
      "   740        0.9380             nan     0.0010    0.0001\n",
      "   760        0.9323             nan     0.0010    0.0001\n",
      "   780        0.9266             nan     0.0010    0.0001\n",
      "   800        0.9211             nan     0.0010    0.0001\n",
      "   820        0.9156             nan     0.0010    0.0001\n",
      "   840        0.9105             nan     0.0010    0.0001\n",
      "   860        0.9053             nan     0.0010    0.0001\n",
      "   880        0.9004             nan     0.0010    0.0001\n",
      "   900        0.8954             nan     0.0010    0.0001\n",
      "   920        0.8904             nan     0.0010    0.0001\n",
      "   940        0.8857             nan     0.0010    0.0001\n",
      "   960        0.8810             nan     0.0010    0.0001\n",
      "   980        0.8764             nan     0.0010    0.0001\n",
      "  1000        0.8718             nan     0.0010    0.0001\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3068             nan     0.0100    0.0029\n",
      "     2        1.3004             nan     0.0100    0.0029\n",
      "     3        1.2941             nan     0.0100    0.0028\n",
      "     4        1.2888             nan     0.0100    0.0019\n",
      "     5        1.2826             nan     0.0100    0.0028\n",
      "     6        1.2769             nan     0.0100    0.0027\n",
      "     7        1.2712             nan     0.0100    0.0025\n",
      "     8        1.2656             nan     0.0100    0.0025\n",
      "     9        1.2599             nan     0.0100    0.0025\n",
      "    10        1.2546             nan     0.0100    0.0025\n",
      "    20        1.2053             nan     0.0100    0.0022\n",
      "    40        1.1280             nan     0.0100    0.0015\n",
      "    60        1.0692             nan     0.0100    0.0012\n",
      "    80        1.0265             nan     0.0100    0.0008\n",
      "   100        0.9910             nan     0.0100    0.0007\n",
      "   120        0.9639             nan     0.0100    0.0005\n",
      "   140        0.9415             nan     0.0100    0.0003\n",
      "   160        0.9245             nan     0.0100    0.0002\n",
      "   180        0.9102             nan     0.0100    0.0003\n",
      "   200        0.8987             nan     0.0100   -0.0000\n",
      "   220        0.8882             nan     0.0100    0.0001\n",
      "   240        0.8790             nan     0.0100    0.0001\n",
      "   260        0.8708             nan     0.0100    0.0001\n",
      "   280        0.8634             nan     0.0100    0.0000\n",
      "   300        0.8561             nan     0.0100    0.0000\n",
      "   320        0.8497             nan     0.0100   -0.0000\n",
      "   340        0.8435             nan     0.0100    0.0000\n",
      "   360        0.8373             nan     0.0100    0.0000\n",
      "   380        0.8321             nan     0.0100   -0.0000\n",
      "   400        0.8269             nan     0.0100   -0.0000\n",
      "   420        0.8223             nan     0.0100   -0.0001\n",
      "   440        0.8173             nan     0.0100    0.0000\n",
      "   460        0.8124             nan     0.0100   -0.0002\n",
      "   480        0.8075             nan     0.0100    0.0000\n",
      "   500        0.8031             nan     0.0100   -0.0001\n",
      "   520        0.7993             nan     0.0100   -0.0000\n",
      "   540        0.7952             nan     0.0100   -0.0001\n",
      "   560        0.7912             nan     0.0100   -0.0000\n",
      "   580        0.7876             nan     0.0100   -0.0000\n",
      "   600        0.7840             nan     0.0100    0.0000\n",
      "   620        0.7804             nan     0.0100   -0.0001\n",
      "   640        0.7770             nan     0.0100    0.0000\n",
      "   660        0.7735             nan     0.0100   -0.0000\n",
      "   680        0.7700             nan     0.0100   -0.0001\n",
      "   700        0.7667             nan     0.0100   -0.0001\n",
      "   720        0.7634             nan     0.0100   -0.0001\n",
      "   740        0.7606             nan     0.0100   -0.0001\n",
      "   760        0.7578             nan     0.0100   -0.0000\n",
      "   780        0.7554             nan     0.0100   -0.0001\n",
      "   800        0.7529             nan     0.0100   -0.0000\n",
      "   820        0.7502             nan     0.0100   -0.0001\n",
      "   840        0.7476             nan     0.0100   -0.0001\n",
      "   860        0.7446             nan     0.0100   -0.0000\n",
      "   880        0.7421             nan     0.0100   -0.0001\n",
      "   900        0.7397             nan     0.0100   -0.0001\n",
      "   920        0.7372             nan     0.0100   -0.0001\n",
      "   940        0.7351             nan     0.0100   -0.0000\n",
      "   960        0.7328             nan     0.0100   -0.0001\n",
      "   980        0.7306             nan     0.0100   -0.0001\n",
      "  1000        0.7281             nan     0.0100   -0.0002\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3050             nan     0.0100    0.0037\n",
      "     2        1.2971             nan     0.0100    0.0036\n",
      "     3        1.2889             nan     0.0100    0.0037\n",
      "     4        1.2814             nan     0.0100    0.0038\n",
      "     5        1.2748             nan     0.0100    0.0032\n",
      "     6        1.2681             nan     0.0100    0.0033\n",
      "     7        1.2608             nan     0.0100    0.0033\n",
      "     8        1.2540             nan     0.0100    0.0029\n",
      "     9        1.2477             nan     0.0100    0.0026\n",
      "    10        1.2410             nan     0.0100    0.0030\n",
      "    20        1.1813             nan     0.0100    0.0027\n",
      "    40        1.0868             nan     0.0100    0.0014\n",
      "    60        1.0137             nan     0.0100    0.0015\n",
      "    80        0.9580             nan     0.0100    0.0007\n",
      "   100        0.9155             nan     0.0100    0.0007\n",
      "   120        0.8802             nan     0.0100    0.0002\n",
      "   140        0.8498             nan     0.0100    0.0002\n",
      "   160        0.8246             nan     0.0100    0.0003\n",
      "   180        0.8044             nan     0.0100    0.0002\n",
      "   200        0.7859             nan     0.0100    0.0002\n",
      "   220        0.7696             nan     0.0100   -0.0001\n",
      "   240        0.7557             nan     0.0100   -0.0001\n",
      "   260        0.7418             nan     0.0100    0.0000\n",
      "   280        0.7306             nan     0.0100   -0.0001\n",
      "   300        0.7197             nan     0.0100   -0.0001\n",
      "   320        0.7082             nan     0.0100    0.0001\n",
      "   340        0.6980             nan     0.0100    0.0000\n",
      "   360        0.6880             nan     0.0100    0.0000\n",
      "   380        0.6788             nan     0.0100   -0.0002\n",
      "   400        0.6707             nan     0.0100   -0.0000\n",
      "   420        0.6625             nan     0.0100   -0.0001\n",
      "   440        0.6544             nan     0.0100   -0.0001\n",
      "   460        0.6465             nan     0.0100   -0.0001\n",
      "   480        0.6377             nan     0.0100   -0.0000\n",
      "   500        0.6292             nan     0.0100   -0.0000\n",
      "   520        0.6214             nan     0.0100    0.0000\n",
      "   540        0.6146             nan     0.0100   -0.0002\n",
      "   560        0.6083             nan     0.0100   -0.0002\n",
      "   580        0.6018             nan     0.0100   -0.0000\n",
      "   600        0.5954             nan     0.0100   -0.0001\n",
      "   620        0.5894             nan     0.0100    0.0000\n",
      "   640        0.5835             nan     0.0100   -0.0001\n",
      "   660        0.5772             nan     0.0100   -0.0001\n",
      "   680        0.5712             nan     0.0100   -0.0002\n",
      "   700        0.5648             nan     0.0100   -0.0002\n",
      "   720        0.5593             nan     0.0100   -0.0002\n",
      "   740        0.5528             nan     0.0100   -0.0002\n",
      "   760        0.5455             nan     0.0100   -0.0001\n",
      "   780        0.5401             nan     0.0100   -0.0001\n",
      "   800        0.5341             nan     0.0100   -0.0000\n",
      "   820        0.5288             nan     0.0100   -0.0002\n",
      "   840        0.5236             nan     0.0100   -0.0002\n",
      "   860        0.5184             nan     0.0100   -0.0001\n",
      "   880        0.5134             nan     0.0100   -0.0001\n",
      "   900        0.5077             nan     0.0100   -0.0001\n",
      "   920        0.5031             nan     0.0100   -0.0000\n",
      "   940        0.4984             nan     0.0100   -0.0002\n",
      "   960        0.4935             nan     0.0100   -0.0001\n",
      "   980        0.4890             nan     0.0100   -0.0001\n",
      "  1000        0.4842             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold03.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0036\n",
      "     2        1.2966             nan     0.0100    0.0038\n",
      "     3        1.2883             nan     0.0100    0.0038\n",
      "     4        1.2805             nan     0.0100    0.0032\n",
      "     5        1.2722             nan     0.0100    0.0039\n",
      "     6        1.2645             nan     0.0100    0.0031\n",
      "     7        1.2569             nan     0.0100    0.0030\n",
      "     8        1.2485             nan     0.0100    0.0034\n",
      "     9        1.2419             nan     0.0100    0.0031\n",
      "    10        1.2340             nan     0.0100    0.0032\n",
      "    20        1.1662             nan     0.0100    0.0027\n",
      "    40        1.0607             nan     0.0100    0.0022\n",
      "    60        0.9829             nan     0.0100    0.0014\n",
      "    80        0.9213             nan     0.0100    0.0011\n",
      "   100        0.8722             nan     0.0100    0.0006\n",
      "   120        0.8320             nan     0.0100    0.0004\n",
      "   140        0.7981             nan     0.0100    0.0002\n",
      "   160        0.7692             nan     0.0100    0.0004\n",
      "   180        0.7438             nan     0.0100    0.0002\n",
      "   200        0.7208             nan     0.0100   -0.0000\n",
      "   220        0.7005             nan     0.0100   -0.0001\n",
      "   240        0.6822             nan     0.0100    0.0000\n",
      "   260        0.6648             nan     0.0100    0.0001\n",
      "   280        0.6500             nan     0.0100   -0.0003\n",
      "   300        0.6352             nan     0.0100   -0.0001\n",
      "   320        0.6205             nan     0.0100   -0.0001\n",
      "   340        0.6066             nan     0.0100   -0.0002\n",
      "   360        0.5927             nan     0.0100   -0.0001\n",
      "   380        0.5812             nan     0.0100   -0.0002\n",
      "   400        0.5691             nan     0.0100   -0.0001\n",
      "   420        0.5583             nan     0.0100   -0.0001\n",
      "   440        0.5474             nan     0.0100    0.0000\n",
      "   460        0.5374             nan     0.0100   -0.0002\n",
      "   480        0.5268             nan     0.0100   -0.0001\n",
      "   500        0.5165             nan     0.0100   -0.0002\n",
      "   520        0.5059             nan     0.0100   -0.0001\n",
      "   540        0.4973             nan     0.0100   -0.0001\n",
      "   560        0.4881             nan     0.0100   -0.0002\n",
      "   580        0.4792             nan     0.0100   -0.0000\n",
      "   600        0.4707             nan     0.0100   -0.0001\n",
      "   620        0.4618             nan     0.0100   -0.0000\n",
      "   640        0.4542             nan     0.0100   -0.0002\n",
      "   660        0.4467             nan     0.0100   -0.0001\n",
      "   680        0.4395             nan     0.0100   -0.0001\n",
      "   700        0.4323             nan     0.0100   -0.0001\n",
      "   720        0.4248             nan     0.0100   -0.0001\n",
      "   740        0.4174             nan     0.0100   -0.0001\n",
      "   760        0.4107             nan     0.0100   -0.0001\n",
      "   780        0.4038             nan     0.0100   -0.0001\n",
      "   800        0.3972             nan     0.0100   -0.0001\n",
      "   820        0.3911             nan     0.0100   -0.0001\n",
      "   840        0.3847             nan     0.0100   -0.0002\n",
      "   860        0.3782             nan     0.0100    0.0000\n",
      "   880        0.3717             nan     0.0100   -0.0001\n",
      "   900        0.3659             nan     0.0100   -0.0001\n",
      "   920        0.3606             nan     0.0100   -0.0001\n",
      "   940        0.3545             nan     0.0100   -0.0001\n",
      "   960        0.3486             nan     0.0100   -0.0001\n",
      "   980        0.3425             nan     0.0100   -0.0001\n",
      "  1000        0.3375             nan     0.0100   -0.0002\n",
      "\n",
      "- Fold03.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3128             nan     0.0010    0.0003\n",
      "     2        1.3122             nan     0.0010    0.0003\n",
      "     3        1.3116             nan     0.0010    0.0003\n",
      "     4        1.3109             nan     0.0010    0.0003\n",
      "     5        1.3103             nan     0.0010    0.0003\n",
      "     6        1.3096             nan     0.0010    0.0003\n",
      "     7        1.3089             nan     0.0010    0.0003\n",
      "     8        1.3082             nan     0.0010    0.0003\n",
      "     9        1.3076             nan     0.0010    0.0003\n",
      "    10        1.3070             nan     0.0010    0.0003\n",
      "    20        1.3007             nan     0.0010    0.0003\n",
      "    40        1.2880             nan     0.0010    0.0003\n",
      "    60        1.2758             nan     0.0010    0.0003\n",
      "    80        1.2639             nan     0.0010    0.0003\n",
      "   100        1.2522             nan     0.0010    0.0003\n",
      "   120        1.2412             nan     0.0010    0.0002\n",
      "   140        1.2306             nan     0.0010    0.0002\n",
      "   160        1.2205             nan     0.0010    0.0002\n",
      "   180        1.2103             nan     0.0010    0.0002\n",
      "   200        1.2004             nan     0.0010    0.0002\n",
      "   220        1.1912             nan     0.0010    0.0002\n",
      "   240        1.1821             nan     0.0010    0.0002\n",
      "   260        1.1731             nan     0.0010    0.0002\n",
      "   280        1.1644             nan     0.0010    0.0002\n",
      "   300        1.1560             nan     0.0010    0.0002\n",
      "   320        1.1480             nan     0.0010    0.0002\n",
      "   340        1.1400             nan     0.0010    0.0002\n",
      "   360        1.1320             nan     0.0010    0.0002\n",
      "   380        1.1246             nan     0.0010    0.0002\n",
      "   400        1.1172             nan     0.0010    0.0002\n",
      "   420        1.1100             nan     0.0010    0.0002\n",
      "   440        1.1029             nan     0.0010    0.0001\n",
      "   460        1.0962             nan     0.0010    0.0002\n",
      "   480        1.0898             nan     0.0010    0.0001\n",
      "   500        1.0834             nan     0.0010    0.0001\n",
      "   520        1.0773             nan     0.0010    0.0001\n",
      "   540        1.0711             nan     0.0010    0.0001\n",
      "   560        1.0653             nan     0.0010    0.0001\n",
      "   580        1.0595             nan     0.0010    0.0001\n",
      "   600        1.0539             nan     0.0010    0.0001\n",
      "   620        1.0483             nan     0.0010    0.0001\n",
      "   640        1.0431             nan     0.0010    0.0001\n",
      "   660        1.0380             nan     0.0010    0.0001\n",
      "   680        1.0330             nan     0.0010    0.0001\n",
      "   700        1.0280             nan     0.0010    0.0001\n",
      "   720        1.0233             nan     0.0010    0.0001\n",
      "   740        1.0185             nan     0.0010    0.0001\n",
      "   760        1.0139             nan     0.0010    0.0001\n",
      "   780        1.0094             nan     0.0010    0.0001\n",
      "   800        1.0051             nan     0.0010    0.0001\n",
      "   820        1.0008             nan     0.0010    0.0001\n",
      "   840        0.9964             nan     0.0010    0.0001\n",
      "   860        0.9924             nan     0.0010    0.0000\n",
      "   880        0.9884             nan     0.0010    0.0001\n",
      "   900        0.9845             nan     0.0010    0.0001\n",
      "   920        0.9806             nan     0.0010    0.0001\n",
      "   940        0.9767             nan     0.0010    0.0001\n",
      "   960        0.9731             nan     0.0010    0.0001\n",
      "   980        0.9695             nan     0.0010    0.0001\n",
      "  1000        0.9660             nan     0.0010    0.0001\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3126             nan     0.0010    0.0004\n",
      "     2        1.3118             nan     0.0010    0.0004\n",
      "     3        1.3109             nan     0.0010    0.0004\n",
      "     4        1.3101             nan     0.0010    0.0004\n",
      "     5        1.3093             nan     0.0010    0.0004\n",
      "     6        1.3084             nan     0.0010    0.0004\n",
      "     7        1.3075             nan     0.0010    0.0004\n",
      "     8        1.3067             nan     0.0010    0.0004\n",
      "     9        1.3059             nan     0.0010    0.0004\n",
      "    10        1.3051             nan     0.0010    0.0004\n",
      "    20        1.2969             nan     0.0010    0.0004\n",
      "    40        1.2809             nan     0.0010    0.0004\n",
      "    60        1.2654             nan     0.0010    0.0003\n",
      "    80        1.2507             nan     0.0010    0.0003\n",
      "   100        1.2365             nan     0.0010    0.0003\n",
      "   120        1.2227             nan     0.0010    0.0003\n",
      "   140        1.2093             nan     0.0010    0.0003\n",
      "   160        1.1966             nan     0.0010    0.0003\n",
      "   180        1.1841             nan     0.0010    0.0002\n",
      "   200        1.1720             nan     0.0010    0.0003\n",
      "   220        1.1602             nan     0.0010    0.0002\n",
      "   240        1.1488             nan     0.0010    0.0002\n",
      "   260        1.1376             nan     0.0010    0.0002\n",
      "   280        1.1269             nan     0.0010    0.0002\n",
      "   300        1.1164             nan     0.0010    0.0002\n",
      "   320        1.1063             nan     0.0010    0.0002\n",
      "   340        1.0964             nan     0.0010    0.0002\n",
      "   360        1.0869             nan     0.0010    0.0002\n",
      "   380        1.0780             nan     0.0010    0.0002\n",
      "   400        1.0690             nan     0.0010    0.0002\n",
      "   420        1.0604             nan     0.0010    0.0002\n",
      "   440        1.0519             nan     0.0010    0.0002\n",
      "   460        1.0437             nan     0.0010    0.0001\n",
      "   480        1.0359             nan     0.0010    0.0001\n",
      "   500        1.0279             nan     0.0010    0.0002\n",
      "   520        1.0206             nan     0.0010    0.0002\n",
      "   540        1.0131             nan     0.0010    0.0002\n",
      "   560        1.0058             nan     0.0010    0.0001\n",
      "   580        0.9988             nan     0.0010    0.0001\n",
      "   600        0.9920             nan     0.0010    0.0001\n",
      "   620        0.9850             nan     0.0010    0.0001\n",
      "   640        0.9784             nan     0.0010    0.0001\n",
      "   660        0.9721             nan     0.0010    0.0001\n",
      "   680        0.9658             nan     0.0010    0.0001\n",
      "   700        0.9595             nan     0.0010    0.0001\n",
      "   720        0.9535             nan     0.0010    0.0001\n",
      "   740        0.9478             nan     0.0010    0.0001\n",
      "   760        0.9420             nan     0.0010    0.0001\n",
      "   780        0.9364             nan     0.0010    0.0001\n",
      "   800        0.9308             nan     0.0010    0.0001\n",
      "   820        0.9256             nan     0.0010    0.0001\n",
      "   840        0.9201             nan     0.0010    0.0001\n",
      "   860        0.9148             nan     0.0010    0.0001\n",
      "   880        0.9099             nan     0.0010    0.0001\n",
      "   900        0.9051             nan     0.0010    0.0001\n",
      "   920        0.9003             nan     0.0010    0.0001\n",
      "   940        0.8955             nan     0.0010    0.0001\n",
      "   960        0.8911             nan     0.0010    0.0001\n",
      "   980        0.8866             nan     0.0010    0.0001\n",
      "  1000        0.8821             nan     0.0010    0.0001\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3126             nan     0.0010    0.0004\n",
      "     2        1.3117             nan     0.0010    0.0004\n",
      "     3        1.3108             nan     0.0010    0.0004\n",
      "     4        1.3099             nan     0.0010    0.0004\n",
      "     5        1.3090             nan     0.0010    0.0004\n",
      "     6        1.3080             nan     0.0010    0.0004\n",
      "     7        1.3071             nan     0.0010    0.0004\n",
      "     8        1.3061             nan     0.0010    0.0003\n",
      "     9        1.3052             nan     0.0010    0.0004\n",
      "    10        1.3043             nan     0.0010    0.0004\n",
      "    20        1.2953             nan     0.0010    0.0004\n",
      "    40        1.2778             nan     0.0010    0.0004\n",
      "    60        1.2606             nan     0.0010    0.0003\n",
      "    80        1.2442             nan     0.0010    0.0004\n",
      "   100        1.2284             nan     0.0010    0.0003\n",
      "   120        1.2134             nan     0.0010    0.0003\n",
      "   140        1.1983             nan     0.0010    0.0004\n",
      "   160        1.1842             nan     0.0010    0.0003\n",
      "   180        1.1700             nan     0.0010    0.0003\n",
      "   200        1.1567             nan     0.0010    0.0003\n",
      "   220        1.1438             nan     0.0010    0.0002\n",
      "   240        1.1312             nan     0.0010    0.0003\n",
      "   260        1.1185             nan     0.0010    0.0003\n",
      "   280        1.1066             nan     0.0010    0.0002\n",
      "   300        1.0951             nan     0.0010    0.0003\n",
      "   320        1.0840             nan     0.0010    0.0002\n",
      "   340        1.0729             nan     0.0010    0.0002\n",
      "   360        1.0624             nan     0.0010    0.0002\n",
      "   380        1.0524             nan     0.0010    0.0002\n",
      "   400        1.0425             nan     0.0010    0.0002\n",
      "   420        1.0328             nan     0.0010    0.0002\n",
      "   440        1.0235             nan     0.0010    0.0002\n",
      "   460        1.0143             nan     0.0010    0.0001\n",
      "   480        1.0055             nan     0.0010    0.0002\n",
      "   500        0.9968             nan     0.0010    0.0002\n",
      "   520        0.9882             nan     0.0010    0.0001\n",
      "   540        0.9798             nan     0.0010    0.0002\n",
      "   560        0.9718             nan     0.0010    0.0002\n",
      "   580        0.9639             nan     0.0010    0.0002\n",
      "   600        0.9561             nan     0.0010    0.0001\n",
      "   620        0.9487             nan     0.0010    0.0001\n",
      "   640        0.9415             nan     0.0010    0.0001\n",
      "   660        0.9343             nan     0.0010    0.0001\n",
      "   680        0.9274             nan     0.0010    0.0001\n",
      "   700        0.9208             nan     0.0010    0.0001\n",
      "   720        0.9141             nan     0.0010    0.0001\n",
      "   740        0.9074             nan     0.0010    0.0001\n",
      "   760        0.9011             nan     0.0010    0.0001\n",
      "   780        0.8950             nan     0.0010    0.0001\n",
      "   800        0.8890             nan     0.0010    0.0001\n",
      "   820        0.8830             nan     0.0010    0.0001\n",
      "   840        0.8774             nan     0.0010    0.0001\n",
      "   860        0.8715             nan     0.0010    0.0001\n",
      "   880        0.8659             nan     0.0010    0.0001\n",
      "   900        0.8604             nan     0.0010    0.0001\n",
      "   920        0.8550             nan     0.0010    0.0001\n",
      "   940        0.8497             nan     0.0010    0.0001\n",
      "   960        0.8447             nan     0.0010    0.0001\n",
      "   980        0.8398             nan     0.0010    0.0001\n",
      "  1000        0.8351             nan     0.0010    0.0001\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3065             nan     0.0100    0.0029\n",
      "     2        1.3001             nan     0.0100    0.0032\n",
      "     3        1.2936             nan     0.0100    0.0029\n",
      "     4        1.2873             nan     0.0100    0.0030\n",
      "     5        1.2812             nan     0.0100    0.0030\n",
      "     6        1.2753             nan     0.0100    0.0029\n",
      "     7        1.2696             nan     0.0100    0.0028\n",
      "     8        1.2631             nan     0.0100    0.0029\n",
      "     9        1.2572             nan     0.0100    0.0028\n",
      "    10        1.2517             nan     0.0100    0.0026\n",
      "    20        1.1992             nan     0.0100    0.0022\n",
      "    40        1.1143             nan     0.0100    0.0014\n",
      "    60        1.0525             nan     0.0100    0.0013\n",
      "    80        1.0042             nan     0.0100    0.0010\n",
      "   100        0.9649             nan     0.0100    0.0008\n",
      "   120        0.9348             nan     0.0100    0.0005\n",
      "   140        0.9091             nan     0.0100    0.0005\n",
      "   160        0.8886             nan     0.0100    0.0002\n",
      "   180        0.8725             nan     0.0100    0.0003\n",
      "   200        0.8594             nan     0.0100    0.0001\n",
      "   220        0.8471             nan     0.0100    0.0002\n",
      "   240        0.8363             nan     0.0100    0.0001\n",
      "   260        0.8281             nan     0.0100    0.0001\n",
      "   280        0.8205             nan     0.0100   -0.0001\n",
      "   300        0.8126             nan     0.0100    0.0001\n",
      "   320        0.8056             nan     0.0100   -0.0000\n",
      "   340        0.7984             nan     0.0100   -0.0000\n",
      "   360        0.7908             nan     0.0100   -0.0001\n",
      "   380        0.7844             nan     0.0100    0.0000\n",
      "   400        0.7784             nan     0.0100    0.0000\n",
      "   420        0.7727             nan     0.0100    0.0000\n",
      "   440        0.7671             nan     0.0100    0.0001\n",
      "   460        0.7618             nan     0.0100    0.0000\n",
      "   480        0.7565             nan     0.0100    0.0000\n",
      "   500        0.7510             nan     0.0100    0.0000\n",
      "   520        0.7466             nan     0.0100   -0.0000\n",
      "   540        0.7420             nan     0.0100   -0.0001\n",
      "   560        0.7374             nan     0.0100   -0.0001\n",
      "   580        0.7331             nan     0.0100   -0.0001\n",
      "   600        0.7293             nan     0.0100   -0.0001\n",
      "   620        0.7254             nan     0.0100    0.0000\n",
      "   640        0.7214             nan     0.0100    0.0000\n",
      "   660        0.7174             nan     0.0100   -0.0000\n",
      "   680        0.7139             nan     0.0100   -0.0001\n",
      "   700        0.7102             nan     0.0100   -0.0000\n",
      "   720        0.7072             nan     0.0100   -0.0000\n",
      "   740        0.7035             nan     0.0100   -0.0001\n",
      "   760        0.6999             nan     0.0100   -0.0001\n",
      "   780        0.6968             nan     0.0100   -0.0001\n",
      "   800        0.6936             nan     0.0100    0.0000\n",
      "   820        0.6904             nan     0.0100   -0.0001\n",
      "   840        0.6874             nan     0.0100   -0.0001\n",
      "   860        0.6842             nan     0.0100   -0.0000\n",
      "   880        0.6814             nan     0.0100   -0.0000\n",
      "   900        0.6784             nan     0.0100   -0.0001\n",
      "   920        0.6756             nan     0.0100    0.0000\n",
      "   940        0.6730             nan     0.0100   -0.0000\n",
      "   960        0.6702             nan     0.0100   -0.0001\n",
      "   980        0.6674             nan     0.0100   -0.0001\n",
      "  1000        0.6646             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3049             nan     0.0100    0.0040\n",
      "     2        1.2970             nan     0.0100    0.0035\n",
      "     3        1.2891             nan     0.0100    0.0037\n",
      "     4        1.2814             nan     0.0100    0.0035\n",
      "     5        1.2746             nan     0.0100    0.0030\n",
      "     6        1.2670             nan     0.0100    0.0035\n",
      "     7        1.2601             nan     0.0100    0.0035\n",
      "     8        1.2526             nan     0.0100    0.0033\n",
      "     9        1.2457             nan     0.0100    0.0031\n",
      "    10        1.2377             nan     0.0100    0.0032\n",
      "    20        1.1728             nan     0.0100    0.0027\n",
      "    40        1.0674             nan     0.0100    0.0022\n",
      "    60        0.9891             nan     0.0100    0.0013\n",
      "    80        0.9281             nan     0.0100    0.0010\n",
      "   100        0.8803             nan     0.0100    0.0008\n",
      "   120        0.8402             nan     0.0100    0.0006\n",
      "   140        0.8079             nan     0.0100    0.0002\n",
      "   160        0.7795             nan     0.0100    0.0001\n",
      "   180        0.7557             nan     0.0100    0.0003\n",
      "   200        0.7358             nan     0.0100    0.0001\n",
      "   220        0.7168             nan     0.0100    0.0002\n",
      "   240        0.7020             nan     0.0100   -0.0001\n",
      "   260        0.6874             nan     0.0100    0.0001\n",
      "   280        0.6736             nan     0.0100   -0.0002\n",
      "   300        0.6609             nan     0.0100   -0.0001\n",
      "   320        0.6503             nan     0.0100    0.0000\n",
      "   340        0.6395             nan     0.0100    0.0001\n",
      "   360        0.6295             nan     0.0100    0.0001\n",
      "   380        0.6191             nan     0.0100   -0.0000\n",
      "   400        0.6103             nan     0.0100   -0.0003\n",
      "   420        0.6014             nan     0.0100   -0.0001\n",
      "   440        0.5925             nan     0.0100    0.0000\n",
      "   460        0.5841             nan     0.0100   -0.0001\n",
      "   480        0.5753             nan     0.0100   -0.0003\n",
      "   500        0.5678             nan     0.0100   -0.0001\n",
      "   520        0.5611             nan     0.0100   -0.0001\n",
      "   540        0.5541             nan     0.0100   -0.0000\n",
      "   560        0.5468             nan     0.0100   -0.0000\n",
      "   580        0.5398             nan     0.0100    0.0000\n",
      "   600        0.5317             nan     0.0100   -0.0001\n",
      "   620        0.5255             nan     0.0100   -0.0001\n",
      "   640        0.5192             nan     0.0100   -0.0001\n",
      "   660        0.5120             nan     0.0100   -0.0001\n",
      "   680        0.5053             nan     0.0100   -0.0001\n",
      "   700        0.4990             nan     0.0100   -0.0001\n",
      "   720        0.4932             nan     0.0100   -0.0002\n",
      "   740        0.4873             nan     0.0100   -0.0002\n",
      "   760        0.4812             nan     0.0100   -0.0000\n",
      "   780        0.4746             nan     0.0100   -0.0001\n",
      "   800        0.4689             nan     0.0100   -0.0001\n",
      "   820        0.4633             nan     0.0100   -0.0002\n",
      "   840        0.4577             nan     0.0100   -0.0002\n",
      "   860        0.4523             nan     0.0100   -0.0001\n",
      "   880        0.4470             nan     0.0100   -0.0000\n",
      "   900        0.4416             nan     0.0100   -0.0001\n",
      "   920        0.4376             nan     0.0100   -0.0001\n",
      "   940        0.4328             nan     0.0100   -0.0001\n",
      "   960        0.4278             nan     0.0100   -0.0001\n",
      "   980        0.4237             nan     0.0100   -0.0000\n",
      "  1000        0.4186             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold04.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3037             nan     0.0100    0.0036\n",
      "     2        1.2949             nan     0.0100    0.0038\n",
      "     3        1.2858             nan     0.0100    0.0038\n",
      "     4        1.2776             nan     0.0100    0.0034\n",
      "     5        1.2686             nan     0.0100    0.0043\n",
      "     6        1.2604             nan     0.0100    0.0038\n",
      "     7        1.2529             nan     0.0100    0.0030\n",
      "     8        1.2448             nan     0.0100    0.0033\n",
      "     9        1.2371             nan     0.0100    0.0033\n",
      "    10        1.2285             nan     0.0100    0.0038\n",
      "    20        1.1567             nan     0.0100    0.0032\n",
      "    40        1.0403             nan     0.0100    0.0019\n",
      "    60        0.9550             nan     0.0100    0.0014\n",
      "    80        0.8862             nan     0.0100    0.0011\n",
      "   100        0.8317             nan     0.0100    0.0008\n",
      "   120        0.7870             nan     0.0100    0.0006\n",
      "   140        0.7503             nan     0.0100    0.0007\n",
      "   160        0.7186             nan     0.0100    0.0004\n",
      "   180        0.6910             nan     0.0100    0.0002\n",
      "   200        0.6668             nan     0.0100    0.0002\n",
      "   220        0.6447             nan     0.0100    0.0002\n",
      "   240        0.6257             nan     0.0100    0.0001\n",
      "   260        0.6085             nan     0.0100   -0.0002\n",
      "   280        0.5909             nan     0.0100   -0.0000\n",
      "   300        0.5749             nan     0.0100   -0.0001\n",
      "   320        0.5610             nan     0.0100   -0.0002\n",
      "   340        0.5467             nan     0.0100    0.0000\n",
      "   360        0.5319             nan     0.0100   -0.0002\n",
      "   380        0.5188             nan     0.0100   -0.0000\n",
      "   400        0.5077             nan     0.0100   -0.0001\n",
      "   420        0.4964             nan     0.0100   -0.0001\n",
      "   440        0.4858             nan     0.0100   -0.0002\n",
      "   460        0.4753             nan     0.0100   -0.0001\n",
      "   480        0.4651             nan     0.0100   -0.0001\n",
      "   500        0.4560             nan     0.0100    0.0000\n",
      "   520        0.4463             nan     0.0100   -0.0002\n",
      "   540        0.4370             nan     0.0100   -0.0001\n",
      "   560        0.4287             nan     0.0100   -0.0000\n",
      "   580        0.4191             nan     0.0100   -0.0000\n",
      "   600        0.4105             nan     0.0100   -0.0001\n",
      "   620        0.4024             nan     0.0100   -0.0001\n",
      "   640        0.3943             nan     0.0100   -0.0001\n",
      "   660        0.3862             nan     0.0100   -0.0001\n",
      "   680        0.3798             nan     0.0100   -0.0001\n",
      "   700        0.3726             nan     0.0100   -0.0001\n",
      "   720        0.3654             nan     0.0100   -0.0001\n",
      "   740        0.3575             nan     0.0100    0.0000\n",
      "   760        0.3500             nan     0.0100    0.0001\n",
      "   780        0.3438             nan     0.0100   -0.0001\n",
      "   800        0.3376             nan     0.0100   -0.0001\n",
      "   820        0.3306             nan     0.0100   -0.0001\n",
      "   840        0.3245             nan     0.0100   -0.0000\n",
      "   860        0.3186             nan     0.0100   -0.0002\n",
      "   880        0.3127             nan     0.0100   -0.0001\n",
      "   900        0.3071             nan     0.0100    0.0000\n",
      "   920        0.3012             nan     0.0100   -0.0001\n",
      "   940        0.2953             nan     0.0100   -0.0000\n",
      "   960        0.2902             nan     0.0100   -0.0001\n",
      "   980        0.2846             nan     0.0100   -0.0001\n",
      "  1000        0.2798             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold04.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3123             nan     0.0010    0.0003\n",
      "     2        1.3118             nan     0.0010    0.0003\n",
      "     3        1.3111             nan     0.0010    0.0003\n",
      "     4        1.3105             nan     0.0010    0.0003\n",
      "     5        1.3098             nan     0.0010    0.0003\n",
      "     6        1.3092             nan     0.0010    0.0003\n",
      "     7        1.3085             nan     0.0010    0.0002\n",
      "     8        1.3079             nan     0.0010    0.0003\n",
      "     9        1.3073             nan     0.0010    0.0003\n",
      "    10        1.3067             nan     0.0010    0.0003\n",
      "    20        1.3007             nan     0.0010    0.0003\n",
      "    40        1.2886             nan     0.0010    0.0003\n",
      "    60        1.2771             nan     0.0010    0.0003\n",
      "    80        1.2662             nan     0.0010    0.0003\n",
      "   100        1.2556             nan     0.0010    0.0003\n",
      "   120        1.2453             nan     0.0010    0.0002\n",
      "   140        1.2352             nan     0.0010    0.0002\n",
      "   160        1.2253             nan     0.0010    0.0002\n",
      "   180        1.2159             nan     0.0010    0.0002\n",
      "   200        1.2067             nan     0.0010    0.0002\n",
      "   220        1.1977             nan     0.0010    0.0002\n",
      "   240        1.1890             nan     0.0010    0.0002\n",
      "   260        1.1804             nan     0.0010    0.0002\n",
      "   280        1.1723             nan     0.0010    0.0002\n",
      "   300        1.1644             nan     0.0010    0.0002\n",
      "   320        1.1568             nan     0.0010    0.0002\n",
      "   340        1.1496             nan     0.0010    0.0002\n",
      "   360        1.1423             nan     0.0010    0.0002\n",
      "   380        1.1351             nan     0.0010    0.0002\n",
      "   400        1.1281             nan     0.0010    0.0002\n",
      "   420        1.1214             nan     0.0010    0.0001\n",
      "   440        1.1149             nan     0.0010    0.0001\n",
      "   460        1.1084             nan     0.0010    0.0001\n",
      "   480        1.1022             nan     0.0010    0.0001\n",
      "   500        1.0964             nan     0.0010    0.0001\n",
      "   520        1.0905             nan     0.0010    0.0001\n",
      "   540        1.0846             nan     0.0010    0.0001\n",
      "   560        1.0791             nan     0.0010    0.0001\n",
      "   580        1.0736             nan     0.0010    0.0001\n",
      "   600        1.0682             nan     0.0010    0.0001\n",
      "   620        1.0631             nan     0.0010    0.0001\n",
      "   640        1.0582             nan     0.0010    0.0001\n",
      "   660        1.0533             nan     0.0010    0.0001\n",
      "   680        1.0486             nan     0.0010    0.0001\n",
      "   700        1.0440             nan     0.0010    0.0001\n",
      "   720        1.0395             nan     0.0010    0.0001\n",
      "   740        1.0351             nan     0.0010    0.0001\n",
      "   760        1.0308             nan     0.0010    0.0001\n",
      "   780        1.0265             nan     0.0010    0.0001\n",
      "   800        1.0224             nan     0.0010    0.0001\n",
      "   820        1.0183             nan     0.0010    0.0001\n",
      "   840        1.0144             nan     0.0010    0.0001\n",
      "   860        1.0105             nan     0.0010    0.0001\n",
      "   880        1.0067             nan     0.0010    0.0001\n",
      "   900        1.0029             nan     0.0010    0.0001\n",
      "   920        0.9993             nan     0.0010    0.0001\n",
      "   940        0.9959             nan     0.0010    0.0001\n",
      "   960        0.9925             nan     0.0010    0.0001\n",
      "   980        0.9892             nan     0.0010    0.0001\n",
      "  1000        0.9859             nan     0.0010    0.0001\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3121             nan     0.0010    0.0004\n",
      "     2        1.3114             nan     0.0010    0.0003\n",
      "     3        1.3105             nan     0.0010    0.0004\n",
      "     4        1.3098             nan     0.0010    0.0003\n",
      "     5        1.3089             nan     0.0010    0.0004\n",
      "     6        1.3082             nan     0.0010    0.0003\n",
      "     7        1.3074             nan     0.0010    0.0004\n",
      "     8        1.3066             nan     0.0010    0.0004\n",
      "     9        1.3058             nan     0.0010    0.0004\n",
      "    10        1.3049             nan     0.0010    0.0003\n",
      "    20        1.2974             nan     0.0010    0.0003\n",
      "    40        1.2826             nan     0.0010    0.0004\n",
      "    60        1.2680             nan     0.0010    0.0003\n",
      "    80        1.2542             nan     0.0010    0.0003\n",
      "   100        1.2406             nan     0.0010    0.0002\n",
      "   120        1.2275             nan     0.0010    0.0003\n",
      "   140        1.2147             nan     0.0010    0.0003\n",
      "   160        1.2024             nan     0.0010    0.0003\n",
      "   180        1.1906             nan     0.0010    0.0003\n",
      "   200        1.1790             nan     0.0010    0.0003\n",
      "   220        1.1678             nan     0.0010    0.0003\n",
      "   240        1.1568             nan     0.0010    0.0003\n",
      "   260        1.1464             nan     0.0010    0.0003\n",
      "   280        1.1360             nan     0.0010    0.0002\n",
      "   300        1.1261             nan     0.0010    0.0002\n",
      "   320        1.1165             nan     0.0010    0.0002\n",
      "   340        1.1073             nan     0.0010    0.0002\n",
      "   360        1.0984             nan     0.0010    0.0002\n",
      "   380        1.0895             nan     0.0010    0.0002\n",
      "   400        1.0809             nan     0.0010    0.0002\n",
      "   420        1.0730             nan     0.0010    0.0002\n",
      "   440        1.0650             nan     0.0010    0.0001\n",
      "   460        1.0569             nan     0.0010    0.0001\n",
      "   480        1.0490             nan     0.0010    0.0002\n",
      "   500        1.0414             nan     0.0010    0.0002\n",
      "   520        1.0344             nan     0.0010    0.0001\n",
      "   540        1.0274             nan     0.0010    0.0001\n",
      "   560        1.0204             nan     0.0010    0.0001\n",
      "   580        1.0137             nan     0.0010    0.0001\n",
      "   600        1.0070             nan     0.0010    0.0002\n",
      "   620        1.0009             nan     0.0010    0.0001\n",
      "   640        0.9947             nan     0.0010    0.0001\n",
      "   660        0.9886             nan     0.0010    0.0001\n",
      "   680        0.9829             nan     0.0010    0.0001\n",
      "   700        0.9770             nan     0.0010    0.0001\n",
      "   720        0.9715             nan     0.0010    0.0001\n",
      "   740        0.9659             nan     0.0010    0.0001\n",
      "   760        0.9605             nan     0.0010    0.0001\n",
      "   780        0.9551             nan     0.0010    0.0001\n",
      "   800        0.9500             nan     0.0010    0.0001\n",
      "   820        0.9449             nan     0.0010    0.0001\n",
      "   840        0.9401             nan     0.0010    0.0001\n",
      "   860        0.9352             nan     0.0010    0.0001\n",
      "   880        0.9306             nan     0.0010    0.0001\n",
      "   900        0.9260             nan     0.0010    0.0001\n",
      "   920        0.9214             nan     0.0010    0.0001\n",
      "   940        0.9168             nan     0.0010    0.0001\n",
      "   960        0.9125             nan     0.0010    0.0001\n",
      "   980        0.9082             nan     0.0010    0.0001\n",
      "  1000        0.9041             nan     0.0010    0.0001\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3120             nan     0.0010    0.0004\n",
      "     2        1.3111             nan     0.0010    0.0004\n",
      "     3        1.3103             nan     0.0010    0.0004\n",
      "     4        1.3094             nan     0.0010    0.0003\n",
      "     5        1.3085             nan     0.0010    0.0004\n",
      "     6        1.3078             nan     0.0010    0.0003\n",
      "     7        1.3068             nan     0.0010    0.0004\n",
      "     8        1.3059             nan     0.0010    0.0004\n",
      "     9        1.3051             nan     0.0010    0.0004\n",
      "    10        1.3042             nan     0.0010    0.0004\n",
      "    20        1.2957             nan     0.0010    0.0004\n",
      "    40        1.2787             nan     0.0010    0.0004\n",
      "    60        1.2625             nan     0.0010    0.0003\n",
      "    80        1.2472             nan     0.0010    0.0003\n",
      "   100        1.2322             nan     0.0010    0.0003\n",
      "   120        1.2178             nan     0.0010    0.0003\n",
      "   140        1.2040             nan     0.0010    0.0003\n",
      "   160        1.1903             nan     0.0010    0.0003\n",
      "   180        1.1773             nan     0.0010    0.0003\n",
      "   200        1.1644             nan     0.0010    0.0003\n",
      "   220        1.1520             nan     0.0010    0.0003\n",
      "   240        1.1396             nan     0.0010    0.0003\n",
      "   260        1.1280             nan     0.0010    0.0002\n",
      "   280        1.1167             nan     0.0010    0.0003\n",
      "   300        1.1060             nan     0.0010    0.0002\n",
      "   320        1.0953             nan     0.0010    0.0003\n",
      "   340        1.0850             nan     0.0010    0.0002\n",
      "   360        1.0749             nan     0.0010    0.0002\n",
      "   380        1.0649             nan     0.0010    0.0002\n",
      "   400        1.0555             nan     0.0010    0.0002\n",
      "   420        1.0463             nan     0.0010    0.0002\n",
      "   440        1.0374             nan     0.0010    0.0002\n",
      "   460        1.0286             nan     0.0010    0.0002\n",
      "   480        1.0202             nan     0.0010    0.0001\n",
      "   500        1.0122             nan     0.0010    0.0002\n",
      "   520        1.0042             nan     0.0010    0.0002\n",
      "   540        0.9964             nan     0.0010    0.0001\n",
      "   560        0.9886             nan     0.0010    0.0001\n",
      "   580        0.9813             nan     0.0010    0.0001\n",
      "   600        0.9739             nan     0.0010    0.0001\n",
      "   620        0.9668             nan     0.0010    0.0001\n",
      "   640        0.9599             nan     0.0010    0.0001\n",
      "   660        0.9529             nan     0.0010    0.0001\n",
      "   680        0.9462             nan     0.0010    0.0001\n",
      "   700        0.9398             nan     0.0010    0.0001\n",
      "   720        0.9333             nan     0.0010    0.0001\n",
      "   740        0.9271             nan     0.0010    0.0001\n",
      "   760        0.9212             nan     0.0010    0.0001\n",
      "   780        0.9153             nan     0.0010    0.0001\n",
      "   800        0.9093             nan     0.0010    0.0001\n",
      "   820        0.9036             nan     0.0010    0.0001\n",
      "   840        0.8982             nan     0.0010    0.0001\n",
      "   860        0.8930             nan     0.0010    0.0001\n",
      "   880        0.8877             nan     0.0010    0.0001\n",
      "   900        0.8825             nan     0.0010    0.0001\n",
      "   920        0.8775             nan     0.0010    0.0001\n",
      "   940        0.8727             nan     0.0010    0.0001\n",
      "   960        0.8679             nan     0.0010    0.0001\n",
      "   980        0.8633             nan     0.0010    0.0001\n",
      "  1000        0.8584             nan     0.0010    0.0001\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3059             nan     0.0100    0.0028\n",
      "     2        1.3000             nan     0.0100    0.0030\n",
      "     3        1.2941             nan     0.0100    0.0028\n",
      "     4        1.2880             nan     0.0100    0.0026\n",
      "     5        1.2823             nan     0.0100    0.0026\n",
      "     6        1.2771             nan     0.0100    0.0027\n",
      "     7        1.2719             nan     0.0100    0.0026\n",
      "     8        1.2667             nan     0.0100    0.0027\n",
      "     9        1.2608             nan     0.0100    0.0026\n",
      "    10        1.2558             nan     0.0100    0.0025\n",
      "    20        1.2088             nan     0.0100    0.0021\n",
      "    40        1.1313             nan     0.0100    0.0016\n",
      "    60        1.0723             nan     0.0100    0.0012\n",
      "    80        1.0262             nan     0.0100    0.0009\n",
      "   100        0.9885             nan     0.0100    0.0007\n",
      "   120        0.9583             nan     0.0100    0.0005\n",
      "   140        0.9353             nan     0.0100    0.0004\n",
      "   160        0.9159             nan     0.0100    0.0003\n",
      "   180        0.9015             nan     0.0100    0.0003\n",
      "   200        0.8889             nan     0.0100    0.0002\n",
      "   220        0.8789             nan     0.0100   -0.0000\n",
      "   240        0.8693             nan     0.0100   -0.0001\n",
      "   260        0.8603             nan     0.0100    0.0001\n",
      "   280        0.8525             nan     0.0100    0.0001\n",
      "   300        0.8452             nan     0.0100   -0.0000\n",
      "   320        0.8378             nan     0.0100    0.0000\n",
      "   340        0.8311             nan     0.0100    0.0001\n",
      "   360        0.8248             nan     0.0100   -0.0001\n",
      "   380        0.8190             nan     0.0100    0.0001\n",
      "   400        0.8131             nan     0.0100   -0.0001\n",
      "   420        0.8073             nan     0.0100   -0.0000\n",
      "   440        0.8021             nan     0.0100   -0.0000\n",
      "   460        0.7971             nan     0.0100   -0.0000\n",
      "   480        0.7923             nan     0.0100   -0.0000\n",
      "   500        0.7877             nan     0.0100    0.0000\n",
      "   520        0.7828             nan     0.0100   -0.0000\n",
      "   540        0.7782             nan     0.0100   -0.0000\n",
      "   560        0.7739             nan     0.0100    0.0000\n",
      "   580        0.7698             nan     0.0100   -0.0001\n",
      "   600        0.7658             nan     0.0100    0.0000\n",
      "   620        0.7617             nan     0.0100   -0.0000\n",
      "   640        0.7575             nan     0.0100   -0.0001\n",
      "   660        0.7539             nan     0.0100    0.0000\n",
      "   680        0.7498             nan     0.0100   -0.0000\n",
      "   700        0.7462             nan     0.0100   -0.0001\n",
      "   720        0.7428             nan     0.0100   -0.0001\n",
      "   740        0.7395             nan     0.0100   -0.0001\n",
      "   760        0.7363             nan     0.0100   -0.0000\n",
      "   780        0.7330             nan     0.0100    0.0000\n",
      "   800        0.7297             nan     0.0100   -0.0001\n",
      "   820        0.7270             nan     0.0100   -0.0000\n",
      "   840        0.7239             nan     0.0100   -0.0001\n",
      "   860        0.7211             nan     0.0100   -0.0001\n",
      "   880        0.7183             nan     0.0100    0.0000\n",
      "   900        0.7155             nan     0.0100   -0.0001\n",
      "   920        0.7127             nan     0.0100   -0.0000\n",
      "   940        0.7095             nan     0.0100   -0.0000\n",
      "   960        0.7066             nan     0.0100    0.0000\n",
      "   980        0.7045             nan     0.0100   -0.0000\n",
      "  1000        0.7021             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3047             nan     0.0100    0.0040\n",
      "     2        1.2970             nan     0.0100    0.0034\n",
      "     3        1.2890             nan     0.0100    0.0036\n",
      "     4        1.2811             nan     0.0100    0.0035\n",
      "     5        1.2738             nan     0.0100    0.0033\n",
      "     6        1.2664             nan     0.0100    0.0036\n",
      "     7        1.2591             nan     0.0100    0.0032\n",
      "     8        1.2520             nan     0.0100    0.0033\n",
      "     9        1.2445             nan     0.0100    0.0033\n",
      "    10        1.2377             nan     0.0100    0.0032\n",
      "    20        1.1765             nan     0.0100    0.0026\n",
      "    40        1.0784             nan     0.0100    0.0016\n",
      "    60        1.0036             nan     0.0100    0.0014\n",
      "    80        0.9477             nan     0.0100    0.0008\n",
      "   100        0.9026             nan     0.0100    0.0007\n",
      "   120        0.8658             nan     0.0100    0.0004\n",
      "   140        0.8350             nan     0.0100    0.0005\n",
      "   160        0.8083             nan     0.0100    0.0003\n",
      "   180        0.7858             nan     0.0100    0.0003\n",
      "   200        0.7670             nan     0.0100    0.0001\n",
      "   220        0.7495             nan     0.0100    0.0000\n",
      "   240        0.7346             nan     0.0100   -0.0001\n",
      "   260        0.7209             nan     0.0100    0.0000\n",
      "   280        0.7088             nan     0.0100   -0.0001\n",
      "   300        0.6966             nan     0.0100    0.0000\n",
      "   320        0.6853             nan     0.0100    0.0001\n",
      "   340        0.6745             nan     0.0100   -0.0001\n",
      "   360        0.6642             nan     0.0100    0.0001\n",
      "   380        0.6553             nan     0.0100   -0.0002\n",
      "   400        0.6471             nan     0.0100   -0.0000\n",
      "   420        0.6384             nan     0.0100   -0.0001\n",
      "   440        0.6288             nan     0.0100   -0.0000\n",
      "   460        0.6208             nan     0.0100   -0.0001\n",
      "   480        0.6134             nan     0.0100   -0.0001\n",
      "   500        0.6054             nan     0.0100   -0.0001\n",
      "   520        0.5985             nan     0.0100   -0.0002\n",
      "   540        0.5911             nan     0.0100   -0.0001\n",
      "   560        0.5839             nan     0.0100   -0.0001\n",
      "   580        0.5767             nan     0.0100   -0.0002\n",
      "   600        0.5698             nan     0.0100   -0.0000\n",
      "   620        0.5627             nan     0.0100   -0.0001\n",
      "   640        0.5558             nan     0.0100   -0.0002\n",
      "   660        0.5495             nan     0.0100   -0.0000\n",
      "   680        0.5443             nan     0.0100   -0.0001\n",
      "   700        0.5385             nan     0.0100    0.0000\n",
      "   720        0.5325             nan     0.0100   -0.0001\n",
      "   740        0.5268             nan     0.0100   -0.0001\n",
      "   760        0.5209             nan     0.0100   -0.0000\n",
      "   780        0.5153             nan     0.0100   -0.0000\n",
      "   800        0.5093             nan     0.0100   -0.0000\n",
      "   820        0.5033             nan     0.0100   -0.0001\n",
      "   840        0.4970             nan     0.0100   -0.0000\n",
      "   860        0.4911             nan     0.0100   -0.0001\n",
      "   880        0.4861             nan     0.0100   -0.0001\n",
      "   900        0.4813             nan     0.0100   -0.0002\n",
      "   920        0.4765             nan     0.0100    0.0000\n",
      "   940        0.4720             nan     0.0100   -0.0001\n",
      "   960        0.4671             nan     0.0100   -0.0000\n",
      "   980        0.4623             nan     0.0100   -0.0000\n",
      "  1000        0.4583             nan     0.0100   -0.0002\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold05.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3041             nan     0.0100    0.0039\n",
      "     2        1.2950             nan     0.0100    0.0040\n",
      "     3        1.2860             nan     0.0100    0.0041\n",
      "     4        1.2778             nan     0.0100    0.0035\n",
      "     5        1.2695             nan     0.0100    0.0038\n",
      "     6        1.2621             nan     0.0100    0.0035\n",
      "     7        1.2540             nan     0.0100    0.0037\n",
      "     8        1.2462             nan     0.0100    0.0033\n",
      "     9        1.2390             nan     0.0100    0.0033\n",
      "    10        1.2327             nan     0.0100    0.0023\n",
      "    20        1.1656             nan     0.0100    0.0027\n",
      "    40        1.0558             nan     0.0100    0.0015\n",
      "    60        0.9746             nan     0.0100    0.0015\n",
      "    80        0.9093             nan     0.0100    0.0010\n",
      "   100        0.8601             nan     0.0100    0.0007\n",
      "   120        0.8175             nan     0.0100    0.0005\n",
      "   140        0.7816             nan     0.0100    0.0004\n",
      "   160        0.7498             nan     0.0100    0.0003\n",
      "   180        0.7245             nan     0.0100    0.0001\n",
      "   200        0.7010             nan     0.0100    0.0002\n",
      "   220        0.6800             nan     0.0100    0.0001\n",
      "   240        0.6595             nan     0.0100    0.0003\n",
      "   260        0.6424             nan     0.0100   -0.0001\n",
      "   280        0.6254             nan     0.0100   -0.0000\n",
      "   300        0.6085             nan     0.0100   -0.0002\n",
      "   320        0.5937             nan     0.0100    0.0001\n",
      "   340        0.5794             nan     0.0100   -0.0001\n",
      "   360        0.5660             nan     0.0100   -0.0001\n",
      "   380        0.5531             nan     0.0100   -0.0000\n",
      "   400        0.5409             nan     0.0100    0.0000\n",
      "   420        0.5299             nan     0.0100   -0.0002\n",
      "   440        0.5201             nan     0.0100   -0.0002\n",
      "   460        0.5100             nan     0.0100   -0.0001\n",
      "   480        0.5010             nan     0.0100    0.0000\n",
      "   500        0.4900             nan     0.0100   -0.0001\n",
      "   520        0.4803             nan     0.0100   -0.0000\n",
      "   540        0.4718             nan     0.0100   -0.0001\n",
      "   560        0.4641             nan     0.0100   -0.0000\n",
      "   580        0.4562             nan     0.0100   -0.0001\n",
      "   600        0.4469             nan     0.0100   -0.0001\n",
      "   620        0.4379             nan     0.0100   -0.0002\n",
      "   640        0.4299             nan     0.0100   -0.0002\n",
      "   660        0.4226             nan     0.0100   -0.0001\n",
      "   680        0.4153             nan     0.0100   -0.0001\n",
      "   700        0.4075             nan     0.0100   -0.0001\n",
      "   720        0.4004             nan     0.0100   -0.0002\n",
      "   740        0.3929             nan     0.0100   -0.0001\n",
      "   760        0.3857             nan     0.0100   -0.0001\n",
      "   780        0.3789             nan     0.0100   -0.0000\n",
      "   800        0.3728             nan     0.0100   -0.0002\n",
      "   820        0.3658             nan     0.0100   -0.0001\n",
      "   840        0.3594             nan     0.0100   -0.0002\n",
      "   860        0.3532             nan     0.0100   -0.0001\n",
      "   880        0.3473             nan     0.0100   -0.0001\n",
      "   900        0.3413             nan     0.0100   -0.0002\n",
      "   920        0.3351             nan     0.0100   -0.0001\n",
      "   940        0.3295             nan     0.0100   -0.0001\n",
      "   960        0.3239             nan     0.0100   -0.0001\n",
      "   980        0.3189             nan     0.0100   -0.0001\n",
      "  1000        0.3138             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold05.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3118             nan     0.0010    0.0003\n",
      "     2        1.3112             nan     0.0010    0.0003\n",
      "     3        1.3105             nan     0.0010    0.0003\n",
      "     4        1.3099             nan     0.0010    0.0003\n",
      "     5        1.3093             nan     0.0010    0.0003\n",
      "     6        1.3087             nan     0.0010    0.0003\n",
      "     7        1.3081             nan     0.0010    0.0003\n",
      "     8        1.3075             nan     0.0010    0.0003\n",
      "     9        1.3069             nan     0.0010    0.0003\n",
      "    10        1.3062             nan     0.0010    0.0003\n",
      "    20        1.3004             nan     0.0010    0.0003\n",
      "    40        1.2887             nan     0.0010    0.0003\n",
      "    60        1.2776             nan     0.0010    0.0002\n",
      "    80        1.2669             nan     0.0010    0.0002\n",
      "   100        1.2562             nan     0.0010    0.0002\n",
      "   120        1.2460             nan     0.0010    0.0002\n",
      "   140        1.2361             nan     0.0010    0.0002\n",
      "   160        1.2266             nan     0.0010    0.0002\n",
      "   180        1.2175             nan     0.0010    0.0002\n",
      "   200        1.2086             nan     0.0010    0.0002\n",
      "   220        1.1998             nan     0.0010    0.0002\n",
      "   240        1.1913             nan     0.0010    0.0002\n",
      "   260        1.1832             nan     0.0010    0.0002\n",
      "   280        1.1752             nan     0.0010    0.0002\n",
      "   300        1.1674             nan     0.0010    0.0002\n",
      "   320        1.1596             nan     0.0010    0.0002\n",
      "   340        1.1521             nan     0.0010    0.0002\n",
      "   360        1.1450             nan     0.0010    0.0002\n",
      "   380        1.1383             nan     0.0010    0.0002\n",
      "   400        1.1315             nan     0.0010    0.0001\n",
      "   420        1.1250             nan     0.0010    0.0001\n",
      "   440        1.1186             nan     0.0010    0.0001\n",
      "   460        1.1124             nan     0.0010    0.0001\n",
      "   480        1.1066             nan     0.0010    0.0001\n",
      "   500        1.1008             nan     0.0010    0.0001\n",
      "   520        1.0950             nan     0.0010    0.0001\n",
      "   540        1.0894             nan     0.0010    0.0001\n",
      "   560        1.0841             nan     0.0010    0.0001\n",
      "   580        1.0788             nan     0.0010    0.0001\n",
      "   600        1.0737             nan     0.0010    0.0001\n",
      "   620        1.0686             nan     0.0010    0.0001\n",
      "   640        1.0635             nan     0.0010    0.0001\n",
      "   660        1.0588             nan     0.0010    0.0001\n",
      "   680        1.0541             nan     0.0010    0.0001\n",
      "   700        1.0495             nan     0.0010    0.0001\n",
      "   720        1.0451             nan     0.0010    0.0001\n",
      "   740        1.0409             nan     0.0010    0.0001\n",
      "   760        1.0367             nan     0.0010    0.0001\n",
      "   780        1.0327             nan     0.0010    0.0001\n",
      "   800        1.0286             nan     0.0010    0.0001\n",
      "   820        1.0247             nan     0.0010    0.0001\n",
      "   840        1.0208             nan     0.0010    0.0001\n",
      "   860        1.0169             nan     0.0010    0.0001\n",
      "   880        1.0132             nan     0.0010    0.0001\n",
      "   900        1.0097             nan     0.0010    0.0001\n",
      "   920        1.0061             nan     0.0010    0.0001\n",
      "   940        1.0027             nan     0.0010    0.0001\n",
      "   960        0.9994             nan     0.0010    0.0001\n",
      "   980        0.9961             nan     0.0010    0.0001\n",
      "  1000        0.9929             nan     0.0010    0.0000\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3117             nan     0.0010    0.0003\n",
      "     2        1.3109             nan     0.0010    0.0004\n",
      "     3        1.3101             nan     0.0010    0.0004\n",
      "     4        1.3094             nan     0.0010    0.0004\n",
      "     5        1.3086             nan     0.0010    0.0004\n",
      "     6        1.3079             nan     0.0010    0.0003\n",
      "     7        1.3071             nan     0.0010    0.0003\n",
      "     8        1.3063             nan     0.0010    0.0003\n",
      "     9        1.3055             nan     0.0010    0.0004\n",
      "    10        1.3048             nan     0.0010    0.0003\n",
      "    20        1.2971             nan     0.0010    0.0004\n",
      "    40        1.2822             nan     0.0010    0.0003\n",
      "    60        1.2680             nan     0.0010    0.0003\n",
      "    80        1.2545             nan     0.0010    0.0003\n",
      "   100        1.2413             nan     0.0010    0.0003\n",
      "   120        1.2286             nan     0.0010    0.0003\n",
      "   140        1.2162             nan     0.0010    0.0002\n",
      "   160        1.2041             nan     0.0010    0.0003\n",
      "   180        1.1921             nan     0.0010    0.0003\n",
      "   200        1.1806             nan     0.0010    0.0002\n",
      "   220        1.1697             nan     0.0010    0.0002\n",
      "   240        1.1592             nan     0.0010    0.0002\n",
      "   260        1.1489             nan     0.0010    0.0002\n",
      "   280        1.1387             nan     0.0010    0.0002\n",
      "   300        1.1290             nan     0.0010    0.0002\n",
      "   320        1.1198             nan     0.0010    0.0002\n",
      "   340        1.1107             nan     0.0010    0.0002\n",
      "   360        1.1018             nan     0.0010    0.0002\n",
      "   380        1.0932             nan     0.0010    0.0001\n",
      "   400        1.0848             nan     0.0010    0.0002\n",
      "   420        1.0766             nan     0.0010    0.0002\n",
      "   440        1.0687             nan     0.0010    0.0002\n",
      "   460        1.0611             nan     0.0010    0.0001\n",
      "   480        1.0537             nan     0.0010    0.0002\n",
      "   500        1.0463             nan     0.0010    0.0001\n",
      "   520        1.0390             nan     0.0010    0.0002\n",
      "   540        1.0320             nan     0.0010    0.0001\n",
      "   560        1.0251             nan     0.0010    0.0002\n",
      "   580        1.0184             nan     0.0010    0.0001\n",
      "   600        1.0120             nan     0.0010    0.0001\n",
      "   620        1.0058             nan     0.0010    0.0001\n",
      "   640        0.9996             nan     0.0010    0.0001\n",
      "   660        0.9936             nan     0.0010    0.0001\n",
      "   680        0.9877             nan     0.0010    0.0001\n",
      "   700        0.9819             nan     0.0010    0.0001\n",
      "   720        0.9763             nan     0.0010    0.0001\n",
      "   740        0.9706             nan     0.0010    0.0001\n",
      "   760        0.9653             nan     0.0010    0.0001\n",
      "   780        0.9600             nan     0.0010    0.0001\n",
      "   800        0.9549             nan     0.0010    0.0001\n",
      "   820        0.9499             nan     0.0010    0.0001\n",
      "   840        0.9448             nan     0.0010    0.0001\n",
      "   860        0.9401             nan     0.0010    0.0001\n",
      "   880        0.9354             nan     0.0010    0.0001\n",
      "   900        0.9309             nan     0.0010    0.0001\n",
      "   920        0.9265             nan     0.0010    0.0001\n",
      "   940        0.9221             nan     0.0010    0.0001\n",
      "   960        0.9177             nan     0.0010    0.0001\n",
      "   980        0.9135             nan     0.0010    0.0001\n",
      "  1000        0.9094             nan     0.0010    0.0001\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3116             nan     0.0010    0.0004\n",
      "     2        1.3108             nan     0.0010    0.0004\n",
      "     3        1.3099             nan     0.0010    0.0004\n",
      "     4        1.3090             nan     0.0010    0.0004\n",
      "     5        1.3081             nan     0.0010    0.0004\n",
      "     6        1.3073             nan     0.0010    0.0004\n",
      "     7        1.3064             nan     0.0010    0.0004\n",
      "     8        1.3056             nan     0.0010    0.0004\n",
      "     9        1.3047             nan     0.0010    0.0004\n",
      "    10        1.3038             nan     0.0010    0.0004\n",
      "    20        1.2953             nan     0.0010    0.0004\n",
      "    40        1.2787             nan     0.0010    0.0004\n",
      "    60        1.2626             nan     0.0010    0.0004\n",
      "    80        1.2475             nan     0.0010    0.0003\n",
      "   100        1.2326             nan     0.0010    0.0003\n",
      "   120        1.2182             nan     0.0010    0.0003\n",
      "   140        1.2044             nan     0.0010    0.0003\n",
      "   160        1.1909             nan     0.0010    0.0002\n",
      "   180        1.1779             nan     0.0010    0.0003\n",
      "   200        1.1653             nan     0.0010    0.0003\n",
      "   220        1.1533             nan     0.0010    0.0002\n",
      "   240        1.1414             nan     0.0010    0.0002\n",
      "   260        1.1299             nan     0.0010    0.0002\n",
      "   280        1.1187             nan     0.0010    0.0003\n",
      "   300        1.1081             nan     0.0010    0.0002\n",
      "   320        1.0975             nan     0.0010    0.0002\n",
      "   340        1.0872             nan     0.0010    0.0002\n",
      "   360        1.0774             nan     0.0010    0.0002\n",
      "   380        1.0677             nan     0.0010    0.0002\n",
      "   400        1.0582             nan     0.0010    0.0002\n",
      "   420        1.0488             nan     0.0010    0.0002\n",
      "   440        1.0400             nan     0.0010    0.0002\n",
      "   460        1.0314             nan     0.0010    0.0002\n",
      "   480        1.0232             nan     0.0010    0.0002\n",
      "   500        1.0150             nan     0.0010    0.0002\n",
      "   520        1.0070             nan     0.0010    0.0002\n",
      "   540        0.9989             nan     0.0010    0.0002\n",
      "   560        0.9913             nan     0.0010    0.0002\n",
      "   580        0.9839             nan     0.0010    0.0001\n",
      "   600        0.9766             nan     0.0010    0.0001\n",
      "   620        0.9694             nan     0.0010    0.0001\n",
      "   640        0.9624             nan     0.0010    0.0001\n",
      "   660        0.9556             nan     0.0010    0.0001\n",
      "   680        0.9490             nan     0.0010    0.0001\n",
      "   700        0.9427             nan     0.0010    0.0001\n",
      "   720        0.9363             nan     0.0010    0.0001\n",
      "   740        0.9302             nan     0.0010    0.0001\n",
      "   760        0.9241             nan     0.0010    0.0001\n",
      "   780        0.9182             nan     0.0010    0.0001\n",
      "   800        0.9125             nan     0.0010    0.0001\n",
      "   820        0.9069             nan     0.0010    0.0001\n",
      "   840        0.9015             nan     0.0010    0.0001\n",
      "   860        0.8963             nan     0.0010    0.0001\n",
      "   880        0.8910             nan     0.0010    0.0001\n",
      "   900        0.8857             nan     0.0010    0.0001\n",
      "   920        0.8808             nan     0.0010    0.0001\n",
      "   940        0.8757             nan     0.0010    0.0001\n",
      "   960        0.8708             nan     0.0010    0.0001\n",
      "   980        0.8661             nan     0.0010    0.0001\n",
      "  1000        0.8613             nan     0.0010    0.0001\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0030\n",
      "     2        1.2999             nan     0.0100    0.0026\n",
      "     3        1.2942             nan     0.0100    0.0027\n",
      "     4        1.2878             nan     0.0100    0.0029\n",
      "     5        1.2822             nan     0.0100    0.0028\n",
      "     6        1.2765             nan     0.0100    0.0024\n",
      "     7        1.2706             nan     0.0100    0.0026\n",
      "     8        1.2661             nan     0.0100    0.0020\n",
      "     9        1.2608             nan     0.0100    0.0026\n",
      "    10        1.2554             nan     0.0100    0.0023\n",
      "    20        1.2080             nan     0.0100    0.0021\n",
      "    40        1.1305             nan     0.0100    0.0016\n",
      "    60        1.0705             nan     0.0100    0.0012\n",
      "    80        1.0261             nan     0.0100    0.0006\n",
      "   100        0.9915             nan     0.0100    0.0006\n",
      "   120        0.9639             nan     0.0100    0.0006\n",
      "   140        0.9407             nan     0.0100    0.0003\n",
      "   160        0.9222             nan     0.0100    0.0003\n",
      "   180        0.9069             nan     0.0100    0.0002\n",
      "   200        0.8937             nan     0.0100    0.0002\n",
      "   220        0.8824             nan     0.0100    0.0001\n",
      "   240        0.8721             nan     0.0100    0.0001\n",
      "   260        0.8630             nan     0.0100    0.0001\n",
      "   280        0.8544             nan     0.0100    0.0001\n",
      "   300        0.8470             nan     0.0100    0.0000\n",
      "   320        0.8402             nan     0.0100    0.0000\n",
      "   340        0.8335             nan     0.0100    0.0001\n",
      "   360        0.8272             nan     0.0100    0.0000\n",
      "   380        0.8215             nan     0.0100   -0.0000\n",
      "   400        0.8156             nan     0.0100   -0.0000\n",
      "   420        0.8100             nan     0.0100    0.0000\n",
      "   440        0.8049             nan     0.0100   -0.0001\n",
      "   460        0.7997             nan     0.0100   -0.0000\n",
      "   480        0.7946             nan     0.0100    0.0000\n",
      "   500        0.7898             nan     0.0100    0.0000\n",
      "   520        0.7850             nan     0.0100   -0.0000\n",
      "   540        0.7807             nan     0.0100   -0.0001\n",
      "   560        0.7766             nan     0.0100   -0.0001\n",
      "   580        0.7717             nan     0.0100    0.0000\n",
      "   600        0.7677             nan     0.0100    0.0000\n",
      "   620        0.7634             nan     0.0100   -0.0000\n",
      "   640        0.7596             nan     0.0100    0.0000\n",
      "   660        0.7556             nan     0.0100    0.0000\n",
      "   680        0.7524             nan     0.0100   -0.0001\n",
      "   700        0.7489             nan     0.0100   -0.0002\n",
      "   720        0.7456             nan     0.0100   -0.0001\n",
      "   740        0.7421             nan     0.0100   -0.0001\n",
      "   760        0.7389             nan     0.0100   -0.0000\n",
      "   780        0.7357             nan     0.0100   -0.0000\n",
      "   800        0.7327             nan     0.0100   -0.0001\n",
      "   820        0.7291             nan     0.0100   -0.0000\n",
      "   840        0.7263             nan     0.0100   -0.0000\n",
      "   860        0.7237             nan     0.0100   -0.0001\n",
      "   880        0.7211             nan     0.0100   -0.0000\n",
      "   900        0.7180             nan     0.0100   -0.0000\n",
      "   920        0.7155             nan     0.0100   -0.0001\n",
      "   940        0.7126             nan     0.0100    0.0000\n",
      "   960        0.7102             nan     0.0100   -0.0001\n",
      "   980        0.7079             nan     0.0100   -0.0000\n",
      "  1000        0.7056             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0035\n",
      "     2        1.2975             nan     0.0100    0.0037\n",
      "     3        1.2904             nan     0.0100    0.0030\n",
      "     4        1.2831             nan     0.0100    0.0031\n",
      "     5        1.2755             nan     0.0100    0.0033\n",
      "     6        1.2684             nan     0.0100    0.0035\n",
      "     7        1.2613             nan     0.0100    0.0031\n",
      "     8        1.2547             nan     0.0100    0.0028\n",
      "     9        1.2477             nan     0.0100    0.0028\n",
      "    10        1.2409             nan     0.0100    0.0031\n",
      "    20        1.1808             nan     0.0100    0.0020\n",
      "    40        1.0848             nan     0.0100    0.0017\n",
      "    60        1.0120             nan     0.0100    0.0015\n",
      "    80        0.9545             nan     0.0100    0.0010\n",
      "   100        0.9067             nan     0.0100    0.0008\n",
      "   120        0.8703             nan     0.0100    0.0004\n",
      "   140        0.8386             nan     0.0100    0.0007\n",
      "   160        0.8125             nan     0.0100    0.0002\n",
      "   180        0.7901             nan     0.0100    0.0002\n",
      "   200        0.7702             nan     0.0100    0.0002\n",
      "   220        0.7529             nan     0.0100    0.0003\n",
      "   240        0.7366             nan     0.0100    0.0001\n",
      "   260        0.7231             nan     0.0100   -0.0000\n",
      "   280        0.7087             nan     0.0100    0.0001\n",
      "   300        0.6948             nan     0.0100    0.0000\n",
      "   320        0.6836             nan     0.0100   -0.0001\n",
      "   340        0.6732             nan     0.0100    0.0001\n",
      "   360        0.6625             nan     0.0100    0.0000\n",
      "   380        0.6524             nan     0.0100   -0.0000\n",
      "   400        0.6427             nan     0.0100   -0.0001\n",
      "   420        0.6340             nan     0.0100   -0.0000\n",
      "   440        0.6252             nan     0.0100   -0.0002\n",
      "   460        0.6170             nan     0.0100   -0.0001\n",
      "   480        0.6093             nan     0.0100   -0.0001\n",
      "   500        0.6010             nan     0.0100   -0.0001\n",
      "   520        0.5945             nan     0.0100   -0.0000\n",
      "   540        0.5881             nan     0.0100   -0.0001\n",
      "   560        0.5799             nan     0.0100    0.0000\n",
      "   580        0.5731             nan     0.0100   -0.0001\n",
      "   600        0.5663             nan     0.0100    0.0000\n",
      "   620        0.5606             nan     0.0100   -0.0002\n",
      "   640        0.5545             nan     0.0100    0.0000\n",
      "   660        0.5474             nan     0.0100    0.0001\n",
      "   680        0.5411             nan     0.0100   -0.0002\n",
      "   700        0.5345             nan     0.0100   -0.0001\n",
      "   720        0.5283             nan     0.0100   -0.0001\n",
      "   740        0.5223             nan     0.0100    0.0000\n",
      "   760        0.5163             nan     0.0100   -0.0001\n",
      "   780        0.5108             nan     0.0100   -0.0001\n",
      "   800        0.5053             nan     0.0100   -0.0001\n",
      "   820        0.4997             nan     0.0100   -0.0001\n",
      "   840        0.4945             nan     0.0100   -0.0000\n",
      "   860        0.4893             nan     0.0100   -0.0001\n",
      "   880        0.4842             nan     0.0100   -0.0001\n",
      "   900        0.4791             nan     0.0100   -0.0002\n",
      "   920        0.4744             nan     0.0100   -0.0000\n",
      "   940        0.4686             nan     0.0100   -0.0002\n",
      "   960        0.4646             nan     0.0100   -0.0001\n",
      "   980        0.4603             nan     0.0100   -0.0002\n",
      "  1000        0.4554             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold06.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3045             nan     0.0100    0.0034\n",
      "     2        1.2965             nan     0.0100    0.0037\n",
      "     3        1.2885             nan     0.0100    0.0035\n",
      "     4        1.2804             nan     0.0100    0.0036\n",
      "     5        1.2723             nan     0.0100    0.0034\n",
      "     6        1.2648             nan     0.0100    0.0033\n",
      "     7        1.2572             nan     0.0100    0.0030\n",
      "     8        1.2498             nan     0.0100    0.0036\n",
      "     9        1.2425             nan     0.0100    0.0032\n",
      "    10        1.2358             nan     0.0100    0.0028\n",
      "    20        1.1652             nan     0.0100    0.0029\n",
      "    40        1.0583             nan     0.0100    0.0019\n",
      "    60        0.9767             nan     0.0100    0.0012\n",
      "    80        0.9135             nan     0.0100    0.0012\n",
      "   100        0.8598             nan     0.0100    0.0009\n",
      "   120        0.8170             nan     0.0100    0.0006\n",
      "   140        0.7812             nan     0.0100    0.0004\n",
      "   160        0.7492             nan     0.0100    0.0002\n",
      "   180        0.7215             nan     0.0100   -0.0001\n",
      "   200        0.6984             nan     0.0100    0.0003\n",
      "   220        0.6762             nan     0.0100   -0.0000\n",
      "   240        0.6568             nan     0.0100    0.0001\n",
      "   260        0.6392             nan     0.0100    0.0001\n",
      "   280        0.6233             nan     0.0100   -0.0001\n",
      "   300        0.6086             nan     0.0100   -0.0000\n",
      "   320        0.5937             nan     0.0100   -0.0001\n",
      "   340        0.5809             nan     0.0100   -0.0000\n",
      "   360        0.5676             nan     0.0100   -0.0001\n",
      "   380        0.5550             nan     0.0100   -0.0001\n",
      "   400        0.5428             nan     0.0100   -0.0002\n",
      "   420        0.5310             nan     0.0100   -0.0002\n",
      "   440        0.5202             nan     0.0100   -0.0001\n",
      "   460        0.5093             nan     0.0100   -0.0000\n",
      "   480        0.4988             nan     0.0100   -0.0002\n",
      "   500        0.4888             nan     0.0100   -0.0002\n",
      "   520        0.4790             nan     0.0100    0.0002\n",
      "   540        0.4709             nan     0.0100   -0.0000\n",
      "   560        0.4618             nan     0.0100   -0.0000\n",
      "   580        0.4529             nan     0.0100   -0.0000\n",
      "   600        0.4449             nan     0.0100   -0.0002\n",
      "   620        0.4373             nan     0.0100   -0.0001\n",
      "   640        0.4290             nan     0.0100   -0.0002\n",
      "   660        0.4217             nan     0.0100   -0.0001\n",
      "   680        0.4144             nan     0.0100   -0.0000\n",
      "   700        0.4069             nan     0.0100   -0.0001\n",
      "   720        0.3999             nan     0.0100   -0.0001\n",
      "   740        0.3930             nan     0.0100   -0.0002\n",
      "   760        0.3857             nan     0.0100   -0.0001\n",
      "   780        0.3790             nan     0.0100   -0.0002\n",
      "   800        0.3717             nan     0.0100   -0.0001\n",
      "   820        0.3656             nan     0.0100   -0.0002\n",
      "   840        0.3595             nan     0.0100   -0.0002\n",
      "   860        0.3527             nan     0.0100   -0.0000\n",
      "   880        0.3470             nan     0.0100   -0.0002\n",
      "   900        0.3411             nan     0.0100   -0.0002\n",
      "   920        0.3357             nan     0.0100   -0.0001\n",
      "   940        0.3303             nan     0.0100   -0.0002\n",
      "   960        0.3248             nan     0.0100   -0.0001\n",
      "   980        0.3193             nan     0.0100   -0.0001\n",
      "  1000        0.3143             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold06.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3129             nan     0.0010    0.0003\n",
      "     2        1.3122             nan     0.0010    0.0003\n",
      "     3        1.3115             nan     0.0010    0.0003\n",
      "     4        1.3109             nan     0.0010    0.0003\n",
      "     5        1.3103             nan     0.0010    0.0003\n",
      "     6        1.3097             nan     0.0010    0.0003\n",
      "     7        1.3090             nan     0.0010    0.0003\n",
      "     8        1.3083             nan     0.0010    0.0003\n",
      "     9        1.3076             nan     0.0010    0.0003\n",
      "    10        1.3069             nan     0.0010    0.0003\n",
      "    20        1.3006             nan     0.0010    0.0003\n",
      "    40        1.2885             nan     0.0010    0.0003\n",
      "    60        1.2766             nan     0.0010    0.0003\n",
      "    80        1.2651             nan     0.0010    0.0003\n",
      "   100        1.2540             nan     0.0010    0.0003\n",
      "   120        1.2432             nan     0.0010    0.0002\n",
      "   140        1.2327             nan     0.0010    0.0002\n",
      "   160        1.2223             nan     0.0010    0.0002\n",
      "   180        1.2124             nan     0.0010    0.0002\n",
      "   200        1.2029             nan     0.0010    0.0002\n",
      "   220        1.1937             nan     0.0010    0.0002\n",
      "   240        1.1848             nan     0.0010    0.0002\n",
      "   260        1.1761             nan     0.0010    0.0002\n",
      "   280        1.1677             nan     0.0010    0.0002\n",
      "   300        1.1595             nan     0.0010    0.0002\n",
      "   320        1.1512             nan     0.0010    0.0002\n",
      "   340        1.1438             nan     0.0010    0.0002\n",
      "   360        1.1362             nan     0.0010    0.0002\n",
      "   380        1.1289             nan     0.0010    0.0002\n",
      "   400        1.1222             nan     0.0010    0.0002\n",
      "   420        1.1152             nan     0.0010    0.0002\n",
      "   440        1.1085             nan     0.0010    0.0002\n",
      "   460        1.1020             nan     0.0010    0.0001\n",
      "   480        1.0958             nan     0.0010    0.0001\n",
      "   500        1.0896             nan     0.0010    0.0001\n",
      "   520        1.0837             nan     0.0010    0.0001\n",
      "   540        1.0779             nan     0.0010    0.0001\n",
      "   560        1.0725             nan     0.0010    0.0001\n",
      "   580        1.0670             nan     0.0010    0.0001\n",
      "   600        1.0616             nan     0.0010    0.0001\n",
      "   620        1.0566             nan     0.0010    0.0001\n",
      "   640        1.0513             nan     0.0010    0.0001\n",
      "   660        1.0465             nan     0.0010    0.0001\n",
      "   680        1.0417             nan     0.0010    0.0001\n",
      "   700        1.0370             nan     0.0010    0.0001\n",
      "   720        1.0325             nan     0.0010    0.0001\n",
      "   740        1.0281             nan     0.0010    0.0001\n",
      "   760        1.0238             nan     0.0010    0.0001\n",
      "   780        1.0195             nan     0.0010    0.0001\n",
      "   800        1.0154             nan     0.0010    0.0001\n",
      "   820        1.0114             nan     0.0010    0.0001\n",
      "   840        1.0074             nan     0.0010    0.0001\n",
      "   860        1.0035             nan     0.0010    0.0001\n",
      "   880        0.9997             nan     0.0010    0.0001\n",
      "   900        0.9959             nan     0.0010    0.0001\n",
      "   920        0.9922             nan     0.0010    0.0000\n",
      "   940        0.9887             nan     0.0010    0.0001\n",
      "   960        0.9853             nan     0.0010    0.0001\n",
      "   980        0.9819             nan     0.0010    0.0001\n",
      "  1000        0.9787             nan     0.0010    0.0001\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3127             nan     0.0010    0.0004\n",
      "     2        1.3120             nan     0.0010    0.0004\n",
      "     3        1.3112             nan     0.0010    0.0003\n",
      "     4        1.3104             nan     0.0010    0.0004\n",
      "     5        1.3094             nan     0.0010    0.0004\n",
      "     6        1.3086             nan     0.0010    0.0004\n",
      "     7        1.3077             nan     0.0010    0.0004\n",
      "     8        1.3070             nan     0.0010    0.0004\n",
      "     9        1.3063             nan     0.0010    0.0003\n",
      "    10        1.3055             nan     0.0010    0.0003\n",
      "    20        1.2978             nan     0.0010    0.0003\n",
      "    40        1.2825             nan     0.0010    0.0004\n",
      "    60        1.2680             nan     0.0010    0.0003\n",
      "    80        1.2538             nan     0.0010    0.0003\n",
      "   100        1.2399             nan     0.0010    0.0003\n",
      "   120        1.2269             nan     0.0010    0.0003\n",
      "   140        1.2139             nan     0.0010    0.0003\n",
      "   160        1.2018             nan     0.0010    0.0003\n",
      "   180        1.1898             nan     0.0010    0.0003\n",
      "   200        1.1781             nan     0.0010    0.0003\n",
      "   220        1.1670             nan     0.0010    0.0003\n",
      "   240        1.1561             nan     0.0010    0.0002\n",
      "   260        1.1455             nan     0.0010    0.0002\n",
      "   280        1.1351             nan     0.0010    0.0003\n",
      "   300        1.1251             nan     0.0010    0.0002\n",
      "   320        1.1155             nan     0.0010    0.0002\n",
      "   340        1.1062             nan     0.0010    0.0002\n",
      "   360        1.0973             nan     0.0010    0.0002\n",
      "   380        1.0885             nan     0.0010    0.0002\n",
      "   400        1.0798             nan     0.0010    0.0001\n",
      "   420        1.0713             nan     0.0010    0.0002\n",
      "   440        1.0632             nan     0.0010    0.0002\n",
      "   460        1.0551             nan     0.0010    0.0001\n",
      "   480        1.0472             nan     0.0010    0.0002\n",
      "   500        1.0399             nan     0.0010    0.0002\n",
      "   520        1.0328             nan     0.0010    0.0001\n",
      "   540        1.0258             nan     0.0010    0.0002\n",
      "   560        1.0187             nan     0.0010    0.0001\n",
      "   580        1.0119             nan     0.0010    0.0001\n",
      "   600        1.0053             nan     0.0010    0.0001\n",
      "   620        0.9989             nan     0.0010    0.0001\n",
      "   640        0.9925             nan     0.0010    0.0001\n",
      "   660        0.9864             nan     0.0010    0.0001\n",
      "   680        0.9806             nan     0.0010    0.0001\n",
      "   700        0.9747             nan     0.0010    0.0001\n",
      "   720        0.9690             nan     0.0010    0.0001\n",
      "   740        0.9635             nan     0.0010    0.0001\n",
      "   760        0.9582             nan     0.0010    0.0001\n",
      "   780        0.9527             nan     0.0010    0.0001\n",
      "   800        0.9475             nan     0.0010    0.0001\n",
      "   820        0.9424             nan     0.0010    0.0001\n",
      "   840        0.9373             nan     0.0010    0.0001\n",
      "   860        0.9325             nan     0.0010    0.0001\n",
      "   880        0.9279             nan     0.0010    0.0001\n",
      "   900        0.9235             nan     0.0010    0.0001\n",
      "   920        0.9190             nan     0.0010    0.0001\n",
      "   940        0.9146             nan     0.0010    0.0001\n",
      "   960        0.9102             nan     0.0010    0.0001\n",
      "   980        0.9058             nan     0.0010    0.0001\n",
      "  1000        0.9016             nan     0.0010    0.0001\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3126             nan     0.0010    0.0004\n",
      "     2        1.3118             nan     0.0010    0.0004\n",
      "     3        1.3109             nan     0.0010    0.0004\n",
      "     4        1.3099             nan     0.0010    0.0004\n",
      "     5        1.3091             nan     0.0010    0.0003\n",
      "     6        1.3082             nan     0.0010    0.0004\n",
      "     7        1.3073             nan     0.0010    0.0004\n",
      "     8        1.3065             nan     0.0010    0.0004\n",
      "     9        1.3057             nan     0.0010    0.0004\n",
      "    10        1.3048             nan     0.0010    0.0004\n",
      "    20        1.2962             nan     0.0010    0.0003\n",
      "    40        1.2792             nan     0.0010    0.0004\n",
      "    60        1.2629             nan     0.0010    0.0003\n",
      "    80        1.2473             nan     0.0010    0.0003\n",
      "   100        1.2319             nan     0.0010    0.0003\n",
      "   120        1.2174             nan     0.0010    0.0003\n",
      "   140        1.2034             nan     0.0010    0.0003\n",
      "   160        1.1897             nan     0.0010    0.0003\n",
      "   180        1.1767             nan     0.0010    0.0003\n",
      "   200        1.1638             nan     0.0010    0.0002\n",
      "   220        1.1514             nan     0.0010    0.0002\n",
      "   240        1.1393             nan     0.0010    0.0002\n",
      "   260        1.1277             nan     0.0010    0.0002\n",
      "   280        1.1162             nan     0.0010    0.0002\n",
      "   300        1.1051             nan     0.0010    0.0003\n",
      "   320        1.0941             nan     0.0010    0.0002\n",
      "   340        1.0837             nan     0.0010    0.0002\n",
      "   360        1.0737             nan     0.0010    0.0002\n",
      "   380        1.0637             nan     0.0010    0.0002\n",
      "   400        1.0540             nan     0.0010    0.0002\n",
      "   420        1.0446             nan     0.0010    0.0002\n",
      "   440        1.0354             nan     0.0010    0.0002\n",
      "   460        1.0264             nan     0.0010    0.0002\n",
      "   480        1.0181             nan     0.0010    0.0002\n",
      "   500        1.0100             nan     0.0010    0.0002\n",
      "   520        1.0019             nan     0.0010    0.0002\n",
      "   540        0.9941             nan     0.0010    0.0001\n",
      "   560        0.9866             nan     0.0010    0.0002\n",
      "   580        0.9791             nan     0.0010    0.0001\n",
      "   600        0.9717             nan     0.0010    0.0001\n",
      "   620        0.9649             nan     0.0010    0.0001\n",
      "   640        0.9579             nan     0.0010    0.0001\n",
      "   660        0.9511             nan     0.0010    0.0001\n",
      "   680        0.9443             nan     0.0010    0.0001\n",
      "   700        0.9379             nan     0.0010    0.0001\n",
      "   720        0.9316             nan     0.0010    0.0001\n",
      "   740        0.9256             nan     0.0010    0.0001\n",
      "   760        0.9195             nan     0.0010    0.0001\n",
      "   780        0.9136             nan     0.0010    0.0001\n",
      "   800        0.9077             nan     0.0010    0.0001\n",
      "   820        0.9021             nan     0.0010    0.0001\n",
      "   840        0.8966             nan     0.0010    0.0001\n",
      "   860        0.8912             nan     0.0010    0.0001\n",
      "   880        0.8858             nan     0.0010    0.0001\n",
      "   900        0.8807             nan     0.0010    0.0001\n",
      "   920        0.8757             nan     0.0010    0.0001\n",
      "   940        0.8706             nan     0.0010    0.0001\n",
      "   960        0.8657             nan     0.0010    0.0001\n",
      "   980        0.8612             nan     0.0010    0.0001\n",
      "  1000        0.8564             nan     0.0010    0.0001\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3070             nan     0.0100    0.0032\n",
      "     2        1.3008             nan     0.0100    0.0030\n",
      "     3        1.2950             nan     0.0100    0.0030\n",
      "     4        1.2891             nan     0.0100    0.0028\n",
      "     5        1.2828             nan     0.0100    0.0029\n",
      "     6        1.2767             nan     0.0100    0.0028\n",
      "     7        1.2702             nan     0.0100    0.0026\n",
      "     8        1.2645             nan     0.0100    0.0027\n",
      "     9        1.2585             nan     0.0100    0.0027\n",
      "    10        1.2530             nan     0.0100    0.0027\n",
      "    20        1.2017             nan     0.0100    0.0022\n",
      "    40        1.1228             nan     0.0100    0.0016\n",
      "    60        1.0620             nan     0.0100    0.0012\n",
      "    80        1.0154             nan     0.0100    0.0009\n",
      "   100        0.9794             nan     0.0100    0.0007\n",
      "   120        0.9503             nan     0.0100    0.0005\n",
      "   140        0.9270             nan     0.0100    0.0004\n",
      "   160        0.9084             nan     0.0100    0.0002\n",
      "   180        0.8942             nan     0.0100    0.0002\n",
      "   200        0.8820             nan     0.0100   -0.0001\n",
      "   220        0.8710             nan     0.0100    0.0002\n",
      "   240        0.8616             nan     0.0100   -0.0001\n",
      "   260        0.8533             nan     0.0100    0.0000\n",
      "   280        0.8453             nan     0.0100    0.0000\n",
      "   300        0.8377             nan     0.0100    0.0001\n",
      "   320        0.8306             nan     0.0100   -0.0000\n",
      "   340        0.8245             nan     0.0100   -0.0000\n",
      "   360        0.8180             nan     0.0100    0.0000\n",
      "   380        0.8128             nan     0.0100    0.0000\n",
      "   400        0.8075             nan     0.0100   -0.0001\n",
      "   420        0.8023             nan     0.0100   -0.0000\n",
      "   440        0.7973             nan     0.0100    0.0000\n",
      "   460        0.7934             nan     0.0100    0.0000\n",
      "   480        0.7884             nan     0.0100    0.0000\n",
      "   500        0.7840             nan     0.0100    0.0000\n",
      "   520        0.7795             nan     0.0100    0.0000\n",
      "   540        0.7753             nan     0.0100   -0.0000\n",
      "   560        0.7707             nan     0.0100   -0.0000\n",
      "   580        0.7665             nan     0.0100    0.0000\n",
      "   600        0.7625             nan     0.0100   -0.0000\n",
      "   620        0.7584             nan     0.0100   -0.0001\n",
      "   640        0.7550             nan     0.0100   -0.0000\n",
      "   660        0.7514             nan     0.0100   -0.0000\n",
      "   680        0.7480             nan     0.0100   -0.0002\n",
      "   700        0.7445             nan     0.0100   -0.0000\n",
      "   720        0.7413             nan     0.0100    0.0000\n",
      "   740        0.7381             nan     0.0100   -0.0001\n",
      "   760        0.7349             nan     0.0100   -0.0000\n",
      "   780        0.7319             nan     0.0100   -0.0000\n",
      "   800        0.7292             nan     0.0100   -0.0002\n",
      "   820        0.7264             nan     0.0100   -0.0001\n",
      "   840        0.7234             nan     0.0100   -0.0000\n",
      "   860        0.7207             nan     0.0100   -0.0001\n",
      "   880        0.7176             nan     0.0100   -0.0000\n",
      "   900        0.7153             nan     0.0100   -0.0000\n",
      "   920        0.7129             nan     0.0100   -0.0000\n",
      "   940        0.7100             nan     0.0100   -0.0000\n",
      "   960        0.7075             nan     0.0100   -0.0001\n",
      "   980        0.7050             nan     0.0100   -0.0001\n",
      "  1000        0.7025             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3060             nan     0.0100    0.0034\n",
      "     2        1.2981             nan     0.0100    0.0035\n",
      "     3        1.2895             nan     0.0100    0.0036\n",
      "     4        1.2820             nan     0.0100    0.0036\n",
      "     5        1.2749             nan     0.0100    0.0034\n",
      "     6        1.2674             nan     0.0100    0.0035\n",
      "     7        1.2602             nan     0.0100    0.0037\n",
      "     8        1.2536             nan     0.0100    0.0032\n",
      "     9        1.2467             nan     0.0100    0.0030\n",
      "    10        1.2402             nan     0.0100    0.0029\n",
      "    20        1.1798             nan     0.0100    0.0026\n",
      "    40        1.0810             nan     0.0100    0.0017\n",
      "    60        1.0076             nan     0.0100    0.0013\n",
      "    80        0.9490             nan     0.0100    0.0009\n",
      "   100        0.9026             nan     0.0100    0.0007\n",
      "   120        0.8656             nan     0.0100    0.0008\n",
      "   140        0.8352             nan     0.0100    0.0003\n",
      "   160        0.8095             nan     0.0100    0.0002\n",
      "   180        0.7877             nan     0.0100    0.0002\n",
      "   200        0.7679             nan     0.0100   -0.0000\n",
      "   220        0.7501             nan     0.0100    0.0001\n",
      "   240        0.7339             nan     0.0100    0.0002\n",
      "   260        0.7194             nan     0.0100    0.0002\n",
      "   280        0.7068             nan     0.0100   -0.0000\n",
      "   300        0.6954             nan     0.0100   -0.0000\n",
      "   320        0.6842             nan     0.0100   -0.0001\n",
      "   340        0.6731             nan     0.0100   -0.0000\n",
      "   360        0.6628             nan     0.0100   -0.0001\n",
      "   380        0.6536             nan     0.0100    0.0000\n",
      "   400        0.6454             nan     0.0100   -0.0001\n",
      "   420        0.6367             nan     0.0100   -0.0000\n",
      "   440        0.6285             nan     0.0100   -0.0001\n",
      "   460        0.6204             nan     0.0100   -0.0001\n",
      "   480        0.6117             nan     0.0100   -0.0000\n",
      "   500        0.6048             nan     0.0100   -0.0001\n",
      "   520        0.5978             nan     0.0100   -0.0002\n",
      "   540        0.5904             nan     0.0100   -0.0000\n",
      "   560        0.5837             nan     0.0100   -0.0001\n",
      "   580        0.5765             nan     0.0100   -0.0000\n",
      "   600        0.5700             nan     0.0100   -0.0001\n",
      "   620        0.5629             nan     0.0100   -0.0001\n",
      "   640        0.5564             nan     0.0100   -0.0000\n",
      "   660        0.5496             nan     0.0100   -0.0000\n",
      "   680        0.5443             nan     0.0100   -0.0001\n",
      "   700        0.5381             nan     0.0100   -0.0001\n",
      "   720        0.5321             nan     0.0100   -0.0001\n",
      "   740        0.5263             nan     0.0100   -0.0000\n",
      "   760        0.5206             nan     0.0100   -0.0002\n",
      "   780        0.5145             nan     0.0100   -0.0000\n",
      "   800        0.5077             nan     0.0100   -0.0000\n",
      "   820        0.5019             nan     0.0100    0.0000\n",
      "   840        0.4962             nan     0.0100   -0.0001\n",
      "   860        0.4910             nan     0.0100   -0.0001\n",
      "   880        0.4857             nan     0.0100   -0.0000\n",
      "   900        0.4802             nan     0.0100   -0.0001\n",
      "   920        0.4752             nan     0.0100   -0.0001\n",
      "   940        0.4697             nan     0.0100   -0.0001\n",
      "   960        0.4651             nan     0.0100   -0.0001\n",
      "   980        0.4606             nan     0.0100   -0.0001\n",
      "  1000        0.4563             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold07.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 12: JJS has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0040\n",
      "     2        1.2965             nan     0.0100    0.0033\n",
      "     3        1.2880             nan     0.0100    0.0031\n",
      "     4        1.2792             nan     0.0100    0.0041\n",
      "     5        1.2705             nan     0.0100    0.0038\n",
      "     6        1.2625             nan     0.0100    0.0034\n",
      "     7        1.2537             nan     0.0100    0.0038\n",
      "     8        1.2462             nan     0.0100    0.0035\n",
      "     9        1.2383             nan     0.0100    0.0034\n",
      "    10        1.2308             nan     0.0100    0.0033\n",
      "    20        1.1596             nan     0.0100    0.0029\n",
      "    40        1.0492             nan     0.0100    0.0023\n",
      "    60        0.9685             nan     0.0100    0.0015\n",
      "    80        0.9034             nan     0.0100    0.0010\n",
      "   100        0.8530             nan     0.0100    0.0008\n",
      "   120        0.8118             nan     0.0100    0.0006\n",
      "   140        0.7769             nan     0.0100    0.0005\n",
      "   160        0.7472             nan     0.0100    0.0001\n",
      "   180        0.7221             nan     0.0100    0.0002\n",
      "   200        0.6990             nan     0.0100    0.0001\n",
      "   220        0.6787             nan     0.0100    0.0002\n",
      "   240        0.6603             nan     0.0100    0.0002\n",
      "   260        0.6423             nan     0.0100    0.0000\n",
      "   280        0.6254             nan     0.0100   -0.0000\n",
      "   300        0.6111             nan     0.0100   -0.0002\n",
      "   320        0.5973             nan     0.0100   -0.0002\n",
      "   340        0.5828             nan     0.0100    0.0001\n",
      "   360        0.5696             nan     0.0100   -0.0000\n",
      "   380        0.5576             nan     0.0100   -0.0003\n",
      "   400        0.5462             nan     0.0100    0.0000\n",
      "   420        0.5348             nan     0.0100   -0.0002\n",
      "   440        0.5237             nan     0.0100   -0.0001\n",
      "   460        0.5132             nan     0.0100    0.0001\n",
      "   480        0.5034             nan     0.0100   -0.0002\n",
      "   500        0.4935             nan     0.0100   -0.0000\n",
      "   520        0.4845             nan     0.0100    0.0001\n",
      "   540        0.4763             nan     0.0100   -0.0001\n",
      "   560        0.4665             nan     0.0100   -0.0001\n",
      "   580        0.4580             nan     0.0100   -0.0000\n",
      "   600        0.4493             nan     0.0100   -0.0000\n",
      "   620        0.4402             nan     0.0100   -0.0001\n",
      "   640        0.4318             nan     0.0100   -0.0001\n",
      "   660        0.4238             nan     0.0100   -0.0002\n",
      "   680        0.4159             nan     0.0100   -0.0000\n",
      "   700        0.4086             nan     0.0100   -0.0001\n",
      "   720        0.4023             nan     0.0100   -0.0000\n",
      "   740        0.3949             nan     0.0100   -0.0001\n",
      "   760        0.3880             nan     0.0100   -0.0000\n",
      "   780        0.3811             nan     0.0100   -0.0001\n",
      "   800        0.3741             nan     0.0100   -0.0002\n",
      "   820        0.3681             nan     0.0100   -0.0003\n",
      "   840        0.3617             nan     0.0100   -0.0001\n",
      "   860        0.3562             nan     0.0100   -0.0000\n",
      "   880        0.3494             nan     0.0100   -0.0001\n",
      "   900        0.3436             nan     0.0100   -0.0001\n",
      "   920        0.3379             nan     0.0100   -0.0001\n",
      "   940        0.3321             nan     0.0100   -0.0000\n",
      "   960        0.3269             nan     0.0100   -0.0000\n",
      "   980        0.3214             nan     0.0100   -0.0001\n",
      "  1000        0.3152             nan     0.0100    0.0000\n",
      "\n",
      "- Fold07.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3129             nan     0.0010    0.0003\n",
      "     2        1.3123             nan     0.0010    0.0003\n",
      "     3        1.3117             nan     0.0010    0.0003\n",
      "     4        1.3111             nan     0.0010    0.0003\n",
      "     5        1.3105             nan     0.0010    0.0003\n",
      "     6        1.3099             nan     0.0010    0.0003\n",
      "     7        1.3092             nan     0.0010    0.0003\n",
      "     8        1.3087             nan     0.0010    0.0003\n",
      "     9        1.3081             nan     0.0010    0.0003\n",
      "    10        1.3074             nan     0.0010    0.0003\n",
      "    20        1.3012             nan     0.0010    0.0003\n",
      "    40        1.2893             nan     0.0010    0.0002\n",
      "    60        1.2779             nan     0.0010    0.0003\n",
      "    80        1.2669             nan     0.0010    0.0002\n",
      "   100        1.2562             nan     0.0010    0.0003\n",
      "   120        1.2460             nan     0.0010    0.0002\n",
      "   140        1.2359             nan     0.0010    0.0002\n",
      "   160        1.2261             nan     0.0010    0.0002\n",
      "   180        1.2163             nan     0.0010    0.0002\n",
      "   200        1.2070             nan     0.0010    0.0002\n",
      "   220        1.1981             nan     0.0010    0.0002\n",
      "   240        1.1898             nan     0.0010    0.0002\n",
      "   260        1.1812             nan     0.0010    0.0002\n",
      "   280        1.1729             nan     0.0010    0.0002\n",
      "   300        1.1648             nan     0.0010    0.0002\n",
      "   320        1.1573             nan     0.0010    0.0002\n",
      "   340        1.1500             nan     0.0010    0.0002\n",
      "   360        1.1430             nan     0.0010    0.0002\n",
      "   380        1.1361             nan     0.0010    0.0001\n",
      "   400        1.1292             nan     0.0010    0.0002\n",
      "   420        1.1227             nan     0.0010    0.0001\n",
      "   440        1.1165             nan     0.0010    0.0001\n",
      "   460        1.1104             nan     0.0010    0.0001\n",
      "   480        1.1045             nan     0.0010    0.0001\n",
      "   500        1.0986             nan     0.0010    0.0001\n",
      "   520        1.0930             nan     0.0010    0.0001\n",
      "   540        1.0874             nan     0.0010    0.0001\n",
      "   560        1.0819             nan     0.0010    0.0001\n",
      "   580        1.0767             nan     0.0010    0.0001\n",
      "   600        1.0714             nan     0.0010    0.0001\n",
      "   620        1.0663             nan     0.0010    0.0001\n",
      "   640        1.0613             nan     0.0010    0.0001\n",
      "   660        1.0566             nan     0.0010    0.0001\n",
      "   680        1.0520             nan     0.0010    0.0001\n",
      "   700        1.0474             nan     0.0010    0.0001\n",
      "   720        1.0431             nan     0.0010    0.0001\n",
      "   740        1.0388             nan     0.0010    0.0001\n",
      "   760        1.0346             nan     0.0010    0.0001\n",
      "   780        1.0305             nan     0.0010    0.0001\n",
      "   800        1.0265             nan     0.0010    0.0001\n",
      "   820        1.0226             nan     0.0010    0.0001\n",
      "   840        1.0188             nan     0.0010    0.0001\n",
      "   860        1.0152             nan     0.0010    0.0001\n",
      "   880        1.0117             nan     0.0010    0.0001\n",
      "   900        1.0082             nan     0.0010    0.0001\n",
      "   920        1.0047             nan     0.0010    0.0001\n",
      "   940        1.0013             nan     0.0010    0.0001\n",
      "   960        0.9979             nan     0.0010    0.0001\n",
      "   980        0.9948             nan     0.0010    0.0001\n",
      "  1000        0.9916             nan     0.0010    0.0000\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3127             nan     0.0010    0.0004\n",
      "     2        1.3119             nan     0.0010    0.0004\n",
      "     3        1.3112             nan     0.0010    0.0003\n",
      "     4        1.3104             nan     0.0010    0.0003\n",
      "     5        1.3097             nan     0.0010    0.0003\n",
      "     6        1.3089             nan     0.0010    0.0004\n",
      "     7        1.3081             nan     0.0010    0.0004\n",
      "     8        1.3073             nan     0.0010    0.0003\n",
      "     9        1.3065             nan     0.0010    0.0004\n",
      "    10        1.3057             nan     0.0010    0.0004\n",
      "    20        1.2981             nan     0.0010    0.0004\n",
      "    40        1.2830             nan     0.0010    0.0003\n",
      "    60        1.2686             nan     0.0010    0.0003\n",
      "    80        1.2547             nan     0.0010    0.0003\n",
      "   100        1.2411             nan     0.0010    0.0003\n",
      "   120        1.2282             nan     0.0010    0.0003\n",
      "   140        1.2156             nan     0.0010    0.0003\n",
      "   160        1.2036             nan     0.0010    0.0003\n",
      "   180        1.1921             nan     0.0010    0.0002\n",
      "   200        1.1811             nan     0.0010    0.0002\n",
      "   220        1.1700             nan     0.0010    0.0002\n",
      "   240        1.1594             nan     0.0010    0.0002\n",
      "   260        1.1491             nan     0.0010    0.0002\n",
      "   280        1.1390             nan     0.0010    0.0002\n",
      "   300        1.1290             nan     0.0010    0.0002\n",
      "   320        1.1196             nan     0.0010    0.0002\n",
      "   340        1.1103             nan     0.0010    0.0002\n",
      "   360        1.1012             nan     0.0010    0.0002\n",
      "   380        1.0925             nan     0.0010    0.0002\n",
      "   400        1.0841             nan     0.0010    0.0002\n",
      "   420        1.0760             nan     0.0010    0.0002\n",
      "   440        1.0682             nan     0.0010    0.0001\n",
      "   460        1.0604             nan     0.0010    0.0001\n",
      "   480        1.0530             nan     0.0010    0.0001\n",
      "   500        1.0460             nan     0.0010    0.0001\n",
      "   520        1.0389             nan     0.0010    0.0002\n",
      "   540        1.0320             nan     0.0010    0.0001\n",
      "   560        1.0253             nan     0.0010    0.0001\n",
      "   580        1.0190             nan     0.0010    0.0001\n",
      "   600        1.0125             nan     0.0010    0.0001\n",
      "   620        1.0063             nan     0.0010    0.0001\n",
      "   640        1.0003             nan     0.0010    0.0001\n",
      "   660        0.9944             nan     0.0010    0.0001\n",
      "   680        0.9885             nan     0.0010    0.0001\n",
      "   700        0.9829             nan     0.0010    0.0001\n",
      "   720        0.9774             nan     0.0010    0.0001\n",
      "   740        0.9720             nan     0.0010    0.0001\n",
      "   760        0.9668             nan     0.0010    0.0001\n",
      "   780        0.9617             nan     0.0010    0.0001\n",
      "   800        0.9567             nan     0.0010    0.0001\n",
      "   820        0.9517             nan     0.0010    0.0001\n",
      "   840        0.9469             nan     0.0010    0.0001\n",
      "   860        0.9422             nan     0.0010    0.0001\n",
      "   880        0.9376             nan     0.0010    0.0001\n",
      "   900        0.9332             nan     0.0010    0.0001\n",
      "   920        0.9287             nan     0.0010    0.0001\n",
      "   940        0.9243             nan     0.0010    0.0001\n",
      "   960        0.9202             nan     0.0010    0.0000\n",
      "   980        0.9161             nan     0.0010    0.0001\n",
      "  1000        0.9120             nan     0.0010    0.0001\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3126             nan     0.0010    0.0004\n",
      "     2        1.3117             nan     0.0010    0.0004\n",
      "     3        1.3109             nan     0.0010    0.0004\n",
      "     4        1.3101             nan     0.0010    0.0004\n",
      "     5        1.3091             nan     0.0010    0.0004\n",
      "     6        1.3083             nan     0.0010    0.0004\n",
      "     7        1.3073             nan     0.0010    0.0004\n",
      "     8        1.3065             nan     0.0010    0.0004\n",
      "     9        1.3057             nan     0.0010    0.0004\n",
      "    10        1.3047             nan     0.0010    0.0004\n",
      "    20        1.2964             nan     0.0010    0.0003\n",
      "    40        1.2798             nan     0.0010    0.0003\n",
      "    60        1.2642             nan     0.0010    0.0003\n",
      "    80        1.2489             nan     0.0010    0.0003\n",
      "   100        1.2342             nan     0.0010    0.0003\n",
      "   120        1.2197             nan     0.0010    0.0003\n",
      "   140        1.2059             nan     0.0010    0.0003\n",
      "   160        1.1924             nan     0.0010    0.0003\n",
      "   180        1.1794             nan     0.0010    0.0003\n",
      "   200        1.1666             nan     0.0010    0.0002\n",
      "   220        1.1544             nan     0.0010    0.0002\n",
      "   240        1.1428             nan     0.0010    0.0002\n",
      "   260        1.1315             nan     0.0010    0.0003\n",
      "   280        1.1205             nan     0.0010    0.0002\n",
      "   300        1.1099             nan     0.0010    0.0002\n",
      "   320        1.0994             nan     0.0010    0.0002\n",
      "   340        1.0890             nan     0.0010    0.0002\n",
      "   360        1.0790             nan     0.0010    0.0002\n",
      "   380        1.0694             nan     0.0010    0.0002\n",
      "   400        1.0602             nan     0.0010    0.0001\n",
      "   420        1.0510             nan     0.0010    0.0002\n",
      "   440        1.0423             nan     0.0010    0.0002\n",
      "   460        1.0337             nan     0.0010    0.0002\n",
      "   480        1.0251             nan     0.0010    0.0002\n",
      "   500        1.0170             nan     0.0010    0.0002\n",
      "   520        1.0092             nan     0.0010    0.0001\n",
      "   540        1.0015             nan     0.0010    0.0002\n",
      "   560        0.9941             nan     0.0010    0.0002\n",
      "   580        0.9869             nan     0.0010    0.0001\n",
      "   600        0.9800             nan     0.0010    0.0001\n",
      "   620        0.9729             nan     0.0010    0.0001\n",
      "   640        0.9660             nan     0.0010    0.0001\n",
      "   660        0.9592             nan     0.0010    0.0001\n",
      "   680        0.9529             nan     0.0010    0.0001\n",
      "   700        0.9465             nan     0.0010    0.0001\n",
      "   720        0.9403             nan     0.0010    0.0001\n",
      "   740        0.9341             nan     0.0010    0.0001\n",
      "   760        0.9281             nan     0.0010    0.0001\n",
      "   780        0.9221             nan     0.0010    0.0001\n",
      "   800        0.9164             nan     0.0010    0.0001\n",
      "   820        0.9107             nan     0.0010    0.0001\n",
      "   840        0.9052             nan     0.0010    0.0001\n",
      "   860        0.8998             nan     0.0010    0.0001\n",
      "   880        0.8947             nan     0.0010    0.0001\n",
      "   900        0.8897             nan     0.0010    0.0001\n",
      "   920        0.8848             nan     0.0010    0.0001\n",
      "   940        0.8799             nan     0.0010    0.0001\n",
      "   960        0.8749             nan     0.0010    0.0001\n",
      "   980        0.8700             nan     0.0010    0.0001\n",
      "  1000        0.8653             nan     0.0010    0.0001\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3073             nan     0.0100    0.0028\n",
      "     2        1.3013             nan     0.0100    0.0030\n",
      "     3        1.2946             nan     0.0100    0.0030\n",
      "     4        1.2889             nan     0.0100    0.0029\n",
      "     5        1.2827             nan     0.0100    0.0027\n",
      "     6        1.2763             nan     0.0100    0.0029\n",
      "     7        1.2706             nan     0.0100    0.0026\n",
      "     8        1.2656             nan     0.0100    0.0026\n",
      "     9        1.2598             nan     0.0100    0.0028\n",
      "    10        1.2542             nan     0.0100    0.0025\n",
      "    20        1.2053             nan     0.0100    0.0022\n",
      "    40        1.1285             nan     0.0100    0.0011\n",
      "    60        1.0721             nan     0.0100    0.0012\n",
      "    80        1.0285             nan     0.0100    0.0009\n",
      "   100        0.9928             nan     0.0100    0.0007\n",
      "   120        0.9646             nan     0.0100    0.0005\n",
      "   140        0.9413             nan     0.0100    0.0003\n",
      "   160        0.9236             nan     0.0100    0.0003\n",
      "   180        0.9085             nan     0.0100    0.0003\n",
      "   200        0.8960             nan     0.0100   -0.0000\n",
      "   220        0.8866             nan     0.0100    0.0001\n",
      "   240        0.8785             nan     0.0100    0.0002\n",
      "   260        0.8701             nan     0.0100    0.0001\n",
      "   280        0.8620             nan     0.0100   -0.0000\n",
      "   300        0.8554             nan     0.0100    0.0001\n",
      "   320        0.8487             nan     0.0100    0.0001\n",
      "   340        0.8422             nan     0.0100    0.0000\n",
      "   360        0.8357             nan     0.0100   -0.0001\n",
      "   380        0.8299             nan     0.0100    0.0000\n",
      "   400        0.8241             nan     0.0100    0.0001\n",
      "   420        0.8189             nan     0.0100    0.0001\n",
      "   440        0.8138             nan     0.0100    0.0000\n",
      "   460        0.8091             nan     0.0100    0.0000\n",
      "   480        0.8038             nan     0.0100   -0.0000\n",
      "   500        0.7988             nan     0.0100    0.0000\n",
      "   520        0.7944             nan     0.0100   -0.0000\n",
      "   540        0.7899             nan     0.0100   -0.0001\n",
      "   560        0.7853             nan     0.0100    0.0000\n",
      "   580        0.7814             nan     0.0100   -0.0001\n",
      "   600        0.7774             nan     0.0100   -0.0001\n",
      "   620        0.7738             nan     0.0100   -0.0001\n",
      "   640        0.7701             nan     0.0100   -0.0001\n",
      "   660        0.7663             nan     0.0100   -0.0000\n",
      "   680        0.7625             nan     0.0100   -0.0001\n",
      "   700        0.7589             nan     0.0100   -0.0001\n",
      "   720        0.7553             nan     0.0100    0.0000\n",
      "   740        0.7518             nan     0.0100   -0.0000\n",
      "   760        0.7486             nan     0.0100   -0.0001\n",
      "   780        0.7454             nan     0.0100   -0.0000\n",
      "   800        0.7419             nan     0.0100   -0.0000\n",
      "   820        0.7394             nan     0.0100   -0.0000\n",
      "   840        0.7368             nan     0.0100   -0.0000\n",
      "   860        0.7338             nan     0.0100   -0.0000\n",
      "   880        0.7308             nan     0.0100   -0.0000\n",
      "   900        0.7277             nan     0.0100   -0.0000\n",
      "   920        0.7250             nan     0.0100   -0.0000\n",
      "   940        0.7220             nan     0.0100   -0.0000\n",
      "   960        0.7195             nan     0.0100   -0.0000\n",
      "   980        0.7168             nan     0.0100   -0.0000\n",
      "  1000        0.7143             nan     0.0100    0.0000\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3053             nan     0.0100    0.0036\n",
      "     2        1.2979             nan     0.0100    0.0031\n",
      "     3        1.2905             nan     0.0100    0.0035\n",
      "     4        1.2827             nan     0.0100    0.0033\n",
      "     5        1.2751             nan     0.0100    0.0035\n",
      "     6        1.2677             nan     0.0100    0.0032\n",
      "     7        1.2604             nan     0.0100    0.0032\n",
      "     8        1.2537             nan     0.0100    0.0029\n",
      "     9        1.2467             nan     0.0100    0.0029\n",
      "    10        1.2401             nan     0.0100    0.0031\n",
      "    20        1.1807             nan     0.0100    0.0026\n",
      "    40        1.0847             nan     0.0100    0.0019\n",
      "    60        1.0122             nan     0.0100    0.0013\n",
      "    80        0.9556             nan     0.0100    0.0010\n",
      "   100        0.9113             nan     0.0100    0.0006\n",
      "   120        0.8755             nan     0.0100    0.0006\n",
      "   140        0.8445             nan     0.0100    0.0003\n",
      "   160        0.8189             nan     0.0100    0.0002\n",
      "   180        0.7972             nan     0.0100   -0.0000\n",
      "   200        0.7794             nan     0.0100    0.0002\n",
      "   220        0.7619             nan     0.0100   -0.0000\n",
      "   240        0.7475             nan     0.0100    0.0000\n",
      "   260        0.7332             nan     0.0100   -0.0001\n",
      "   280        0.7191             nan     0.0100   -0.0003\n",
      "   300        0.7066             nan     0.0100   -0.0001\n",
      "   320        0.6954             nan     0.0100   -0.0000\n",
      "   340        0.6840             nan     0.0100   -0.0000\n",
      "   360        0.6745             nan     0.0100    0.0001\n",
      "   380        0.6651             nan     0.0100   -0.0001\n",
      "   400        0.6551             nan     0.0100   -0.0001\n",
      "   420        0.6461             nan     0.0100   -0.0001\n",
      "   440        0.6364             nan     0.0100    0.0001\n",
      "   460        0.6287             nan     0.0100   -0.0001\n",
      "   480        0.6207             nan     0.0100   -0.0001\n",
      "   500        0.6125             nan     0.0100   -0.0001\n",
      "   520        0.6055             nan     0.0100   -0.0002\n",
      "   540        0.5980             nan     0.0100   -0.0000\n",
      "   560        0.5903             nan     0.0100   -0.0001\n",
      "   580        0.5828             nan     0.0100   -0.0001\n",
      "   600        0.5764             nan     0.0100   -0.0001\n",
      "   620        0.5690             nan     0.0100   -0.0002\n",
      "   640        0.5621             nan     0.0100   -0.0001\n",
      "   660        0.5540             nan     0.0100   -0.0000\n",
      "   680        0.5475             nan     0.0100   -0.0002\n",
      "   700        0.5416             nan     0.0100   -0.0001\n",
      "   720        0.5352             nan     0.0100   -0.0001\n",
      "   740        0.5287             nan     0.0100   -0.0002\n",
      "   760        0.5222             nan     0.0100   -0.0001\n",
      "   780        0.5163             nan     0.0100   -0.0001\n",
      "   800        0.5105             nan     0.0100   -0.0001\n",
      "   820        0.5051             nan     0.0100   -0.0000\n",
      "   840        0.4993             nan     0.0100   -0.0002\n",
      "   860        0.4943             nan     0.0100   -0.0000\n",
      "   880        0.4883             nan     0.0100   -0.0000\n",
      "   900        0.4830             nan     0.0100   -0.0002\n",
      "   920        0.4776             nan     0.0100   -0.0002\n",
      "   940        0.4728             nan     0.0100   -0.0002\n",
      "   960        0.4677             nan     0.0100   -0.0001\n",
      "   980        0.4627             nan     0.0100   -0.0001\n",
      "  1000        0.4583             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold08.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3048             nan     0.0100    0.0038\n",
      "     2        1.2961             nan     0.0100    0.0036\n",
      "     3        1.2873             nan     0.0100    0.0038\n",
      "     4        1.2791             nan     0.0100    0.0037\n",
      "     5        1.2705             nan     0.0100    0.0037\n",
      "     6        1.2633             nan     0.0100    0.0030\n",
      "     7        1.2562             nan     0.0100    0.0036\n",
      "     8        1.2487             nan     0.0100    0.0031\n",
      "     9        1.2409             nan     0.0100    0.0033\n",
      "    10        1.2335             nan     0.0100    0.0035\n",
      "    20        1.1679             nan     0.0100    0.0026\n",
      "    40        1.0617             nan     0.0100    0.0019\n",
      "    60        0.9801             nan     0.0100    0.0014\n",
      "    80        0.9177             nan     0.0100    0.0011\n",
      "   100        0.8670             nan     0.0100    0.0008\n",
      "   120        0.8229             nan     0.0100    0.0003\n",
      "   140        0.7880             nan     0.0100    0.0003\n",
      "   160        0.7576             nan     0.0100    0.0001\n",
      "   180        0.7315             nan     0.0100    0.0003\n",
      "   200        0.7079             nan     0.0100    0.0001\n",
      "   220        0.6877             nan     0.0100    0.0001\n",
      "   240        0.6698             nan     0.0100   -0.0000\n",
      "   260        0.6525             nan     0.0100    0.0001\n",
      "   280        0.6353             nan     0.0100   -0.0001\n",
      "   300        0.6199             nan     0.0100    0.0000\n",
      "   320        0.6046             nan     0.0100   -0.0001\n",
      "   340        0.5907             nan     0.0100    0.0000\n",
      "   360        0.5772             nan     0.0100   -0.0001\n",
      "   380        0.5643             nan     0.0100   -0.0001\n",
      "   400        0.5525             nan     0.0100    0.0001\n",
      "   420        0.5400             nan     0.0100   -0.0001\n",
      "   440        0.5289             nan     0.0100   -0.0000\n",
      "   460        0.5180             nan     0.0100    0.0001\n",
      "   480        0.5074             nan     0.0100   -0.0000\n",
      "   500        0.4978             nan     0.0100   -0.0002\n",
      "   520        0.4888             nan     0.0100   -0.0001\n",
      "   540        0.4787             nan     0.0100   -0.0002\n",
      "   560        0.4692             nan     0.0100   -0.0001\n",
      "   580        0.4608             nan     0.0100   -0.0001\n",
      "   600        0.4518             nan     0.0100   -0.0001\n",
      "   620        0.4426             nan     0.0100   -0.0000\n",
      "   640        0.4346             nan     0.0100   -0.0001\n",
      "   660        0.4257             nan     0.0100   -0.0002\n",
      "   680        0.4185             nan     0.0100   -0.0000\n",
      "   700        0.4113             nan     0.0100   -0.0000\n",
      "   720        0.4044             nan     0.0100   -0.0000\n",
      "   740        0.3976             nan     0.0100   -0.0001\n",
      "   760        0.3907             nan     0.0100   -0.0001\n",
      "   780        0.3837             nan     0.0100    0.0000\n",
      "   800        0.3763             nan     0.0100   -0.0002\n",
      "   820        0.3699             nan     0.0100   -0.0001\n",
      "   840        0.3633             nan     0.0100   -0.0001\n",
      "   860        0.3570             nan     0.0100   -0.0001\n",
      "   880        0.3512             nan     0.0100   -0.0001\n",
      "   900        0.3450             nan     0.0100   -0.0001\n",
      "   920        0.3387             nan     0.0100   -0.0001\n",
      "   940        0.3331             nan     0.0100   -0.0001\n",
      "   960        0.3273             nan     0.0100   -0.0002\n",
      "   980        0.3218             nan     0.0100   -0.0000\n",
      "  1000        0.3166             nan     0.0100   -0.0002\n",
      "\n",
      "- Fold08.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3112             nan     0.0010    0.0003\n",
      "     2        1.3106             nan     0.0010    0.0003\n",
      "     3        1.3099             nan     0.0010    0.0003\n",
      "     4        1.3093             nan     0.0010    0.0003\n",
      "     5        1.3087             nan     0.0010    0.0003\n",
      "     6        1.3081             nan     0.0010    0.0003\n",
      "     7        1.3074             nan     0.0010    0.0003\n",
      "     8        1.3068             nan     0.0010    0.0003\n",
      "     9        1.3062             nan     0.0010    0.0003\n",
      "    10        1.3055             nan     0.0010    0.0003\n",
      "    20        1.2994             nan     0.0010    0.0003\n",
      "    40        1.2877             nan     0.0010    0.0003\n",
      "    60        1.2761             nan     0.0010    0.0003\n",
      "    80        1.2650             nan     0.0010    0.0002\n",
      "   100        1.2542             nan     0.0010    0.0002\n",
      "   120        1.2436             nan     0.0010    0.0002\n",
      "   140        1.2335             nan     0.0010    0.0002\n",
      "   160        1.2235             nan     0.0010    0.0002\n",
      "   180        1.2141             nan     0.0010    0.0002\n",
      "   200        1.2049             nan     0.0010    0.0002\n",
      "   220        1.1962             nan     0.0010    0.0002\n",
      "   240        1.1874             nan     0.0010    0.0002\n",
      "   260        1.1789             nan     0.0010    0.0002\n",
      "   280        1.1707             nan     0.0010    0.0002\n",
      "   300        1.1630             nan     0.0010    0.0002\n",
      "   320        1.1551             nan     0.0010    0.0002\n",
      "   340        1.1474             nan     0.0010    0.0002\n",
      "   360        1.1399             nan     0.0010    0.0002\n",
      "   380        1.1328             nan     0.0010    0.0002\n",
      "   400        1.1258             nan     0.0010    0.0001\n",
      "   420        1.1193             nan     0.0010    0.0001\n",
      "   440        1.1128             nan     0.0010    0.0001\n",
      "   460        1.1065             nan     0.0010    0.0001\n",
      "   480        1.1003             nan     0.0010    0.0001\n",
      "   500        1.0944             nan     0.0010    0.0001\n",
      "   520        1.0887             nan     0.0010    0.0001\n",
      "   540        1.0830             nan     0.0010    0.0001\n",
      "   560        1.0773             nan     0.0010    0.0001\n",
      "   580        1.0720             nan     0.0010    0.0001\n",
      "   600        1.0669             nan     0.0010    0.0001\n",
      "   620        1.0617             nan     0.0010    0.0001\n",
      "   640        1.0568             nan     0.0010    0.0001\n",
      "   660        1.0520             nan     0.0010    0.0001\n",
      "   680        1.0472             nan     0.0010    0.0001\n",
      "   700        1.0426             nan     0.0010    0.0001\n",
      "   720        1.0381             nan     0.0010    0.0001\n",
      "   740        1.0338             nan     0.0010    0.0001\n",
      "   760        1.0296             nan     0.0010    0.0001\n",
      "   780        1.0253             nan     0.0010    0.0001\n",
      "   800        1.0211             nan     0.0010    0.0001\n",
      "   820        1.0172             nan     0.0010    0.0001\n",
      "   840        1.0134             nan     0.0010    0.0001\n",
      "   860        1.0096             nan     0.0010    0.0001\n",
      "   880        1.0058             nan     0.0010    0.0001\n",
      "   900        1.0022             nan     0.0010    0.0001\n",
      "   920        0.9985             nan     0.0010    0.0001\n",
      "   940        0.9951             nan     0.0010    0.0001\n",
      "   960        0.9917             nan     0.0010    0.0000\n",
      "   980        0.9882             nan     0.0010    0.0001\n",
      "  1000        0.9851             nan     0.0010    0.0001\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3110             nan     0.0010    0.0004\n",
      "     2        1.3102             nan     0.0010    0.0004\n",
      "     3        1.3093             nan     0.0010    0.0004\n",
      "     4        1.3085             nan     0.0010    0.0004\n",
      "     5        1.3077             nan     0.0010    0.0004\n",
      "     6        1.3069             nan     0.0010    0.0004\n",
      "     7        1.3061             nan     0.0010    0.0004\n",
      "     8        1.3053             nan     0.0010    0.0003\n",
      "     9        1.3044             nan     0.0010    0.0004\n",
      "    10        1.3038             nan     0.0010    0.0003\n",
      "    20        1.2963             nan     0.0010    0.0003\n",
      "    40        1.2811             nan     0.0010    0.0004\n",
      "    60        1.2669             nan     0.0010    0.0003\n",
      "    80        1.2528             nan     0.0010    0.0003\n",
      "   100        1.2392             nan     0.0010    0.0003\n",
      "   120        1.2259             nan     0.0010    0.0003\n",
      "   140        1.2135             nan     0.0010    0.0003\n",
      "   160        1.2010             nan     0.0010    0.0003\n",
      "   180        1.1890             nan     0.0010    0.0003\n",
      "   200        1.1772             nan     0.0010    0.0003\n",
      "   220        1.1660             nan     0.0010    0.0003\n",
      "   240        1.1552             nan     0.0010    0.0002\n",
      "   260        1.1446             nan     0.0010    0.0002\n",
      "   280        1.1343             nan     0.0010    0.0002\n",
      "   300        1.1245             nan     0.0010    0.0002\n",
      "   320        1.1150             nan     0.0010    0.0002\n",
      "   340        1.1057             nan     0.0010    0.0002\n",
      "   360        1.0968             nan     0.0010    0.0002\n",
      "   380        1.0880             nan     0.0010    0.0002\n",
      "   400        1.0794             nan     0.0010    0.0002\n",
      "   420        1.0709             nan     0.0010    0.0002\n",
      "   440        1.0628             nan     0.0010    0.0002\n",
      "   460        1.0549             nan     0.0010    0.0002\n",
      "   480        1.0473             nan     0.0010    0.0001\n",
      "   500        1.0396             nan     0.0010    0.0002\n",
      "   520        1.0323             nan     0.0010    0.0001\n",
      "   540        1.0253             nan     0.0010    0.0001\n",
      "   560        1.0184             nan     0.0010    0.0001\n",
      "   580        1.0116             nan     0.0010    0.0002\n",
      "   600        1.0049             nan     0.0010    0.0001\n",
      "   620        0.9986             nan     0.0010    0.0001\n",
      "   640        0.9921             nan     0.0010    0.0001\n",
      "   660        0.9858             nan     0.0010    0.0001\n",
      "   680        0.9797             nan     0.0010    0.0001\n",
      "   700        0.9738             nan     0.0010    0.0001\n",
      "   720        0.9680             nan     0.0010    0.0001\n",
      "   740        0.9623             nan     0.0010    0.0001\n",
      "   760        0.9568             nan     0.0010    0.0001\n",
      "   780        0.9514             nan     0.0010    0.0001\n",
      "   800        0.9462             nan     0.0010    0.0001\n",
      "   820        0.9411             nan     0.0010    0.0001\n",
      "   840        0.9361             nan     0.0010    0.0001\n",
      "   860        0.9311             nan     0.0010    0.0001\n",
      "   880        0.9264             nan     0.0010    0.0001\n",
      "   900        0.9220             nan     0.0010    0.0001\n",
      "   920        0.9173             nan     0.0010    0.0001\n",
      "   940        0.9126             nan     0.0010    0.0001\n",
      "   960        0.9082             nan     0.0010    0.0001\n",
      "   980        0.9038             nan     0.0010    0.0001\n",
      "  1000        0.8996             nan     0.0010    0.0001\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3110             nan     0.0010    0.0004\n",
      "     2        1.3101             nan     0.0010    0.0004\n",
      "     3        1.3092             nan     0.0010    0.0004\n",
      "     4        1.3083             nan     0.0010    0.0004\n",
      "     5        1.3075             nan     0.0010    0.0003\n",
      "     6        1.3066             nan     0.0010    0.0004\n",
      "     7        1.3056             nan     0.0010    0.0004\n",
      "     8        1.3047             nan     0.0010    0.0004\n",
      "     9        1.3038             nan     0.0010    0.0004\n",
      "    10        1.3029             nan     0.0010    0.0004\n",
      "    20        1.2942             nan     0.0010    0.0004\n",
      "    40        1.2771             nan     0.0010    0.0003\n",
      "    60        1.2611             nan     0.0010    0.0004\n",
      "    80        1.2453             nan     0.0010    0.0003\n",
      "   100        1.2303             nan     0.0010    0.0003\n",
      "   120        1.2159             nan     0.0010    0.0003\n",
      "   140        1.2014             nan     0.0010    0.0003\n",
      "   160        1.1877             nan     0.0010    0.0002\n",
      "   180        1.1746             nan     0.0010    0.0003\n",
      "   200        1.1619             nan     0.0010    0.0003\n",
      "   220        1.1493             nan     0.0010    0.0003\n",
      "   240        1.1374             nan     0.0010    0.0002\n",
      "   260        1.1253             nan     0.0010    0.0002\n",
      "   280        1.1139             nan     0.0010    0.0002\n",
      "   300        1.1030             nan     0.0010    0.0002\n",
      "   320        1.0924             nan     0.0010    0.0002\n",
      "   340        1.0820             nan     0.0010    0.0002\n",
      "   360        1.0719             nan     0.0010    0.0002\n",
      "   380        1.0622             nan     0.0010    0.0002\n",
      "   400        1.0529             nan     0.0010    0.0002\n",
      "   420        1.0437             nan     0.0010    0.0002\n",
      "   440        1.0346             nan     0.0010    0.0002\n",
      "   460        1.0258             nan     0.0010    0.0002\n",
      "   480        1.0173             nan     0.0010    0.0001\n",
      "   500        1.0090             nan     0.0010    0.0002\n",
      "   520        1.0007             nan     0.0010    0.0002\n",
      "   540        0.9927             nan     0.0010    0.0002\n",
      "   560        0.9850             nan     0.0010    0.0002\n",
      "   580        0.9773             nan     0.0010    0.0001\n",
      "   600        0.9698             nan     0.0010    0.0002\n",
      "   620        0.9630             nan     0.0010    0.0001\n",
      "   640        0.9560             nan     0.0010    0.0001\n",
      "   660        0.9491             nan     0.0010    0.0001\n",
      "   680        0.9424             nan     0.0010    0.0001\n",
      "   700        0.9358             nan     0.0010    0.0001\n",
      "   720        0.9293             nan     0.0010    0.0001\n",
      "   740        0.9231             nan     0.0010    0.0001\n",
      "   760        0.9169             nan     0.0010    0.0001\n",
      "   780        0.9106             nan     0.0010    0.0001\n",
      "   800        0.9047             nan     0.0010    0.0001\n",
      "   820        0.8991             nan     0.0010    0.0001\n",
      "   840        0.8936             nan     0.0010    0.0001\n",
      "   860        0.8880             nan     0.0010    0.0001\n",
      "   880        0.8827             nan     0.0010    0.0001\n",
      "   900        0.8773             nan     0.0010    0.0001\n",
      "   920        0.8721             nan     0.0010    0.0001\n",
      "   940        0.8673             nan     0.0010    0.0001\n",
      "   960        0.8626             nan     0.0010    0.0001\n",
      "   980        0.8576             nan     0.0010    0.0001\n",
      "  1000        0.8528             nan     0.0010    0.0001\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3057             nan     0.0100    0.0027\n",
      "     2        1.3001             nan     0.0100    0.0027\n",
      "     3        1.2943             nan     0.0100    0.0030\n",
      "     4        1.2887             nan     0.0100    0.0027\n",
      "     5        1.2826             nan     0.0100    0.0028\n",
      "     6        1.2768             nan     0.0100    0.0025\n",
      "     7        1.2708             nan     0.0100    0.0027\n",
      "     8        1.2646             nan     0.0100    0.0027\n",
      "     9        1.2592             nan     0.0100    0.0027\n",
      "    10        1.2537             nan     0.0100    0.0026\n",
      "    20        1.2051             nan     0.0100    0.0023\n",
      "    40        1.1268             nan     0.0100    0.0017\n",
      "    60        1.0675             nan     0.0100    0.0006\n",
      "    80        1.0227             nan     0.0100    0.0009\n",
      "   100        0.9860             nan     0.0100    0.0007\n",
      "   120        0.9565             nan     0.0100    0.0005\n",
      "   140        0.9346             nan     0.0100    0.0004\n",
      "   160        0.9157             nan     0.0100    0.0003\n",
      "   180        0.9014             nan     0.0100    0.0002\n",
      "   200        0.8882             nan     0.0100   -0.0000\n",
      "   220        0.8774             nan     0.0100    0.0001\n",
      "   240        0.8670             nan     0.0100    0.0001\n",
      "   260        0.8574             nan     0.0100    0.0000\n",
      "   280        0.8495             nan     0.0100   -0.0000\n",
      "   300        0.8412             nan     0.0100   -0.0000\n",
      "   320        0.8329             nan     0.0100   -0.0000\n",
      "   340        0.8248             nan     0.0100    0.0000\n",
      "   360        0.8178             nan     0.0100   -0.0000\n",
      "   380        0.8107             nan     0.0100   -0.0000\n",
      "   400        0.8042             nan     0.0100    0.0001\n",
      "   420        0.7978             nan     0.0100    0.0000\n",
      "   440        0.7921             nan     0.0100    0.0000\n",
      "   460        0.7866             nan     0.0100    0.0001\n",
      "   480        0.7808             nan     0.0100    0.0000\n",
      "   500        0.7762             nan     0.0100    0.0000\n",
      "   520        0.7718             nan     0.0100   -0.0001\n",
      "   540        0.7666             nan     0.0100    0.0000\n",
      "   560        0.7628             nan     0.0100    0.0000\n",
      "   580        0.7582             nan     0.0100    0.0000\n",
      "   600        0.7539             nan     0.0100    0.0000\n",
      "   620        0.7500             nan     0.0100   -0.0001\n",
      "   640        0.7462             nan     0.0100    0.0000\n",
      "   660        0.7426             nan     0.0100   -0.0001\n",
      "   680        0.7384             nan     0.0100   -0.0001\n",
      "   700        0.7343             nan     0.0100    0.0000\n",
      "   720        0.7306             nan     0.0100   -0.0000\n",
      "   740        0.7271             nan     0.0100   -0.0000\n",
      "   760        0.7235             nan     0.0100    0.0000\n",
      "   780        0.7197             nan     0.0100   -0.0000\n",
      "   800        0.7163             nan     0.0100   -0.0001\n",
      "   820        0.7126             nan     0.0100   -0.0000\n",
      "   840        0.7095             nan     0.0100    0.0000\n",
      "   860        0.7062             nan     0.0100   -0.0000\n",
      "   880        0.7033             nan     0.0100   -0.0000\n",
      "   900        0.7007             nan     0.0100   -0.0001\n",
      "   920        0.6976             nan     0.0100   -0.0000\n",
      "   940        0.6948             nan     0.0100   -0.0000\n",
      "   960        0.6922             nan     0.0100   -0.0000\n",
      "   980        0.6892             nan     0.0100   -0.0000\n",
      "  1000        0.6864             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3046             nan     0.0100    0.0035\n",
      "     2        1.2967             nan     0.0100    0.0041\n",
      "     3        1.2886             nan     0.0100    0.0037\n",
      "     4        1.2812             nan     0.0100    0.0033\n",
      "     5        1.2737             nan     0.0100    0.0035\n",
      "     6        1.2666             nan     0.0100    0.0030\n",
      "     7        1.2593             nan     0.0100    0.0028\n",
      "     8        1.2519             nan     0.0100    0.0032\n",
      "     9        1.2448             nan     0.0100    0.0034\n",
      "    10        1.2376             nan     0.0100    0.0029\n",
      "    20        1.1756             nan     0.0100    0.0027\n",
      "    40        1.0770             nan     0.0100    0.0020\n",
      "    60        1.0037             nan     0.0100    0.0013\n",
      "    80        0.9482             nan     0.0100    0.0009\n",
      "   100        0.8997             nan     0.0100    0.0010\n",
      "   120        0.8608             nan     0.0100    0.0007\n",
      "   140        0.8279             nan     0.0100    0.0006\n",
      "   160        0.8010             nan     0.0100    0.0003\n",
      "   180        0.7779             nan     0.0100    0.0002\n",
      "   200        0.7577             nan     0.0100    0.0001\n",
      "   220        0.7399             nan     0.0100    0.0003\n",
      "   240        0.7250             nan     0.0100    0.0000\n",
      "   260        0.7097             nan     0.0100    0.0001\n",
      "   280        0.6958             nan     0.0100    0.0000\n",
      "   300        0.6835             nan     0.0100    0.0001\n",
      "   320        0.6712             nan     0.0100    0.0000\n",
      "   340        0.6593             nan     0.0100   -0.0000\n",
      "   360        0.6490             nan     0.0100    0.0001\n",
      "   380        0.6389             nan     0.0100   -0.0002\n",
      "   400        0.6277             nan     0.0100   -0.0000\n",
      "   420        0.6176             nan     0.0100   -0.0001\n",
      "   440        0.6085             nan     0.0100   -0.0001\n",
      "   460        0.5997             nan     0.0100   -0.0001\n",
      "   480        0.5924             nan     0.0100   -0.0002\n",
      "   500        0.5839             nan     0.0100    0.0001\n",
      "   520        0.5762             nan     0.0100   -0.0002\n",
      "   540        0.5686             nan     0.0100   -0.0000\n",
      "   560        0.5615             nan     0.0100   -0.0001\n",
      "   580        0.5542             nan     0.0100   -0.0000\n",
      "   600        0.5469             nan     0.0100   -0.0000\n",
      "   620        0.5401             nan     0.0100   -0.0001\n",
      "   640        0.5324             nan     0.0100   -0.0001\n",
      "   660        0.5253             nan     0.0100   -0.0001\n",
      "   680        0.5180             nan     0.0100   -0.0001\n",
      "   700        0.5113             nan     0.0100   -0.0000\n",
      "   720        0.5059             nan     0.0100   -0.0002\n",
      "   740        0.5000             nan     0.0100   -0.0002\n",
      "   760        0.4940             nan     0.0100    0.0000\n",
      "   780        0.4882             nan     0.0100   -0.0001\n",
      "   800        0.4825             nan     0.0100   -0.0001\n",
      "   820        0.4767             nan     0.0100   -0.0001\n",
      "   840        0.4705             nan     0.0100   -0.0001\n",
      "   860        0.4649             nan     0.0100   -0.0001\n",
      "   880        0.4598             nan     0.0100   -0.0001\n",
      "   900        0.4537             nan     0.0100   -0.0001\n",
      "   920        0.4480             nan     0.0100   -0.0002\n",
      "   940        0.4430             nan     0.0100   -0.0001\n",
      "   960        0.4383             nan     0.0100   -0.0001\n",
      "   980        0.4337             nan     0.0100   -0.0002\n",
      "  1000        0.4295             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold09.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3030             nan     0.0100    0.0038\n",
      "     2        1.2943             nan     0.0100    0.0039\n",
      "     3        1.2865             nan     0.0100    0.0037\n",
      "     4        1.2792             nan     0.0100    0.0029\n",
      "     5        1.2713             nan     0.0100    0.0035\n",
      "     6        1.2629             nan     0.0100    0.0032\n",
      "     7        1.2552             nan     0.0100    0.0033\n",
      "     8        1.2473             nan     0.0100    0.0034\n",
      "     9        1.2402             nan     0.0100    0.0033\n",
      "    10        1.2327             nan     0.0100    0.0032\n",
      "    20        1.1652             nan     0.0100    0.0028\n",
      "    40        1.0542             nan     0.0100    0.0020\n",
      "    60        0.9711             nan     0.0100    0.0014\n",
      "    80        0.9054             nan     0.0100    0.0011\n",
      "   100        0.8530             nan     0.0100    0.0006\n",
      "   120        0.8070             nan     0.0100    0.0007\n",
      "   140        0.7729             nan     0.0100    0.0005\n",
      "   160        0.7413             nan     0.0100    0.0004\n",
      "   180        0.7142             nan     0.0100    0.0001\n",
      "   200        0.6899             nan     0.0100    0.0000\n",
      "   220        0.6670             nan     0.0100    0.0003\n",
      "   240        0.6457             nan     0.0100    0.0002\n",
      "   260        0.6276             nan     0.0100    0.0000\n",
      "   280        0.6109             nan     0.0100    0.0001\n",
      "   300        0.5940             nan     0.0100    0.0000\n",
      "   320        0.5786             nan     0.0100   -0.0001\n",
      "   340        0.5635             nan     0.0100   -0.0000\n",
      "   360        0.5507             nan     0.0100    0.0001\n",
      "   380        0.5389             nan     0.0100   -0.0003\n",
      "   400        0.5264             nan     0.0100   -0.0002\n",
      "   420        0.5134             nan     0.0100   -0.0002\n",
      "   440        0.5018             nan     0.0100   -0.0000\n",
      "   460        0.4909             nan     0.0100   -0.0001\n",
      "   480        0.4807             nan     0.0100   -0.0001\n",
      "   500        0.4706             nan     0.0100   -0.0002\n",
      "   520        0.4619             nan     0.0100   -0.0001\n",
      "   540        0.4515             nan     0.0100   -0.0001\n",
      "   560        0.4422             nan     0.0100   -0.0001\n",
      "   580        0.4325             nan     0.0100   -0.0001\n",
      "   600        0.4240             nan     0.0100   -0.0001\n",
      "   620        0.4160             nan     0.0100   -0.0001\n",
      "   640        0.4083             nan     0.0100   -0.0002\n",
      "   660        0.3998             nan     0.0100   -0.0001\n",
      "   680        0.3926             nan     0.0100   -0.0002\n",
      "   700        0.3852             nan     0.0100   -0.0002\n",
      "   720        0.3779             nan     0.0100   -0.0001\n",
      "   740        0.3705             nan     0.0100   -0.0002\n",
      "   760        0.3638             nan     0.0100   -0.0001\n",
      "   780        0.3572             nan     0.0100   -0.0001\n",
      "   800        0.3512             nan     0.0100   -0.0003\n",
      "   820        0.3455             nan     0.0100   -0.0000\n",
      "   840        0.3395             nan     0.0100   -0.0001\n",
      "   860        0.3332             nan     0.0100   -0.0001\n",
      "   880        0.3277             nan     0.0100   -0.0001\n",
      "   900        0.3219             nan     0.0100   -0.0001\n",
      "   920        0.3159             nan     0.0100   -0.0000\n",
      "   940        0.3105             nan     0.0100   -0.0001\n",
      "   960        0.3054             nan     0.0100   -0.0001\n",
      "   980        0.3004             nan     0.0100   -0.0001\n",
      "  1000        0.2949             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold09.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3119             nan     0.0010    0.0003\n",
      "     2        1.3112             nan     0.0010    0.0003\n",
      "     3        1.3106             nan     0.0010    0.0003\n",
      "     4        1.3100             nan     0.0010    0.0003\n",
      "     5        1.3094             nan     0.0010    0.0003\n",
      "     6        1.3088             nan     0.0010    0.0003\n",
      "     7        1.3082             nan     0.0010    0.0003\n",
      "     8        1.3077             nan     0.0010    0.0002\n",
      "     9        1.3071             nan     0.0010    0.0003\n",
      "    10        1.3065             nan     0.0010    0.0003\n",
      "    20        1.3006             nan     0.0010    0.0002\n",
      "    40        1.2891             nan     0.0010    0.0002\n",
      "    60        1.2782             nan     0.0010    0.0002\n",
      "    80        1.2678             nan     0.0010    0.0002\n",
      "   100        1.2573             nan     0.0010    0.0003\n",
      "   120        1.2474             nan     0.0010    0.0002\n",
      "   140        1.2379             nan     0.0010    0.0002\n",
      "   160        1.2284             nan     0.0010    0.0002\n",
      "   180        1.2193             nan     0.0010    0.0002\n",
      "   200        1.2103             nan     0.0010    0.0002\n",
      "   220        1.2018             nan     0.0010    0.0002\n",
      "   240        1.1933             nan     0.0010    0.0002\n",
      "   260        1.1853             nan     0.0010    0.0002\n",
      "   280        1.1774             nan     0.0010    0.0002\n",
      "   300        1.1697             nan     0.0010    0.0002\n",
      "   320        1.1623             nan     0.0010    0.0002\n",
      "   340        1.1552             nan     0.0010    0.0002\n",
      "   360        1.1481             nan     0.0010    0.0002\n",
      "   380        1.1412             nan     0.0010    0.0002\n",
      "   400        1.1345             nan     0.0010    0.0001\n",
      "   420        1.1279             nan     0.0010    0.0001\n",
      "   440        1.1217             nan     0.0010    0.0001\n",
      "   460        1.1155             nan     0.0010    0.0001\n",
      "   480        1.1097             nan     0.0010    0.0001\n",
      "   500        1.1039             nan     0.0010    0.0001\n",
      "   520        1.0983             nan     0.0010    0.0001\n",
      "   540        1.0927             nan     0.0010    0.0001\n",
      "   560        1.0874             nan     0.0010    0.0001\n",
      "   580        1.0822             nan     0.0010    0.0001\n",
      "   600        1.0772             nan     0.0010    0.0001\n",
      "   620        1.0723             nan     0.0010    0.0001\n",
      "   640        1.0676             nan     0.0010    0.0001\n",
      "   660        1.0628             nan     0.0010    0.0001\n",
      "   680        1.0582             nan     0.0010    0.0001\n",
      "   700        1.0538             nan     0.0010    0.0001\n",
      "   720        1.0493             nan     0.0010    0.0001\n",
      "   740        1.0448             nan     0.0010    0.0001\n",
      "   760        1.0407             nan     0.0010    0.0001\n",
      "   780        1.0365             nan     0.0010    0.0001\n",
      "   800        1.0324             nan     0.0010    0.0001\n",
      "   820        1.0285             nan     0.0010    0.0001\n",
      "   840        1.0247             nan     0.0010    0.0001\n",
      "   860        1.0210             nan     0.0010    0.0001\n",
      "   880        1.0173             nan     0.0010    0.0001\n",
      "   900        1.0139             nan     0.0010    0.0001\n",
      "   920        1.0105             nan     0.0010    0.0001\n",
      "   940        1.0070             nan     0.0010    0.0001\n",
      "   960        1.0038             nan     0.0010    0.0001\n",
      "   980        1.0005             nan     0.0010    0.0001\n",
      "  1000        0.9973             nan     0.0010    0.0001\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.001, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3117             nan     0.0010    0.0003\n",
      "     2        1.3109             nan     0.0010    0.0004\n",
      "     3        1.3102             nan     0.0010    0.0003\n",
      "     4        1.3094             nan     0.0010    0.0003\n",
      "     5        1.3086             nan     0.0010    0.0003\n",
      "     6        1.3078             nan     0.0010    0.0003\n",
      "     7        1.3071             nan     0.0010    0.0003\n",
      "     8        1.3063             nan     0.0010    0.0003\n",
      "     9        1.3055             nan     0.0010    0.0003\n",
      "    10        1.3047             nan     0.0010    0.0003\n",
      "    20        1.2971             nan     0.0010    0.0003\n",
      "    40        1.2822             nan     0.0010    0.0003\n",
      "    60        1.2680             nan     0.0010    0.0003\n",
      "    80        1.2545             nan     0.0010    0.0003\n",
      "   100        1.2412             nan     0.0010    0.0003\n",
      "   120        1.2286             nan     0.0010    0.0003\n",
      "   140        1.2162             nan     0.0010    0.0003\n",
      "   160        1.2041             nan     0.0010    0.0003\n",
      "   180        1.1926             nan     0.0010    0.0002\n",
      "   200        1.1811             nan     0.0010    0.0003\n",
      "   220        1.1702             nan     0.0010    0.0002\n",
      "   240        1.1595             nan     0.0010    0.0002\n",
      "   260        1.1494             nan     0.0010    0.0002\n",
      "   280        1.1396             nan     0.0010    0.0002\n",
      "   300        1.1301             nan     0.0010    0.0002\n",
      "   320        1.1209             nan     0.0010    0.0002\n",
      "   340        1.1118             nan     0.0010    0.0002\n",
      "   360        1.1028             nan     0.0010    0.0002\n",
      "   380        1.0945             nan     0.0010    0.0001\n",
      "   400        1.0864             nan     0.0010    0.0002\n",
      "   420        1.0784             nan     0.0010    0.0002\n",
      "   440        1.0705             nan     0.0010    0.0001\n",
      "   460        1.0629             nan     0.0010    0.0002\n",
      "   480        1.0556             nan     0.0010    0.0002\n",
      "   500        1.0484             nan     0.0010    0.0001\n",
      "   520        1.0414             nan     0.0010    0.0001\n",
      "   540        1.0347             nan     0.0010    0.0001\n",
      "   560        1.0283             nan     0.0010    0.0001\n",
      "   580        1.0218             nan     0.0010    0.0001\n",
      "   600        1.0155             nan     0.0010    0.0001\n",
      "   620        1.0094             nan     0.0010    0.0001\n",
      "   640        1.0037             nan     0.0010    0.0001\n",
      "   660        0.9977             nan     0.0010    0.0001\n",
      "   680        0.9919             nan     0.0010    0.0001\n",
      "   700        0.9863             nan     0.0010    0.0001\n",
      "   720        0.9808             nan     0.0010    0.0001\n",
      "   740        0.9755             nan     0.0010    0.0001\n",
      "   760        0.9705             nan     0.0010    0.0001\n",
      "   780        0.9656             nan     0.0010    0.0001\n",
      "   800        0.9604             nan     0.0010    0.0001\n",
      "   820        0.9555             nan     0.0010    0.0001\n",
      "   840        0.9507             nan     0.0010    0.0001\n",
      "   860        0.9460             nan     0.0010    0.0001\n",
      "   880        0.9413             nan     0.0010    0.0001\n",
      "   900        0.9368             nan     0.0010    0.0000\n",
      "   920        0.9325             nan     0.0010    0.0001\n",
      "   940        0.9281             nan     0.0010    0.0001\n",
      "   960        0.9237             nan     0.0010    0.0001\n",
      "   980        0.9195             nan     0.0010    0.0001\n",
      "  1000        0.9154             nan     0.0010    0.0001\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.001, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3116             nan     0.0010    0.0004\n",
      "     2        1.3107             nan     0.0010    0.0004\n",
      "     3        1.3099             nan     0.0010    0.0003\n",
      "     4        1.3090             nan     0.0010    0.0004\n",
      "     5        1.3082             nan     0.0010    0.0003\n",
      "     6        1.3074             nan     0.0010    0.0004\n",
      "     7        1.3065             nan     0.0010    0.0003\n",
      "     8        1.3058             nan     0.0010    0.0003\n",
      "     9        1.3048             nan     0.0010    0.0004\n",
      "    10        1.3040             nan     0.0010    0.0004\n",
      "    20        1.2955             nan     0.0010    0.0004\n",
      "    40        1.2794             nan     0.0010    0.0004\n",
      "    60        1.2634             nan     0.0010    0.0003\n",
      "    80        1.2482             nan     0.0010    0.0003\n",
      "   100        1.2335             nan     0.0010    0.0003\n",
      "   120        1.2196             nan     0.0010    0.0003\n",
      "   140        1.2061             nan     0.0010    0.0003\n",
      "   160        1.1927             nan     0.0010    0.0003\n",
      "   180        1.1799             nan     0.0010    0.0003\n",
      "   200        1.1673             nan     0.0010    0.0003\n",
      "   220        1.1555             nan     0.0010    0.0003\n",
      "   240        1.1435             nan     0.0010    0.0002\n",
      "   260        1.1324             nan     0.0010    0.0003\n",
      "   280        1.1213             nan     0.0010    0.0002\n",
      "   300        1.1107             nan     0.0010    0.0002\n",
      "   320        1.1002             nan     0.0010    0.0002\n",
      "   340        1.0902             nan     0.0010    0.0002\n",
      "   360        1.0805             nan     0.0010    0.0002\n",
      "   380        1.0710             nan     0.0010    0.0002\n",
      "   400        1.0618             nan     0.0010    0.0002\n",
      "   420        1.0529             nan     0.0010    0.0002\n",
      "   440        1.0441             nan     0.0010    0.0002\n",
      "   460        1.0356             nan     0.0010    0.0002\n",
      "   480        1.0272             nan     0.0010    0.0002\n",
      "   500        1.0195             nan     0.0010    0.0002\n",
      "   520        1.0118             nan     0.0010    0.0001\n",
      "   540        1.0043             nan     0.0010    0.0001\n",
      "   560        0.9967             nan     0.0010    0.0001\n",
      "   580        0.9895             nan     0.0010    0.0001\n",
      "   600        0.9824             nan     0.0010    0.0001\n",
      "   620        0.9756             nan     0.0010    0.0001\n",
      "   640        0.9688             nan     0.0010    0.0001\n",
      "   660        0.9621             nan     0.0010    0.0001\n",
      "   680        0.9556             nan     0.0010    0.0001\n",
      "   700        0.9490             nan     0.0010    0.0001\n",
      "   720        0.9427             nan     0.0010    0.0001\n",
      "   740        0.9365             nan     0.0010    0.0001\n",
      "   760        0.9304             nan     0.0010    0.0001\n",
      "   780        0.9246             nan     0.0010    0.0001\n",
      "   800        0.9189             nan     0.0010    0.0001\n",
      "   820        0.9134             nan     0.0010    0.0001\n",
      "   840        0.9078             nan     0.0010    0.0001\n",
      "   860        0.9027             nan     0.0010    0.0001\n",
      "   880        0.8974             nan     0.0010    0.0001\n",
      "   900        0.8923             nan     0.0010    0.0001\n",
      "   920        0.8873             nan     0.0010    0.0001\n",
      "   940        0.8825             nan     0.0010    0.0001\n",
      "   960        0.8775             nan     0.0010    0.0001\n",
      "   980        0.8729             nan     0.0010    0.0001\n",
      "  1000        0.8684             nan     0.0010    0.0001\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.001, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3067             nan     0.0100    0.0029\n",
      "     2        1.3006             nan     0.0100    0.0029\n",
      "     3        1.2946             nan     0.0100    0.0027\n",
      "     4        1.2880             nan     0.0100    0.0027\n",
      "     5        1.2825             nan     0.0100    0.0025\n",
      "     6        1.2766             nan     0.0100    0.0026\n",
      "     7        1.2712             nan     0.0100    0.0025\n",
      "     8        1.2658             nan     0.0100    0.0026\n",
      "     9        1.2598             nan     0.0100    0.0025\n",
      "    10        1.2549             nan     0.0100    0.0022\n",
      "    20        1.2083             nan     0.0100    0.0020\n",
      "    40        1.1323             nan     0.0100    0.0014\n",
      "    60        1.0759             nan     0.0100    0.0012\n",
      "    80        1.0313             nan     0.0100    0.0008\n",
      "   100        0.9964             nan     0.0100    0.0007\n",
      "   120        0.9693             nan     0.0100    0.0004\n",
      "   140        0.9460             nan     0.0100    0.0002\n",
      "   160        0.9272             nan     0.0100    0.0002\n",
      "   180        0.9122             nan     0.0100    0.0002\n",
      "   200        0.8992             nan     0.0100    0.0002\n",
      "   220        0.8887             nan     0.0100    0.0002\n",
      "   240        0.8800             nan     0.0100   -0.0000\n",
      "   260        0.8720             nan     0.0100    0.0000\n",
      "   280        0.8642             nan     0.0100   -0.0000\n",
      "   300        0.8574             nan     0.0100   -0.0001\n",
      "   320        0.8504             nan     0.0100   -0.0000\n",
      "   340        0.8444             nan     0.0100    0.0000\n",
      "   360        0.8381             nan     0.0100    0.0000\n",
      "   380        0.8322             nan     0.0100    0.0000\n",
      "   400        0.8264             nan     0.0100   -0.0000\n",
      "   420        0.8212             nan     0.0100   -0.0000\n",
      "   440        0.8159             nan     0.0100    0.0000\n",
      "   460        0.8110             nan     0.0100   -0.0000\n",
      "   480        0.8062             nan     0.0100   -0.0001\n",
      "   500        0.8018             nan     0.0100   -0.0002\n",
      "   520        0.7975             nan     0.0100    0.0000\n",
      "   540        0.7931             nan     0.0100   -0.0000\n",
      "   560        0.7889             nan     0.0100    0.0000\n",
      "   580        0.7850             nan     0.0100   -0.0001\n",
      "   600        0.7816             nan     0.0100   -0.0000\n",
      "   620        0.7777             nan     0.0100   -0.0000\n",
      "   640        0.7738             nan     0.0100   -0.0000\n",
      "   660        0.7701             nan     0.0100   -0.0001\n",
      "   680        0.7668             nan     0.0100   -0.0000\n",
      "   700        0.7631             nan     0.0100   -0.0001\n",
      "   720        0.7599             nan     0.0100   -0.0001\n",
      "   740        0.7563             nan     0.0100    0.0000\n",
      "   760        0.7529             nan     0.0100   -0.0001\n",
      "   780        0.7496             nan     0.0100   -0.0000\n",
      "   800        0.7467             nan     0.0100    0.0000\n",
      "   820        0.7435             nan     0.0100   -0.0001\n",
      "   840        0.7400             nan     0.0100   -0.0000\n",
      "   860        0.7373             nan     0.0100   -0.0000\n",
      "   880        0.7345             nan     0.0100   -0.0002\n",
      "   900        0.7321             nan     0.0100   -0.0000\n",
      "   920        0.7293             nan     0.0100   -0.0001\n",
      "   940        0.7267             nan     0.0100   -0.0001\n",
      "   960        0.7241             nan     0.0100   -0.0000\n",
      "   980        0.7214             nan     0.0100    0.0000\n",
      "  1000        0.7189             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.010, interaction.depth=1, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3051             nan     0.0100    0.0035\n",
      "     2        1.2979             nan     0.0100    0.0032\n",
      "     3        1.2915             nan     0.0100    0.0027\n",
      "     4        1.2838             nan     0.0100    0.0038\n",
      "     5        1.2768             nan     0.0100    0.0031\n",
      "     6        1.2695             nan     0.0100    0.0027\n",
      "     7        1.2632             nan     0.0100    0.0029\n",
      "     8        1.2563             nan     0.0100    0.0029\n",
      "     9        1.2495             nan     0.0100    0.0033\n",
      "    10        1.2428             nan     0.0100    0.0029\n",
      "    20        1.1819             nan     0.0100    0.0022\n",
      "    40        1.0875             nan     0.0100    0.0019\n",
      "    60        1.0158             nan     0.0100    0.0014\n",
      "    80        0.9592             nan     0.0100    0.0010\n",
      "   100        0.9152             nan     0.0100    0.0009\n",
      "   120        0.8801             nan     0.0100    0.0004\n",
      "   140        0.8494             nan     0.0100    0.0005\n",
      "   160        0.8246             nan     0.0100    0.0003\n",
      "   180        0.8027             nan     0.0100    0.0001\n",
      "   200        0.7828             nan     0.0100    0.0002\n",
      "   220        0.7648             nan     0.0100    0.0002\n",
      "   240        0.7501             nan     0.0100   -0.0000\n",
      "   260        0.7372             nan     0.0100   -0.0001\n",
      "   280        0.7243             nan     0.0100    0.0000\n",
      "   300        0.7133             nan     0.0100    0.0000\n",
      "   320        0.7012             nan     0.0100   -0.0001\n",
      "   340        0.6914             nan     0.0100   -0.0001\n",
      "   360        0.6816             nan     0.0100   -0.0001\n",
      "   380        0.6723             nan     0.0100   -0.0001\n",
      "   400        0.6633             nan     0.0100   -0.0000\n",
      "   420        0.6540             nan     0.0100    0.0000\n",
      "   440        0.6461             nan     0.0100    0.0000\n",
      "   460        0.6377             nan     0.0100   -0.0001\n",
      "   480        0.6297             nan     0.0100   -0.0001\n",
      "   500        0.6220             nan     0.0100   -0.0000\n",
      "   520        0.6146             nan     0.0100   -0.0001\n",
      "   540        0.6068             nan     0.0100   -0.0002\n",
      "   560        0.5989             nan     0.0100   -0.0001\n",
      "   580        0.5912             nan     0.0100   -0.0000\n",
      "   600        0.5841             nan     0.0100   -0.0002\n",
      "   620        0.5772             nan     0.0100   -0.0001\n",
      "   640        0.5710             nan     0.0100   -0.0001\n",
      "   660        0.5644             nan     0.0100    0.0001\n",
      "   680        0.5577             nan     0.0100   -0.0000\n",
      "   700        0.5512             nan     0.0100   -0.0001\n",
      "   720        0.5440             nan     0.0100   -0.0000\n",
      "   740        0.5378             nan     0.0100   -0.0002\n",
      "   760        0.5329             nan     0.0100   -0.0000\n",
      "   780        0.5277             nan     0.0100   -0.0002\n",
      "   800        0.5222             nan     0.0100   -0.0002\n",
      "   820        0.5162             nan     0.0100   -0.0001\n",
      "   840        0.5113             nan     0.0100   -0.0001\n",
      "   860        0.5060             nan     0.0100   -0.0001\n",
      "   880        0.5006             nan     0.0100    0.0001\n",
      "   900        0.4959             nan     0.0100   -0.0000\n",
      "   920        0.4909             nan     0.0100   -0.0001\n",
      "   940        0.4855             nan     0.0100   -0.0001\n",
      "   960        0.4809             nan     0.0100   -0.0001\n",
      "   980        0.4766             nan     0.0100   -0.0000\n",
      "  1000        0.4716             nan     0.0100   -0.0001\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.010, interaction.depth=3, n.minobsinnode=10, n.trees=1000 \n",
      "+ Fold10.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3039             nan     0.0100    0.0037\n",
      "     2        1.2960             nan     0.0100    0.0036\n",
      "     3        1.2876             nan     0.0100    0.0038\n",
      "     4        1.2789             nan     0.0100    0.0038\n",
      "     5        1.2712             nan     0.0100    0.0029\n",
      "     6        1.2631             nan     0.0100    0.0034\n",
      "     7        1.2554             nan     0.0100    0.0028\n",
      "     8        1.2474             nan     0.0100    0.0033\n",
      "     9        1.2399             nan     0.0100    0.0032\n",
      "    10        1.2323             nan     0.0100    0.0031\n",
      "    20        1.1686             nan     0.0100    0.0025\n",
      "    40        1.0628             nan     0.0100    0.0021\n",
      "    60        0.9812             nan     0.0100    0.0014\n",
      "    80        0.9187             nan     0.0100    0.0010\n",
      "   100        0.8686             nan     0.0100    0.0006\n",
      "   120        0.8277             nan     0.0100    0.0005\n",
      "   140        0.7928             nan     0.0100    0.0004\n",
      "   160        0.7625             nan     0.0100    0.0002\n",
      "   180        0.7378             nan     0.0100    0.0001\n",
      "   200        0.7154             nan     0.0100   -0.0002\n",
      "   220        0.6941             nan     0.0100    0.0001\n",
      "   240        0.6748             nan     0.0100    0.0001\n",
      "   260        0.6576             nan     0.0100   -0.0001\n",
      "   280        0.6407             nan     0.0100    0.0001\n",
      "   300        0.6265             nan     0.0100    0.0001\n",
      "   320        0.6121             nan     0.0100   -0.0000\n",
      "   340        0.5980             nan     0.0100   -0.0002\n",
      "   360        0.5850             nan     0.0100   -0.0000\n",
      "   380        0.5724             nan     0.0100    0.0000\n",
      "   400        0.5613             nan     0.0100   -0.0000\n",
      "   420        0.5494             nan     0.0100   -0.0002\n",
      "   440        0.5386             nan     0.0100   -0.0001\n",
      "   460        0.5272             nan     0.0100   -0.0002\n",
      "   480        0.5175             nan     0.0100   -0.0002\n",
      "   500        0.5069             nan     0.0100   -0.0003\n",
      "   520        0.4975             nan     0.0100   -0.0003\n",
      "   540        0.4883             nan     0.0100   -0.0001\n",
      "   560        0.4794             nan     0.0100   -0.0000\n",
      "   580        0.4714             nan     0.0100   -0.0001\n",
      "   600        0.4627             nan     0.0100   -0.0002\n",
      "   620        0.4547             nan     0.0100   -0.0001\n",
      "   640        0.4466             nan     0.0100   -0.0000\n",
      "   660        0.4386             nan     0.0100   -0.0002\n",
      "   680        0.4304             nan     0.0100   -0.0001\n",
      "   700        0.4225             nan     0.0100   -0.0001\n",
      "   720        0.4152             nan     0.0100   -0.0001\n",
      "   740        0.4095             nan     0.0100   -0.0002\n",
      "   760        0.4019             nan     0.0100   -0.0002\n",
      "   780        0.3949             nan     0.0100   -0.0001\n",
      "   800        0.3881             nan     0.0100   -0.0001\n",
      "   820        0.3814             nan     0.0100   -0.0002\n",
      "   840        0.3740             nan     0.0100   -0.0001\n",
      "   860        0.3684             nan     0.0100   -0.0001\n",
      "   880        0.3622             nan     0.0100   -0.0001\n",
      "   900        0.3561             nan     0.0100   -0.0001\n",
      "   920        0.3502             nan     0.0100   -0.0001\n",
      "   940        0.3441             nan     0.0100   -0.0002\n",
      "   960        0.3387             nan     0.0100   -0.0002\n",
      "   980        0.3331             nan     0.0100   -0.0001\n",
      "  1000        0.3277             nan     0.0100   -0.0000\n",
      "\n",
      "- Fold10.Rep1: shrinkage=0.010, interaction.depth=5, n.minobsinnode=10, n.trees=1000 \n",
      "Aggregating results\n",
      "Selecting tuning parameters\n",
      "Fitting n.trees = 500, interaction.depth = 3, shrinkage = 0.01, n.minobsinnode = 10 on full training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 16: NNP has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 39: WRB has no variation.\"Warning message in (function (x, y, offset = NULL, misc = NULL, distribution = \"bernoulli\", :\n",
      "\"variable 48: ellipsis has no variation.\""
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter   TrainDeviance   ValidDeviance   StepSize   Improve\n",
      "     1        1.3055             nan     0.0100    0.0035\n",
      "     2        1.2977             nan     0.0100    0.0034\n",
      "     3        1.2902             nan     0.0100    0.0032\n",
      "     4        1.2826             nan     0.0100    0.0037\n",
      "     5        1.2749             nan     0.0100    0.0033\n",
      "     6        1.2674             nan     0.0100    0.0033\n",
      "     7        1.2603             nan     0.0100    0.0033\n",
      "     8        1.2534             nan     0.0100    0.0030\n",
      "     9        1.2466             nan     0.0100    0.0031\n",
      "    10        1.2400             nan     0.0100    0.0032\n",
      "    20        1.1808             nan     0.0100    0.0024\n",
      "    40        1.0851             nan     0.0100    0.0020\n",
      "    60        1.0132             nan     0.0100    0.0013\n",
      "    80        0.9554             nan     0.0100    0.0008\n",
      "   100        0.9099             nan     0.0100    0.0008\n",
      "   120        0.8738             nan     0.0100    0.0004\n",
      "   140        0.8447             nan     0.0100    0.0004\n",
      "   160        0.8197             nan     0.0100    0.0004\n",
      "   180        0.7990             nan     0.0100    0.0002\n",
      "   200        0.7801             nan     0.0100    0.0002\n",
      "   220        0.7627             nan     0.0100    0.0002\n",
      "   240        0.7470             nan     0.0100    0.0000\n",
      "   260        0.7332             nan     0.0100    0.0000\n",
      "   280        0.7212             nan     0.0100    0.0002\n",
      "   300        0.7098             nan     0.0100   -0.0000\n",
      "   320        0.6984             nan     0.0100   -0.0000\n",
      "   340        0.6881             nan     0.0100   -0.0001\n",
      "   360        0.6784             nan     0.0100   -0.0000\n",
      "   380        0.6704             nan     0.0100   -0.0002\n",
      "   400        0.6616             nan     0.0100   -0.0001\n",
      "   420        0.6530             nan     0.0100   -0.0000\n",
      "   440        0.6454             nan     0.0100    0.0000\n",
      "   460        0.6369             nan     0.0100   -0.0001\n",
      "   480        0.6294             nan     0.0100   -0.0001\n",
      "   500        0.6222             nan     0.0100   -0.0002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "folds <- createMultiFolds(train$Label, k = 10, times = 1)\n",
    "control <- trainControl(method = \"cv\", number = 10, verboseIter = TRUE, summaryFunction = twoClassSummary,\n",
    "                        classProbs = TRUE, savePredictions = TRUE, index = folds, allowParallel = TRUE)\n",
    "tune_grid <- expand.grid(interaction.depth=c(1, 3, 5), n.trees = c(500, 1000), shrinkage=c(0.01, 0.001), n.minobsinnode = 10)\n",
    "gbm <- train(Label ~., data = train, method = \"gbm\", metric = \"Accuracy\", tuneGrid = tune_grid, trControl = control)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stochastic Gradient Boosting \n",
       "\n",
       "750 samples\n",
       " 59 predictor\n",
       "  2 classes: 'objective', 'subjective' \n",
       "\n",
       "No pre-processing\n",
       "Resampling: Cross-Validated (10 fold) \n",
       "Summary of sample sizes: 676, 675, 675, 675, 676, 674, ... \n",
       "Resampling results across tuning parameters:\n",
       "\n",
       "  shrinkage  interaction.depth  n.trees  ROC        Sens       Spec     \n",
       "  0.001      1                   500     0.8541571  0.9475177  0.4525132\n",
       "  0.001      1                  1000     0.8556007  0.9013741  0.6238095\n",
       "  0.001      3                   500     0.8701393  0.9558954  0.4994709\n",
       "  0.001      3                  1000     0.8717922  0.9034574  0.6789683\n",
       "  0.001      5                   500     0.8749237  0.9643174  0.4921958\n",
       "  0.001      5                  1000     0.8781604  0.9118351  0.6862434\n",
       "  0.010      1                   500     0.8655422  0.8845301  0.7191799\n",
       "  0.010      1                  1000     0.8738009  0.8844858  0.7227513\n",
       "  0.010      3                   500     0.8817070  0.8929965  0.7373016\n",
       "  0.010      3                  1000     0.8805818  0.8971631  0.7333333\n",
       "  0.010      5                   500     0.8805065  0.8992465  0.7264550\n",
       "  0.010      5                  1000     0.8780087  0.9055851  0.7374339\n",
       "\n",
       "Tuning parameter 'n.minobsinnode' was held constant at a value of 10\n",
       "ROC was used to select the optimal model using the largest value.\n",
       "The final values used for the model were n.trees = 500, interaction.depth =\n",
       " 3, shrinkage = 0.01 and n.minobsinnode = 10."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        142         17\n",
       "  subjective        20         71\n",
       "                                          \n",
       "               Accuracy : 0.852           \n",
       "                 95% CI : (0.8018, 0.8936)\n",
       "    No Information Rate : 0.648           \n",
       "    P-Value [Acc > NIR] : 4.153e-13       \n",
       "                                          \n",
       "                  Kappa : 0.6781          \n",
       "                                          \n",
       " Mcnemar's Test P-Value : 0.7423          \n",
       "                                          \n",
       "            Sensitivity : 0.8765          \n",
       "            Specificity : 0.8068          \n",
       "         Pos Pred Value : 0.8931          \n",
       "         Neg Pred Value : 0.7802          \n",
       "             Prevalence : 0.6480          \n",
       "         Detection Rate : 0.5680          \n",
       "   Detection Prevalence : 0.6360          \n",
       "      Balanced Accuracy : 0.8417          \n",
       "                                          \n",
       "       'Positive' Class : objective       \n",
       "                                          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions <- predict(gbm, newdata = test)\n",
    "confusionMatrix(test$Label,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Confusion Matrix and Statistics\n",
       "\n",
       "            Reference\n",
       "Prediction   objective subjective\n",
       "  objective        442         34\n",
       "  subjective        58        216\n",
       "                                       \n",
       "               Accuracy : 0.8773       \n",
       "                 95% CI : (0.8517, 0.9)\n",
       "    No Information Rate : 0.6667       \n",
       "    P-Value [Acc > NIR] : < 2e-16      \n",
       "                                       \n",
       "                  Kappa : 0.7305       \n",
       "                                       \n",
       " Mcnemar's Test P-Value : 0.01649      \n",
       "                                       \n",
       "            Sensitivity : 0.8840       \n",
       "            Specificity : 0.8640       \n",
       "         Pos Pred Value : 0.9286       \n",
       "         Neg Pred Value : 0.7883       \n",
       "             Prevalence : 0.6667       \n",
       "         Detection Rate : 0.5893       \n",
       "   Detection Prevalence : 0.6347       \n",
       "      Balanced Accuracy : 0.8740       \n",
       "                                       \n",
       "       'Positive' Class : objective    \n",
       "                                       "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions <- predict(gbm, newdata = train)\n",
    "confusionMatrix(train$Label,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy for test data is 0.85 and 0.87 for train data. Worked well and no issue of overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 90% LASSO performed the best and SGB is second with 0.85. Random Forest was 0.83 but has overfitting. Decision tree has 0.82. For this dataset, LASSO is the best performer, high accuracy but no overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
